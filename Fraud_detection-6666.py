# -*- coding: utf-8 -*-
"""
Biomass Pyrolysis Yield Forecast using CatBoost Ensemble Models
ä¿®å¤ç‰ˆæœ¬ - è§£å†³å°æ•°ç²¾åº¦é—®é¢˜å’Œå­æ¨¡å‹æ ‡å‡†åŒ–å™¨é—®é¢˜
æ·»åŠ å¤šæ¨¡å‹åˆ‡æ¢åŠŸèƒ½ - æ”¯æŒCharã€Oilå’ŒGasäº§ç‡é¢„æµ‹
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import glob
import joblib
import json
import traceback
import matplotlib.pyplot as plt
from datetime import datetime
import io
from PIL import Image

# æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æ¸²æŸ“
if "debug" not in st.session_state:
    st.cache_data.clear()
    st.session_state.debug = True
    st.session_state.decimal_test = 46.12  # æµ‹è¯•ä¸¤ä½å°æ•°

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title='Biomass Pyrolysis Yield Prediction',
    page_icon='ğŸ”¥',
    layout='wide',
    initial_sidebar_state='expanded'
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown(
    """
    <style>
    /* å…¨å±€å­—ä½“è®¾ç½® */
    html, body, [class*="css"] {
        font-size: 16px !important;
    }
    
    /* æ ‡é¢˜ */
    .main-title {
        text-align: center;
        font-size: 32px !important;
        font-weight: bold;
        margin-bottom: 20px;
        color: white !important;
    }
    
    /* åŒºåŸŸæ ·å¼ */
    .section-header {
        color: white;
        font-weight: bold;
        font-size: 22px;
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 5px;
        border-radius: 5px;
        margin-bottom: 5px;
        font-size: 18px;
        color: white;
    }
    
    /* ç»“æœæ˜¾ç¤ºæ ·å¼ */
    .yield-result {
        background-color: #1E1E1E;
        color: white;
        font-size: 36px;
        font-weight: bold;
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    
    /* å¼ºåˆ¶åº”ç”¨ç™½è‰²èƒŒæ™¯åˆ°è¾“å…¥æ¡† */
    [data-testid="stNumberInput"] input {
        background-color: white !important;
        color: black !important;
    }
    
    /* å¢å¤§æŒ‰é’®çš„å­—ä½“ */
    .stButton button {
        font-size: 18px !important;
    }
    
    /* è­¦å‘Šæ ·å¼ */
    .warning-box {
        background-color: rgba(255, 165, 0, 0.2);
        border-left: 5px solid orange;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* é”™è¯¯æ ·å¼ */
    .error-box {
        background-color: rgba(255, 0, 0, 0.2);
        border-left: 5px solid red;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* æˆåŠŸæ ·å¼ */
    .success-box {
        background-color: rgba(0, 128, 0, 0.2);
        border-left: 5px solid green;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* æ—¥å¿—æ ·å¼ */
    .log-container {
        height: 300px;
        overflow-y: auto;
        background-color: #1E1E1E;
        color: #00FF00;
        font-family: 'Courier New', monospace;
        padding: 10px;
        border-radius: 5px;
        font-size: 14px !important;
    }
    
    /* æ¨¡å‹é€‰æ‹©å™¨æ ·å¼ */
    .model-selector {
        background-color: #2E2E2E;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 20px;
        text-align: center;
    }
    
    /* æ¨¡å‹åˆ‡æ¢æŒ‰é’®ç»„æ ·å¼ */
    div[data-testid="stHorizontalBlock"] [data-testid="stButton"] {
        margin: 0 5px;
    }
    
    /* å¡«æ»¡å±å¹• */
    .stApp {
        width: 100%;
        min-width: 100%;
        margin: 0 auto;
    }
    
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 100%;
    }
    
    /* ä¾§è¾¹æ æ¨¡å‹ä¿¡æ¯æ ·å¼ */
    .sidebar-model-info {
        background-color: #2E2E2E;
        padding: 10px;
        border-radius: 5px;
        margin-top: 20px;
    }
    
    /* æ€§èƒ½æŒ‡æ ‡æ ·å¼ */
    .performance-metrics {
        background-color: #2E2E2E;
        padding: 10px;
        border-radius: 5px;
        margin-top: 10px;
    }
    
    /* æŠ€æœ¯è¯´æ˜æ ·å¼ */
    .tech-info {
        background-color: #2E2E2E;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# åˆ›å»ºä¾§è¾¹æ æ—¥å¿—åŒºåŸŸ
log_container = st.sidebar.container()
log_container.markdown("<h3>æ‰§è¡Œæ—¥å¿—</h3>", unsafe_allow_html=True)
log_text = st.sidebar.empty()

# åˆå§‹åŒ–æ—¥å¿—å­—ç¬¦ä¸²
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []

def log(message):
    """è®°å½•æ—¥å¿—åˆ°ä¾§è¾¹æ å’Œä¼šè¯çŠ¶æ€"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    st.session_state.log_messages.append(log_entry)
    # åªä¿ç•™æœ€è¿‘çš„100æ¡æ—¥å¿—
    if len(st.session_state.log_messages) > 100:
        st.session_state.log_messages = st.session_state.log_messages[-100:]
    
    # æ›´æ–°æ—¥å¿—æ˜¾ç¤º
    log_text.markdown(
        f"<div class='log-container'>{'<br>'.join(st.session_state.log_messages)}</div>", 
        unsafe_allow_html=True
    )

# è®°å½•å¯åŠ¨æ—¥å¿—
log("åº”ç”¨å¯åŠ¨ - æ”¯æŒä¸¤ä½å°æ•°å’Œå¤šæ¨¡å‹åˆ‡æ¢åŠŸèƒ½")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ - æ·»åŠ æ¨¡å‹é€‰æ‹©åŠŸèƒ½
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "Char Yield(%)"  # é»˜è®¤é€‰æ‹©Charäº§ç‡æ¨¡å‹
    log(f"åˆå§‹åŒ–é€‰å®šæ¨¡å‹: {st.session_state.selected_model}")

# æ›´æ–°ä¸»æ ‡é¢˜ä»¥æ˜¾ç¤ºå½“å‰é€‰å®šçš„æ¨¡å‹
st.markdown("<h1 class='main-title'>åŸºäºCatboosté›†æˆæ¨¡å‹çš„ç”Ÿç‰©è´¨çƒ­è§£äº§ç‰©é¢„æµ‹ç³»ç»Ÿ</h1>", unsafe_allow_html=True)

# æ·»åŠ æ¨¡å‹é€‰æ‹©åŒºåŸŸ - ä¿®æ”¹ä¸ºä¸‰ä¸ªæŒ‰é’®ä¸€æ’
st.markdown("<div class='model-selector'>", unsafe_allow_html=True)
st.markdown("<h3>é€‰æ‹©é¢„æµ‹ç›®æ ‡</h3>", unsafe_allow_html=True)
col1, col2, col3 = st.columns(3)
with col1:
    char_button = st.button("ğŸ”¥ Char Yield", 
                           key="char_button", 
                           help="é¢„æµ‹ç„¦ç‚­äº§ç‡ (%)", 
                           use_container_width=True,
                           type="primary" if st.session_state.selected_model == "Char Yield(%)" else "secondary")
with col2:
    oil_button = st.button("ğŸ’§ Oil Yield", 
                          key="oil_button", 
                          help="é¢„æµ‹ç”Ÿç‰©æ²¹äº§ç‡ (%)", 
                          use_container_width=True,
                          type="primary" if st.session_state.selected_model == "Oil Yield(%)" else "secondary")
with col3:
    gas_button = st.button("ğŸ’¨ Gas Yield", 
                          key="gas_button", 
                          help="é¢„æµ‹æ°”ä½“äº§ç‡ (%)", 
                          use_container_width=True,
                          type="primary" if st.session_state.selected_model == "Gas Yield(%)" else "secondary")

# å¤„ç†æ¨¡å‹é€‰æ‹©
if char_button:
    st.session_state.selected_model = "Char Yield(%)"
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    st.session_state.individual_predictions = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {st.session_state.selected_model}")
    st.rerun()

if oil_button:
    st.session_state.selected_model = "Oil Yield(%)"
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    st.session_state.individual_predictions = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {st.session_state.selected_model}")
    st.rerun()

if gas_button:
    st.session_state.selected_model = "Gas Yield(%)"
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    st.session_state.individual_predictions = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {st.session_state.selected_model}")
    st.rerun()

st.markdown(f"<p style='text-align:center;'>å½“å‰æ¨¡å‹: <b>{st.session_state.selected_model}</b></p>", unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)

class CorrectedEnsemblePredictor:
    """ä¿®å¤ç‰ˆé›†æˆæ¨¡å‹é¢„æµ‹å™¨ - è§£å†³å­æ¨¡å‹æ ‡å‡†åŒ–å™¨é—®é¢˜ï¼Œæ”¯æŒå¤šæ¨¡å‹åˆ‡æ¢"""
    
    def __init__(self, target_model="Char Yield(%)"):
        self.models = []
        self.scalers = []  # æ¯ä¸ªå­æ¨¡å‹çš„æ ‡å‡†åŒ–å™¨
        self.final_scaler = None  # æœ€ç»ˆæ ‡å‡†åŒ–å™¨ï¼ˆå¤‡ç”¨ï¼‰
        self.model_weights = None
        self.feature_names = None
        self.target_name = target_model  # è®¾ç½®ç›®æ ‡å˜é‡åç§°
        self.metadata = None
        self.model_dir = None
        self.feature_importance = None
        self.training_ranges = {}
        self.model_loaded = False  # æ–°å¢ï¼šæ ‡è®°æ¨¡å‹åŠ è½½çŠ¶æ€
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    def find_model_directory(self):
        """æŸ¥æ‰¾æ¨¡å‹ç›®å½•çš„å¤šç§æ–¹æ³•ï¼Œæ”¯æŒä¸åŒæ¨¡å‹ç±»å‹"""
        # æ ¹æ®ç›®æ ‡å˜é‡ç¡®å®šæ¨¡å‹ç›®å½•åç§°
        model_name = self.target_name.replace(' ', '_').replace('(', '').replace(')', '')
        log(f"å°è¯•æŸ¥æ‰¾æ¨¡å‹ç›®å½•: {model_name}_Model")
        
        # æ¨¡å‹ç›®å½•å¯èƒ½çš„è·¯å¾„ - æ·»åŠ æ›´å¤šå¯èƒ½çš„è·¯å¾„ä»¥æé«˜æŸ¥æ‰¾æˆåŠŸç‡
        possible_dirs = [
            # å½“å‰ç›®å½•å’Œçˆ¶ç›®å½•
            f"./{model_name}_Model",
            f"../{model_name}_Model",
            # åº”ç”¨æ ¹ç›®å½•
            f"{model_name}_Model",
            # æ›´å¤šå¯èƒ½çš„ä½ç½®
            f"./models/{model_name}_Model",
            f"../models/{model_name}_Model",
            # ç³»ç»Ÿè·¯å¾„
            f"C:/Users/HWY/Desktop/æ–¹-3/{model_name}_Model",
            # å¦‚æœæ˜¯åœ¨äº‘æœåŠ¡ä¸Šè¿è¡Œ
            f"/app/{model_name}_Model",
            f"/app/models/{model_name}_Model",
            f"/mount/src/{model_name}_Model",
            # åº”ç”¨å½“å‰å·¥ä½œç›®å½•
            os.path.join(os.getcwd(), f"{model_name}_Model"),
            # ç‰¹å®šè·¯å¾„ (ä»æˆªå›¾ä¸­çœ‹åˆ°çš„)
            f"/source/src/app/{model_name}_Model"
        ]
        
        # å°è¯•æ‰€æœ‰å¯èƒ½è·¯å¾„
        for dir_path in possible_dirs:
            if os.path.exists(dir_path) and os.path.isdir(dir_path):
                log(f"æ‰¾åˆ°æ¨¡å‹ç›®å½•: {dir_path}")
                return os.path.abspath(dir_path)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•å…¨å±€æ¨¡ç³Šæœç´¢ (å…ˆæœç´¢å½“å‰ç›®å½•å’Œå­ç›®å½•)
        try:
            log("åœ¨å½“å‰ç›®å½•åŠå­ç›®å½•æœç´¢æ¨¡å‹æ–‡ä»¶...")
            # ä½¿ç”¨ ** é€šé…ç¬¦è¿›è¡Œé€’å½’æœç´¢
            for pattern in [
                f"**/{model_name}_Model",
                f"**/models/{model_name}_Model",
                f"**/{model_name}_Model/**",
                f"**/models/**/{model_name}_Model"
            ]:
                matches = glob.glob(pattern, recursive=True)
                if matches:
                    for match in matches:
                        if os.path.isdir(match):
                            log(f"é€šè¿‡å…¨å±€æœç´¢æ‰¾åˆ°æ¨¡å‹ç›®å½•: {match}")
                            return os.path.abspath(match)
            
            # å¦‚æœä¸Šé¢çš„æœç´¢å¤±è´¥ï¼Œå°è¯•æ ¹æ®æ¨¡å‹æ–‡ä»¶åå‘æŸ¥æ‰¾ç›®å½•
            model_files = glob.glob(f"**/{model_name}_Model/**/model_*.joblib", recursive=True)
            if model_files:
                model_dir = os.path.dirname(os.path.dirname(model_files[0]))
                log(f"åŸºäºæ¨¡å‹æ–‡ä»¶æ¨æ–­æ¨¡å‹ç›®å½•: {model_dir}")
                return model_dir
        except Exception as e:
            log(f"æœç´¢æ¨¡å‹ç›®å½•æ—¶å‡ºé”™: {str(e)}")
        
        # è¿”å›å½“å‰ç›®å½•ä½œä¸ºæœ€åçš„é€€è·¯ï¼ŒåŒæ—¶è®°å½•è­¦å‘Š
        log(f"ä¸¥é‡è­¦å‘Š: æ— æ³•æ‰¾åˆ°{self.target_name}æ¨¡å‹ç›®å½•ï¼Œå°†ä½¿ç”¨å½“å‰ç›®å½•ã€‚é¢„æµ‹å°†è¿”å›é»˜è®¤å€¼!")
        return os.getcwd()
    
    def load_feature_importance(self):
        """åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®"""
        try:
            # å°è¯•ä»CSVæ–‡ä»¶åŠ è½½ç‰¹å¾é‡è¦æ€§
            importance_csv = os.path.join(self.model_dir, "feature_importance.csv")
            if os.path.exists(importance_csv):
                importance_df = pd.read_csv(importance_csv)
                self.feature_importance = importance_df
                log(f"å·²åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œå…± {len(importance_df)} ä¸ªç‰¹å¾")
                return True
            
            # å¦‚æœCSVä¸å­˜åœ¨ï¼Œå°è¯•ä»å…ƒæ•°æ®ä¸­åŠ è½½
            if self.metadata and 'feature_importance' in self.metadata:
                importance_data = self.metadata['feature_importance']
                self.feature_importance = pd.DataFrame(importance_data)
                log(f"ä»å…ƒæ•°æ®åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®")
                return True
            
            # å°è¯•é€šè¿‡åŠ è½½çš„æ¨¡å‹è®¡ç®—ç‰¹å¾é‡è¦æ€§
            if self.models and self.model_weights is not None and self.feature_names:
                log("é€šè¿‡æ¨¡å‹è®¡ç®—ç‰¹å¾é‡è¦æ€§")
                importance = np.zeros(len(self.feature_names))
                for i, model in enumerate(self.models):
                    try:
                        model_importance = model.get_feature_importance()
                        importance += model_importance * self.model_weights[i]
                    except Exception as e:
                        log(f"è·å–æ¨¡å‹ {i} ç‰¹å¾é‡è¦æ€§æ—¶å‡ºé”™: {str(e)}")
                
                self.feature_importance = pd.DataFrame({
                    'Feature': self.feature_names,
                    'Importance': importance
                }).sort_values('Importance', ascending=False)
                
                log(f"è®¡ç®—å¾—åˆ°ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œæœ€é‡è¦ç‰¹å¾: {self.feature_importance['Feature'].iloc[0]}")
                return True
                
            log("è­¦å‘Š: æ— æ³•åŠ è½½æˆ–è®¡ç®—ç‰¹å¾é‡è¦æ€§")
            return False
        except Exception as e:
            log(f"åŠ è½½ç‰¹å¾é‡è¦æ€§æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def extract_training_ranges(self):
        """ä»æ ‡å‡†åŒ–å™¨ä¸­æå–è®­ç»ƒæ•°æ®èŒƒå›´"""
        if not hasattr(self.final_scaler, 'mean_') or not hasattr(self.final_scaler, 'scale_'):
            log("è­¦å‘Š: æ ‡å‡†åŒ–å™¨æ²¡æœ‰å‡å€¼æˆ–æ ‡å‡†å·®ä¿¡æ¯")
            return
        
        if not self.feature_names:
            log("è­¦å‘Š: æ— æ³•è·å–ç‰¹å¾åç§°")
            return
        
        # æå–ç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
        means = self.final_scaler.mean_
        stds = self.final_scaler.scale_
        
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„95%ç½®ä¿¡åŒºé—´ (å‡å€¼Â±2æ ‡å‡†å·®)
        for i, feature in enumerate(self.feature_names):
            if i < len(means) and i < len(stds):
                mean_val = means[i]
                std_val = stds[i]
                self.training_ranges[feature] = {
                    'mean': mean_val,
                    'std': std_val,
                    'min': mean_val - 2 * std_val,  # è¿‘ä¼¼95%ç½®ä¿¡åŒºé—´ä¸‹é™
                    'max': mean_val + 2 * std_val,  # è¿‘ä¼¼95%ç½®ä¿¡åŒºé—´ä¸Šé™
                }
        
        if self.training_ranges:
            log(f"å·²æå– {len(self.training_ranges)} ä¸ªç‰¹å¾çš„è®­ç»ƒèŒƒå›´")
    
    def load_model(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹ç»„ä»¶ï¼ŒåŒ…æ‹¬æ¯ä¸ªå­æ¨¡å‹çš„æ ‡å‡†åŒ–å™¨"""
        try:
            # æ¸…ç©ºä¹‹å‰çš„æ¨¡å‹æ•°æ®
            self.models = []
            self.scalers = []
            self.feature_importance = None
            self.training_ranges = {}
            self.model_loaded = False  # é‡ç½®åŠ è½½çŠ¶æ€
            
            # 1. æŸ¥æ‰¾æ¨¡å‹ç›®å½•
            self.model_dir = self.find_model_directory()
            log(f"ä½¿ç”¨{self.target_name}æ¨¡å‹ç›®å½•: {self.model_dir}")
            
            # 2. åŠ è½½å…ƒæ•°æ®
            metadata_path = os.path.join(self.model_dir, 'metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    self.metadata = json.load(f)
                
                # è·å–ç‰¹å¾åç§°å’Œç›®æ ‡å˜é‡
                self.feature_names = self.metadata.get('feature_names', None)
                if self.metadata.get('target_name'):
                    self.target_name = self.metadata['target_name']
                
                log(f"ä»å…ƒæ•°æ®åŠ è½½ç‰¹å¾åˆ—è¡¨: {self.feature_names}")
                log(f"ç›®æ ‡å˜é‡: {self.target_name}")
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ {metadata_path}")
                # ä½¿ç”¨é»˜è®¤ç‰¹å¾åˆ—è¡¨ - å¿…é¡»ä¸æ¨¡å‹è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
                self.feature_names = [
                    'C(%)', 'H(%)', 'O(%)', 'N(%)', 'Ash(%)', 'VM(%)', 'FC(%)', 
                    'PT(Â°C)', 'HR(â„ƒ/min)', 'RT(min)'
                ]
                log(f"ä½¿ç”¨é»˜è®¤ç‰¹å¾åˆ—è¡¨: {self.feature_names}")
            
            # 3. åŠ è½½æ¨¡å‹
            models_dir = os.path.join(self.model_dir, 'models')
            if os.path.exists(models_dir):
                model_files = sorted(glob.glob(os.path.join(models_dir, 'model_*.joblib')))
                if model_files:
                    for model_file in model_files:
                        model = joblib.load(model_file)
                        self.models.append(model)
                        log(f"åŠ è½½æ¨¡å‹: {os.path.basename(model_file)}")
                else:
                    log(f"é”™è¯¯: æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶åœ¨ {models_dir}")
                    st.error(f"é”™è¯¯: æœªæ‰¾åˆ°{self.target_name}æ¨¡å‹æ–‡ä»¶ã€‚è¯·æ£€æŸ¥åº”ç”¨å®‰è£…æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")
                    return False
            else:
                log(f"é”™è¯¯: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
                st.error(f"é”™è¯¯: {self.target_name}æ¨¡å‹ç›®å½•ä¸å­˜åœ¨ã€‚è¯·æ£€æŸ¥åº”ç”¨å®‰è£…æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")
                return False
            
            # 4. åŠ è½½æ¯ä¸ªå­æ¨¡å‹çš„æ ‡å‡†åŒ–å™¨ - è¿™æ˜¯å…³é”®ä¿®å¤ç‚¹
            scalers_dir = os.path.join(self.model_dir, 'scalers')
            if os.path.exists(scalers_dir):
                scaler_files = sorted(glob.glob(os.path.join(scalers_dir, 'scaler_*.joblib')))
                if scaler_files:
                    for scaler_file in scaler_files:
                        scaler = joblib.load(scaler_file)
                        self.scalers.append(scaler)
                        log(f"åŠ è½½å­æ¨¡å‹æ ‡å‡†åŒ–å™¨: {os.path.basename(scaler_file)}")
                else:
                    log(f"è­¦å‘Š: æœªæ‰¾åˆ°å­æ¨¡å‹æ ‡å‡†åŒ–å™¨æ–‡ä»¶åœ¨ {scalers_dir}")
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°æ ‡å‡†åŒ–å™¨ç›®å½•: {scalers_dir}")
            
            # 5. åŠ è½½æœ€ç»ˆæ ‡å‡†åŒ–å™¨ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
            final_scaler_path = os.path.join(self.model_dir, 'final_scaler.joblib')
            if os.path.exists(final_scaler_path):
                self.final_scaler = joblib.load(final_scaler_path)
                log(f"åŠ è½½æœ€ç»ˆæ ‡å‡†åŒ–å™¨: {final_scaler_path}")
                
                # æ‰“å°æ ‡å‡†åŒ–å™¨ä¿¡æ¯
                if hasattr(self.final_scaler, 'mean_'):
                    log(f"ç‰¹å¾å‡å€¼: {self.final_scaler.mean_}")
                if hasattr(self.final_scaler, 'scale_'):
                    log(f"ç‰¹å¾æ ‡å‡†å·®: {self.final_scaler.scale_}")
                
                # æå–è®­ç»ƒæ•°æ®èŒƒå›´
                self.extract_training_ranges()
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°æœ€ç»ˆæ ‡å‡†åŒ–å™¨æ–‡ä»¶ {final_scaler_path}")
            
            # 6. åŠ è½½æƒé‡
            weights_path = os.path.join(self.model_dir, 'model_weights.npy')
            if os.path.exists(weights_path):
                self.model_weights = np.load(weights_path)
                log(f"åŠ è½½æƒé‡æ–‡ä»¶: {weights_path}")
            else:
                # å¦‚æœæ²¡æœ‰æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨å‡ç­‰æƒé‡
                self.model_weights = np.ones(len(self.models)) / len(self.models)
                log("è­¦å‘Š: æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨å‡ç­‰æƒé‡")
            
            # 7. åŠ è½½ç‰¹å¾é‡è¦æ€§
            self.load_feature_importance()
            
            # éªŒè¯åŠ è½½çŠ¶æ€
            if len(self.models) > 0:
                log(f"æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹å’Œ {len(self.scalers)} ä¸ªå­æ¨¡å‹æ ‡å‡†åŒ–å™¨")
                self.model_loaded = True  # æ ‡è®°æ¨¡å‹åŠ è½½æˆåŠŸ
            else:
                log(f"é”™è¯¯: æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•{self.target_name}æ¨¡å‹")
                st.error(f"é”™è¯¯: æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•{self.target_name}æ¨¡å‹ã€‚è¯·æ£€æŸ¥åº”ç”¨å®‰è£…æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")
                return False
            
            # ç‰¹åˆ«æ ‡è®°æ ‡å‡†åŒ–å™¨é—®é¢˜
            if len(self.models) != len(self.scalers):
                log(f"è­¦å‘Š: æ¨¡å‹æ•°é‡ ({len(self.models)}) ä¸æ ‡å‡†åŒ–å™¨æ•°é‡ ({len(self.scalers)}) ä¸åŒ¹é…")
                
            return True
            
        except Exception as e:
            log(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            st.error(f"åŠ è½½{self.target_name}æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def check_input_range(self, input_df):
        """æ£€æŸ¥è¾“å…¥å€¼æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®èŒƒå›´å†…"""
        warnings = []
        
        if not self.training_ranges:
            log("è­¦å‘Š: æ²¡æœ‰è®­ç»ƒæ•°æ®èŒƒå›´ä¿¡æ¯ï¼Œè·³è¿‡èŒƒå›´æ£€æŸ¥")
            return warnings
        
        for feature, range_info in self.training_ranges.items():
            if feature in input_df.columns:
                value = input_df[feature].iloc[0]
                # æ£€æŸ¥æ˜¯å¦è¶…å‡ºè®­ç»ƒæ•°æ®çš„95%ç½®ä¿¡åŒºé—´
                if value < range_info['min'] or value > range_info['max']:
                    warning = f"{feature}: {value:.2f} (è¶…å‡ºè®­ç»ƒèŒƒå›´ {range_info['min']:.2f} - {range_info['max']:.2f})"
                    warnings.append(warning)
                    log(f"è­¦å‘Š: {warning}")
        
        return warnings
    
    def predict(self, input_features, return_individual=False):
        """ä½¿ç”¨æ¯ä¸ªå­æ¨¡å‹å¯¹åº”çš„æ ‡å‡†åŒ–å™¨è¿›è¡Œé¢„æµ‹"""
        try:
            # éªŒè¯æ¨¡å‹ç»„ä»¶
            if not self.model_loaded or not self.models or len(self.models) == 0:
                log(f"é”™è¯¯: æ²¡æœ‰åŠ è½½{self.target_name}æ¨¡å‹æˆ–æ¨¡å‹åŠ è½½å¤±è´¥")
                st.error(f"é”™è¯¯: {self.target_name}æ¨¡å‹æœªæ­£ç¡®åŠ è½½ã€‚è¯·æ£€æŸ¥åº”ç”¨å®‰è£…æˆ–è”ç³»ç®¡ç†å‘˜ã€‚")
                if return_individual:
                    return np.array([0.0]), []
                else:
                    return np.array([0.0])
            
            # ç¡®ä¿è¾“å…¥ç‰¹å¾åŒ…å«æ‰€æœ‰å¿…è¦ç‰¹å¾
            missing_features = []
            if self.feature_names:
                for feature in self.feature_names:
                    if feature not in input_features.columns:
                        missing_features.append(feature)
            
            if missing_features:
                missing_str = ", ".join(missing_features)
                log(f"é”™è¯¯: è¾“å…¥ç¼ºå°‘ä»¥ä¸‹ç‰¹å¾: {missing_str}")
                st.error(f"è¾“å…¥æ•°æ®ç¼ºå°‘ä»¥ä¸‹å¿…è¦ç‰¹å¾: {missing_str}")
                if return_individual:
                    return np.array([0.0]), []
                else:
                    return np.array([0.0])
            
            # æŒ‰ç…§æ¨¡å‹è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåºé‡æ–°æ’åˆ—
            if self.feature_names:
                input_ordered = input_features[self.feature_names].copy()
                log(f"{self.target_name}æ¨¡å‹: è¾“å…¥ç‰¹å¾å·²æŒ‰ç…§è®­ç»ƒæ—¶çš„é¡ºåºæ’åˆ—")
            else:
                input_ordered = input_features
                log(f"è­¦å‘Š: {self.target_name}æ¨¡å‹æ²¡æœ‰ç‰¹å¾åç§°åˆ—è¡¨ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥é¡ºåº")
            
            # è®°å½•è¾“å…¥æ•°æ®
            log(f"é¢„æµ‹è¾“å…¥æ•°æ®: {input_ordered.iloc[0].to_dict()}")
            
            # ä½¿ç”¨æ¯ä¸ªå­æ¨¡å‹å’Œå¯¹åº”çš„æ ‡å‡†åŒ–å™¨è¿›è¡Œé¢„æµ‹
            individual_predictions = []
            all_predictions = np.zeros((input_ordered.shape[0], len(self.models)))
            
            # æ£€æŸ¥æ ‡å‡†åŒ–å™¨æ˜¯å¦è¶³å¤Ÿ
            scalers_available = len(self.scalers) > 0
            
            for i, model in enumerate(self.models):
                try:
                    # ä½¿ç”¨å¯¹åº”çš„æ ‡å‡†åŒ–å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if scalers_available and i < len(self.scalers):
                        X_scaled = self.scalers[i].transform(input_ordered)
                        log(f"æ¨¡å‹ {i} ä½¿ç”¨å¯¹åº”çš„æ ‡å‡†åŒ–å™¨")
                    else:
                        # å¦‚æœæ²¡æœ‰å¯¹åº”çš„æ ‡å‡†åŒ–å™¨ï¼Œä½¿ç”¨æœ€ç»ˆæ ‡å‡†åŒ–å™¨
                        if self.final_scaler:
                            X_scaled = self.final_scaler.transform(input_ordered)
                            log(f"æ¨¡å‹ {i} ä½¿ç”¨æœ€ç»ˆæ ‡å‡†åŒ–å™¨")
                        else:
                            # å¦‚æœæ²¡æœ‰ä»»ä½•æ ‡å‡†åŒ–å™¨å¯ç”¨ï¼Œåˆ™ä½¿ç”¨åŸå§‹ç‰¹å¾
                            log(f"è­¦å‘Š: æ¨¡å‹ {i} æ²¡æœ‰å¯ç”¨çš„æ ‡å‡†åŒ–å™¨ï¼Œä½¿ç”¨åŸå§‹ç‰¹å¾")
                            X_scaled = input_ordered.values
                    
                    # æ‰§è¡Œé¢„æµ‹å¹¶ç¡®ä¿è¿”å›çš„æ˜¯æ ‡é‡å€¼ (ä¿®å¤ invalid index to scalar variable é”™è¯¯)
                    pred = model.predict(X_scaled)
                    # ç¡®ä¿é¢„æµ‹å€¼æ˜¯æ ‡é‡ï¼Œä¸æ˜¯æ•°ç»„
                    pred_value = float(pred[0]) if isinstance(pred, (np.ndarray, list)) else float(pred)
                    all_predictions[:, i] = pred_value
                    individual_predictions.append(pred_value)
                    log(f"æ¨¡å‹ {i} é¢„æµ‹ç»“æœ: {pred_value:.2f}")
                except Exception as e:
                    log(f"æ¨¡å‹ {i} é¢„æµ‹æ—¶å‡ºé”™: {str(e)}")
                    # å¦‚æœæŸä¸ªæ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨å…¶ä»–æ¨¡å‹çš„å¹³å‡å€¼
                    if i > 0:
                        avg_pred = np.mean(all_predictions[:, :i], axis=1)
                        avg_value = float(avg_pred[0]) if len(avg_pred) > 0 else 0.0
                        all_predictions[:, i] = avg_value
                        individual_predictions.append(avg_value)
                        log(f"æ¨¡å‹ {i} ä½¿ç”¨ä¹‹å‰æ¨¡å‹çš„å¹³å‡å€¼: {avg_value:.2f}")
            
            # è®¡ç®—åŠ æƒå¹³å‡ - ä¿®å¤ï¼šç¡®ä¿ä¸ä¼šå‡ºç°ç»´åº¦ä¸åŒ¹é…çš„é—®é¢˜
            if len(self.models) > 0:
                # ç¡®ä¿æƒé‡æ•°ç»„ç»´åº¦æ­£ç¡®
                weights = self.model_weights
                if weights.ndim == 1:
                    weights = weights.reshape(1, -1)
                
                # ç¡®ä¿æƒé‡å’Œé¢„æµ‹ç»´åº¦åŒ¹é…
                if weights.shape[1] != all_predictions.shape[1]:
                    log(f"è­¦å‘Š: æƒé‡ç»´åº¦ {weights.shape} ä¸é¢„æµ‹ç»´åº¦ {all_predictions.shape} ä¸åŒ¹é…ï¼Œä½¿ç”¨å¹³å‡å€¼")
                    weighted_pred = np.mean(all_predictions, axis=1)
                else:
                    # æ­£ç¡®è®¡ç®—åŠ æƒå¹³å‡
                    weighted_pred = np.sum(all_predictions * weights, axis=1)
                
                log(f"{self.target_name}æœ€ç»ˆåŠ æƒé¢„æµ‹ç»“æœ: {weighted_pred[0]:.2f}")
            else:
                weighted_pred = np.array([0.0])
                log(f"è­¦å‘Š: æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè¿”å›é»˜è®¤å€¼0")
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ - åŠ¨æ€è®¡ç®—RMSEå’ŒRÂ²
            std_dev = np.std(individual_predictions) if len(individual_predictions) > 0 else 0
            
            # ä¿®å¤ - ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œè®¡ç®—
            if len(individual_predictions) > 1:
                # åˆ›å»ºä¸€ä¸ªæ­£ç¡®çš„è¾“å…¥å‘é‡è¿›è¡ŒRMSEè®¡ç®—
                weighted_pred_reshaped = np.tile(weighted_pred.reshape(-1, 1), (1, all_predictions.shape[1]))
                rmse = np.sqrt(np.mean((all_predictions - weighted_pred_reshaped)**2))
                
                # è®¡ç®—RÂ² (é¿å…é™¤ä»¥é›¶é”™è¯¯)
                total_variance = np.sum((all_predictions - np.mean(all_predictions))**2)
                explained_variance = total_variance - np.sum((all_predictions - weighted_pred_reshaped)**2)
                r2 = explained_variance / total_variance if total_variance > 0 else 0
                
                log(f"é¢„æµ‹æ ‡å‡†å·®: {std_dev:.4f}")
                log(f"è®¡ç®—å¾—åˆ°RMSE: {float(rmse[0]) if isinstance(rmse, np.ndarray) else float(rmse):.4f}, RÂ²: {r2:.4f}")
                
                # å­˜å‚¨è¯„ä¼°æŒ‡æ ‡åˆ°session_state - ç¡®ä¿æ€§èƒ½æŒ‡æ ‡åŠ¨æ€æ›´æ–°
                st.session_state.current_rmse = float(rmse[0]) if isinstance(rmse, np.ndarray) else float(rmse)
                st.session_state.current_r2 = float(r2)
            else:
                log("è­¦å‘Š: æ²¡æœ‰è¶³å¤Ÿçš„æ¨¡å‹è¿›è¡Œæ€§èƒ½è¯„ä¼°")
                # è®¾ç½®é»˜è®¤å€¼ä»¥é¿å…åç»­æ˜¾ç¤ºé”™è¯¯
                st.session_state.current_rmse = 0.0
                st.session_state.current_r2 = 0.0
            
            if return_individual:
                return weighted_pred, individual_predictions
            else:
                return weighted_pred
            
        except Exception as e:
            log(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            # ä¿®å¤ - è¿”å›é»˜è®¤å€¼ï¼Œç¡®ä¿ç±»å‹ä¸€è‡´
            if return_individual:
                return np.array([0.0]), []
            else:
                return np.array([0.0])
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯æ‘˜è¦"""
        info = {
            "æ¨¡å‹ç±»å‹": "CatBoosté›†æˆæ¨¡å‹",
            "æ¨¡å‹æ•°é‡": len(self.models),
            "ç‰¹å¾æ•°é‡": len(self.feature_names) if self.feature_names else 0,
            "ç›®æ ‡å˜é‡": self.target_name,
            "æ¨¡å‹åŠ è½½çŠ¶æ€": "æˆåŠŸ" if self.model_loaded else "å¤±è´¥"
        }
        
        # æ·»åŠ æ€§èƒ½ä¿¡æ¯
        if self.metadata and 'performance' in self.metadata:
            performance = self.metadata['performance']
            info["æµ‹è¯•é›†RÂ²"] = f"{performance.get('test_r2', 'N/A'):.4f}"
            info["æµ‹è¯•é›†RMSE"] = f"{performance.get('test_rmse', 'N/A'):.2f}"
        
        # æ·»åŠ ç‰¹å¾é‡è¦æ€§ä¿¡æ¯
        if self.feature_importance is not None and len(self.feature_importance) > 0:
            top_features = self.feature_importance.head(3)
            info["é‡è¦ç‰¹å¾"] = ", ".join(top_features['Feature'].tolist())
        
        # æ·»åŠ æ ‡å‡†åŒ–å™¨ä¿¡æ¯
        info["å­æ¨¡å‹æ ‡å‡†åŒ–å™¨æ•°é‡"] = len(self.scalers)
        
        return info

# åˆå§‹åŒ–é¢„æµ‹å™¨ - ä½¿ç”¨å½“å‰é€‰æ‹©çš„æ¨¡å‹
predictor = CorrectedEnsemblePredictor(target_model=st.session_state.selected_model)

# åœ¨ä¾§è¾¹æ æ·»åŠ æ¨¡å‹ä¿¡æ¯
model_info = predictor.get_model_info()
model_info_html = "<div class='sidebar-model-info'><h3>å…³äºæ¨¡å‹</h3>"
for key, value in model_info.items():
    model_info_html += f"<p><b>{key}</b>: {value}</p>"

# æ ‡å‡†åŒ–å™¨çŠ¶æ€
model_info_html += "<h4>æ ‡å‡†åŒ–å™¨çŠ¶æ€</h4>"
if len(predictor.scalers) == len(predictor.models):
    model_info_html += f"<p style='color:green'>âœ… æ‰€æœ‰ {len(predictor.models)} ä¸ªå­æ¨¡å‹éƒ½ä½¿ç”¨äº†å¯¹åº”çš„æ ‡å‡†åŒ–å™¨</p>"
elif len(predictor.scalers) > 0:
    model_info_html += f"<p style='color:orange'>âš ï¸ æ‰¾åˆ° {len(predictor.scalers)}/{len(predictor.models)} ä¸ªå­æ¨¡å‹æ ‡å‡†åŒ–å™¨</p>"
else:
    model_info_html += "<p style='color:red'>âŒ æœªæ‰¾åˆ°å­æ¨¡å‹æ ‡å‡†åŒ–å™¨ï¼Œä½¿ç”¨æœ€ç»ˆæ ‡å‡†åŒ–å™¨</p>"

model_info_html += "</div>"
st.sidebar.markdown(model_info_html, unsafe_allow_html=True)

# æ€§èƒ½æŒ‡æ ‡æ˜¾ç¤ºåŒºåŸŸï¼ˆåœ¨é¢„æµ‹ååŠ¨æ€æ›´æ–°ï¼‰
performance_container = st.sidebar.container()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False
if 'prediction_result' not in st.session_state:
    st.session_state.prediction_result = None
if 'warnings' not in st.session_state:
    st.session_state.warnings = []
if 'individual_predictions' not in st.session_state:
    st.session_state.individual_predictions = []
if 'current_rmse' not in st.session_state:
    st.session_state.current_rmse = None
if 'current_r2' not in st.session_state:
    st.session_state.current_r2 = None
if 'prediction_error' not in st.session_state:
    st.session_state.prediction_error = None

# å®šä¹‰é»˜è®¤å€¼ - ä»ç”¨æˆ·æˆªå›¾ä¸­æå–
default_values = {
    "C(%)": 46.00,  # ä½¿ç”¨ä¸¤ä½å°æ•°ç²¾åº¦
    "H(%)": 5.50,
    "O(%)": 55.20,
    "N(%)": 0.60,
    "Ash(%)": 6.60,
    "VM(%)": 81.10,
    "FC(%)": 10.30,
    "PT(Â°C)": 500.00,  # ä½¿ç”¨å®é™…æµ‹è¯•å€¼
    "HR(â„ƒ/min)": 10.00,
    "RT(min)": 60.00
}

# ç‰¹å¾åˆ†ç±»
feature_categories = {
    "Ultimate Analysis": ["C(%)", "H(%)", "O(%)", "N(%)"],
    "Proximate Analysis": ["Ash(%)", "VM(%)", "FC(%)"],
    "Pyrolysis Conditions": ["PT(Â°C)", "HR(â„ƒ/min)", "RT(min)"]
}

# é¢œè‰²é…ç½®
category_colors = {
    "Ultimate Analysis": "#DAA520",  # é»„è‰²
    "Proximate Analysis": "#32CD32",  # ç»¿è‰²
    "Pyrolysis Conditions": "#FF7F50"  # æ©™è‰²
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# Ultimate Analysis - ç¬¬ä¸€åˆ—
with col1:
    category = "Ultimate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # å…³é”®ä¿®æ”¹: è®¾ç½®æ­¥é•¿ä¸º0.01ä»¥æ”¯æŒä¸¤ä½å°æ•°
            features[feature] = st.number_input(
                "", 
                min_value=0.00, 
                max_value=100.00, 
                value=float(value), 
                step=0.01,  # è®¾ç½®ä¸º0.01å…è®¸ä¸¤ä½å°æ•°è¾“å…¥
                key=f"{category}_{feature}", 
                format="%.2f",  # å¼ºåˆ¶æ˜¾ç¤ºä¸¤ä½å°æ•°
                label_visibility="collapsed"
            )
            
            # è°ƒè¯•æ˜¾ç¤º
            st.markdown(f"<span style='font-size:10px;color:gray;'>è¾“å…¥å€¼: {features[feature]:.2f}</span>", unsafe_allow_html=True)

# Proximate Analysis - ç¬¬äºŒåˆ—
with col2:
    category = "Proximate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # å…³é”®ä¿®æ”¹: è®¾ç½®æ­¥é•¿ä¸º0.01ä»¥æ”¯æŒä¸¤ä½å°æ•°
            features[feature] = st.number_input(
                "", 
                min_value=0.00, 
                max_value=100.00, 
                value=float(value), 
                step=0.01,  # è®¾ç½®ä¸º0.01å…è®¸ä¸¤ä½å°æ•°è¾“å…¥
                key=f"{category}_{feature}", 
                format="%.2f",  # å¼ºåˆ¶æ˜¾ç¤ºä¸¤ä½å°æ•°
                label_visibility="collapsed"
            )
            
            # è°ƒè¯•æ˜¾ç¤º
            st.markdown(f"<span style='font-size:10px;color:gray;'>è¾“å…¥å€¼: {features[feature]:.2f}</span>", unsafe_allow_html=True)

# Pyrolysis Conditions - ç¬¬ä¸‰åˆ—
with col3:
    category = "Pyrolysis Conditions"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        # æ ¹æ®ç‰¹å¾è®¾ç½®èŒƒå›´
        if feature == "PT(Â°C)":
            min_val, max_val = 200.00, 900.00
        elif feature == "HR(â„ƒ/min)":
            min_val, max_val = 1.00, 100.00
        elif feature == "RT(min)":
            min_val, max_val = 0.00, 120.00
        else:
            min_val, max_val = 0.00, 100.00
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # å…³é”®ä¿®æ”¹: è®¾ç½®æ­¥é•¿ä¸º0.01ä»¥æ”¯æŒä¸¤ä½å°æ•°
            features[feature] = st.number_input(
                "", 
                min_value=float(min_val), 
                max_value=float(max_val), 
                value=float(value), 
                step=0.01,  # è®¾ç½®ä¸º0.01å…è®¸ä¸¤ä½å°æ•°è¾“å…¥
                key=f"{category}_{feature}", 
                format="%.2f",  # å¼ºåˆ¶æ˜¾ç¤ºä¸¤ä½å°æ•°
                label_visibility="collapsed"
            )
            
            # è°ƒè¯•æ˜¾ç¤º
            st.markdown(f"<span style='font-size:10px;color:gray;'>è¾“å…¥å€¼: {features[feature]:.2f}</span>", unsafe_allow_html=True)

# é‡ç½®çŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.clear_pressed = False

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
result_container = st.container()

# é¢„æµ‹æŒ‰é’®åŒºåŸŸ
col1, col2 = st.columns([1, 1])

with col1:
    if st.button("ğŸ”® è¿è¡Œé¢„æµ‹", use_container_width=True, type="primary"):
        log(f"å¼€å§‹{st.session_state.selected_model}é¢„æµ‹")
        st.session_state.predictions_running = True
        st.session_state.prediction_error = None  # æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
        
        # è®°å½•è¾“å…¥
        log(f"è¾“å…¥ç‰¹å¾: {features}")
        
        # åˆ›å»ºè¾“å…¥æ•°æ®æ¡†
        input_df = pd.DataFrame([features])
        
        # æ£€æŸ¥è¾“å…¥èŒƒå›´
        warnings = predictor.check_input_range(input_df)
        st.session_state.warnings = warnings
        
        # æ‰§è¡Œé¢„æµ‹
        try:
            result, individual_preds = predictor.predict(input_df, return_individual=True)
            # ç¡®ä¿ç»“æœä¸ä¸ºç©ºï¼Œä¿®å¤é¢„æµ‹å€¼ä¸æ˜¾ç¤ºçš„é—®é¢˜
            if result is not None and len(result) > 0:
                st.session_state.prediction_result = float(result[0])
                st.session_state.individual_predictions = individual_preds
                log(f"é¢„æµ‹æˆåŠŸ: {st.session_state.prediction_result:.2f}")
                
                # è®¡ç®—æ ‡å‡†å·®ä½œä¸ºä¸ç¡®å®šæ€§æŒ‡æ ‡
                std_dev = np.std(individual_preds) if individual_preds else 0
                log(f"é¢„æµ‹æ ‡å‡†å·®: {std_dev:.4f}")
            else:
                log("è­¦å‘Š: é¢„æµ‹ç»“æœä¸ºç©º")
                st.session_state.prediction_result = 0.0
                st.session_state.individual_predictions = []
            
        except Exception as e:
            st.session_state.prediction_error = str(e)
            log(f"é¢„æµ‹é”™è¯¯: {str(e)}")
            log(traceback.format_exc())
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        st.session_state.predictions_running = False
        st.rerun()

with col2:
    if st.button("ğŸ”„ é‡ç½®è¾“å…¥", use_container_width=True):
        log("é‡ç½®æ‰€æœ‰è¾“å…¥å€¼")
        st.session_state.clear_pressed = True
        st.session_state.prediction_result = None
        st.session_state.warnings = []
        st.session_state.individual_predictions = []
        st.session_state.prediction_error = None
        st.rerun()

# æ˜¾ç¤ºé¢„æµ‹ç»“æœ
if st.session_state.prediction_result is not None:
    st.markdown("---")
    
    # æ˜¾ç¤ºä¸»é¢„æµ‹ç»“æœ
    result_container.markdown(f"<div class='yield-result'>{st.session_state.selected_model}: {st.session_state.prediction_result:.2f}%</div>", unsafe_allow_html=True)
    
    # æ˜¾ç¤ºè­¦å‘Š
    if st.session_state.warnings:
        warnings_html = "<div class='warning-box'><b>âš ï¸ è­¦å‘Šï¼šéƒ¨åˆ†è¾“å…¥è¶…å‡ºè®­ç»ƒèŒƒå›´</b><ul>"
        for warning in st.session_state.warnings:
            warnings_html += f"<li>{warning}</li>"
        warnings_html += "</ul><p>é¢„æµ‹ç»“æœå¯èƒ½ä¸å¤ªå¯é ã€‚</p></div>"
        result_container.markdown(warnings_html, unsafe_allow_html=True)
    
    # æ ‡å‡†åŒ–å™¨çŠ¶æ€
    if len(predictor.scalers) < len(predictor.models):
        result_container.markdown(
            "<div class='warning-box'><b>âš ï¸ æ³¨æ„ï¼š</b> éƒ¨åˆ†æ¨¡å‹ä½¿ç”¨äº†æœ€ç»ˆæ ‡å‡†åŒ–å™¨è€Œéå…¶å¯¹åº”çš„å­æ¨¡å‹æ ‡å‡†åŒ–å™¨ï¼Œè¿™å¯èƒ½å½±å“é¢„æµ‹ç²¾åº¦ã€‚</div>", 
            unsafe_allow_html=True
        )
    
    # æŠ€æœ¯è¯´æ˜éƒ¨åˆ† - ä½¿ç”¨æŠ˜å å¼å±•ç¤º
    with st.expander("æŠ€æœ¯è¯´æ˜"):
        st.markdown("""
        <div class='tech-info'>
        <p>æœ¬æ¨¡å‹åŸºäºå¤šä¸ªCatBoostæ¨¡å‹é›†æˆåˆ›å»ºï¼Œé¢„æµ‹ç”Ÿç‰©è´¨çƒ­è§£äº§ç‰©åˆ†å¸ƒã€‚æ¨¡å‹ä½¿ç”¨ç”Ÿç‰©è´¨çš„å…ƒç´ åˆ†æã€è¿‘ä¼¼åˆ†ææ•°æ®å’Œçƒ­è§£æ¡ä»¶ä½œä¸ºè¾“å…¥ï¼Œè®¡ç®—çƒ­è§£ç‚­ã€çƒ­è§£æ²¹å’Œçƒ­è§£æ°”ä½“äº§é‡ã€‚</p>
        
        <p><b>ç‰¹åˆ«æé†’ï¼š</b></p>
        <ul>
            <li>è¾“å…¥å‚æ•°åº”è¯¥æ»¡è¶³è®¾å®šå¥½çš„èŒƒå›´å†…ï¼Œå› ä¸ºè¿™æ ·ç¬¦åˆæ¨¡å‹è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒèŒƒå›´ï¼Œå¯ä»¥ä¿è¯è½¯ä»¶çš„é¢„æµ‹ç²¾åº¦ï¼Œå¦‚æœè¶…è¿‡èŒƒå›´ï¼Œä¼šæœ‰æ–‡å­—æé†’</li>
            <li>ç”±äºæ¨¡å‹è®­ç»ƒæ—¶FC(%)é€šè¿‡100-Ash(%)-VM(%)å…¬å¼è½¬æ¢å¾—å‡ºï¼Œæ‰€ä»¥ç”¨æˆ·ä½¿ç”¨æ­¤è½¯ä»¶è¿›è¡Œé¢„æµ‹æ—¶ä¹Ÿéœ€è¦ä½¿ç”¨100-Ash(%)-VM(%)å…¬å¼å¯¹FC(%)è¿›è¡Œè½¬æ¢ï¼Œä»¥ä¿è¯é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

# æ·»åŠ é¡µè„š
st.markdown("---")
footer = """
<div style='text-align: center;'>
<p>Â© 2023 ç”Ÿç‰©è´¨çº³ç±³ææ–™ä¸æ™ºèƒ½è£…å¤‡å®éªŒå®¤å›¢é˜Ÿ. ç‰ˆæœ¬: 2.3.0</p>
</div>
"""
st.markdown(footer, unsafe_allow_html=True)
