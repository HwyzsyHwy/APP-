# -*- coding: utf-8 -*-
"""
Biomass Pyrolysis Yield Forecast using CatBoost Ensemble Models
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import glob
import joblib
import json
from io import StringIO

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title='Biomass Pyrolysis Yield Forecast',
    page_icon='ğŸ“Š',
    layout='wide'
)

# å¢åŠ æœç´¢æ¨¡å‹æ–‡ä»¶çš„åŠŸèƒ½
def find_model_files():
    """
    æœç´¢ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶å’Œsimple_predictor.py
    """
    # æœç´¢å½“å‰ç›®å½•åŠå­ç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶
    model_files = glob.glob("**/model_*.joblib", recursive=True)
    scaler_files = glob.glob("**/final_scaler.joblib", recursive=True)
    predictor_files = glob.glob("**/simple_predictor.py", recursive=True)
    
    return {
        "model_files": model_files,
        "scaler_files": scaler_files,
        "predictor_files": predictor_files
    }

# å®šä¹‰å†…åµŒçš„ç®€å•é¢„æµ‹å™¨ç±»
class EmbeddedPredictor:
    """
    å†…åµŒçš„ç®€å•é¢„æµ‹å™¨ç±»ï¼Œå®ç°CatBoosté›†æˆæ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½
    """
    def __init__(self):
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_info = find_model_files()
        st.sidebar.write("æ¨¡å‹æ–‡ä»¶æœç´¢ç»“æœ:", model_info)
        
        # æ¨¡å‹å’Œç¼©æ”¾å™¨è·¯å¾„
        self.model_paths = model_info["model_files"]
        self.scaler_paths = model_info["scaler_files"]
        
        # åˆå§‹åŒ–
        self.models = []
        self.final_scaler = None
        self.model_weights = None
        self.feature_names = ["PT(Â°C)", "RT(min)", "HR(â„ƒ/min)", "C(%)", "H(%)", "O(%)", "N(%)", "Ash(%)", "VM(%)", "FC(%)"]
        
        # å°è¯•åŠ è½½æ¨¡å‹
        self._load_components()
    
    def _load_components(self):
        """åŠ è½½æ¨¡å‹ç»„ä»¶"""
        try:
            # å°è¯•åŠ è½½æ¨¡å‹æ–‡ä»¶
            if self.model_paths:
                models_dir = os.path.dirname(self.model_paths[0])
                st.sidebar.success(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶å¤¹: {models_dir}")
                
                # åŠ è½½æ¨¡å‹
                for model_path in sorted(self.model_paths):
                    st.sidebar.write(f"åŠ è½½æ¨¡å‹: {model_path}")
                    self.models.append(joblib.load(model_path))
                
                # åŠ è½½ç¼©æ”¾å™¨
                if self.scaler_paths:
                    st.sidebar.write(f"åŠ è½½ç¼©æ”¾å™¨: {self.scaler_paths[0]}")
                    self.final_scaler = joblib.load(self.scaler_paths[0])
                
                # åŠ è½½æƒé‡
                weights_path = os.path.join(models_dir, "model_weights.npy")
                if os.path.exists(weights_path):
                    st.sidebar.write(f"åŠ è½½æƒé‡: {weights_path}")
                    self.model_weights = np.load(weights_path)
                else:
                    # å¦‚æœæ²¡æœ‰æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨å‡ç­‰æƒé‡
                    self.model_weights = np.ones(len(self.models)) / len(self.models)
                
                # åŠ è½½å…ƒæ•°æ®
                metadata_path = os.path.join(models_dir, "metadata.json")
                if os.path.exists(metadata_path):
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                        if 'feature_names' in metadata:
                            self.feature_names = metadata['feature_names']
                            st.sidebar.write("ä»å…ƒæ•°æ®åŠ è½½ç‰¹å¾åç§°")
                
                st.sidebar.success(f"æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹")
                return True
            else:
                st.sidebar.warning("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
                return False
        except Exception as e:
            st.sidebar.error(f"åŠ è½½æ¨¡å‹ç»„ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def predict(self, X):
        """
        ä½¿ç”¨é›†æˆæ¨¡å‹è¿›è¡Œé¢„æµ‹
        """
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯DataFrame
            if not isinstance(X, pd.DataFrame):
                X = pd.DataFrame(X)
            
            # è°ƒè¯•ä¿¡æ¯
            st.sidebar.write("è¾“å…¥ç‰¹å¾:", X.columns.tolist())
            st.sidebar.write("æ¨¡å‹ç‰¹å¾:", self.feature_names)
            
            # æ£€æŸ¥ç‰¹å¾æ˜¯å¦éœ€è¦é‡å‘½å
            if not set(self.feature_names).issubset(set(X.columns)):
                # å°è¯•æ˜ å°„ç‰¹å¾å
                mapped_features = {}
                for model_feat in self.feature_names:
                    for input_feat in X.columns:
                        # ç§»é™¤å•ä½éƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒ
                        model_base = model_feat.split('(')[0] if '(' in model_feat else model_feat
                        input_base = input_feat.split('(')[0] if '(' in input_feat else input_feat
                        
                        if model_base == input_base:
                            mapped_features[input_feat] = model_feat
                            break
                
                if len(mapped_features) == len(X.columns):
                    X = X.rename(columns=mapped_features)
                    st.sidebar.success("ç‰¹å¾åç§°å·²é‡æ˜ å°„")
                    st.sidebar.write("æ˜ å°„å…³ç³»:", mapped_features)
            
            # ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®
            if not all(feat in X.columns for feat in self.feature_names):
                missing = set(self.feature_names) - set(X.columns)
                st.sidebar.error(f"ç¼ºå°‘ç‰¹å¾: {missing}")
                return np.array([33.0])  # è¿”å›é»˜è®¤å€¼
            
            # æŒ‰æ¨¡å‹éœ€è¦çš„é¡ºåºæå–ç‰¹å¾
            X = X[self.feature_names]
            
            # å¦‚æœæœ‰ç¼©æ”¾å™¨ï¼Œåº”ç”¨æ ‡å‡†åŒ–
            if self.final_scaler:
                X_scaled = self.final_scaler.transform(X)
                st.sidebar.success("æ•°æ®å·²æ ‡å‡†åŒ–")
            else:
                X_scaled = X.values
                st.sidebar.warning("æ²¡æœ‰æ ‡å‡†åŒ–å™¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            
            # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹è¿›è¡Œé¢„æµ‹
            if self.models:
                all_predictions = np.zeros((X.shape[0], len(self.models)))
                for i, model in enumerate(self.models):
                    pred = model.predict(X_scaled)
                    all_predictions[:, i] = pred
                    st.sidebar.write(f"æ¨¡å‹ {i} é¢„æµ‹å€¼: {pred[0]:.2f}")
                
                # è®¡ç®—åŠ æƒå¹³å‡
                weighted_pred = np.sum(all_predictions * self.model_weights.reshape(1, -1), axis=1)
                st.sidebar.success(f"æœ€ç»ˆåŠ æƒé¢„æµ‹å€¼: {weighted_pred[0]:.2f}")
                return weighted_pred
            else:
                # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œè¿”å›åŸºäºè§„åˆ™çš„ä¼°è®¡
                st.sidebar.warning("æ— å¯ç”¨æ¨¡å‹ï¼Œä½¿ç”¨ç®€å•ä¼°è®¡")
                return self._simple_estimate(X)
        except Exception as e:
            st.sidebar.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            st.sidebar.error(traceback.format_exc())
            return np.array([33.0])  # è¿”å›é»˜è®¤å€¼
    
    def _simple_estimate(self, X):
        """ç®€å•ä¼°è®¡ï¼Œåœ¨æ²¡æœ‰æ¨¡å‹æ—¶ä½¿ç”¨"""
        # æå–å…³é”®ç‰¹å¾
        pt = X["PT(Â°C)"].values[0] if "PT(Â°C)" in X.columns else 500
        rt = X["RT(min)"].values[0] if "RT(min)" in X.columns else 20
        
        # åŸºäºæ¸©åº¦å’Œåœç•™æ—¶é—´çš„ç®€å•ä¼°è®¡
        base_yield = 40.0
        temp_effect = -0.03 * (pt - 500)  # é«˜æ¸©é™ä½äº§ç‡
        time_effect = 0.1 * (rt - 20)     # æ›´é•¿æ—¶é—´å¢åŠ äº§ç‡
        
        estimated_yield = base_yield + temp_effect + time_effect
        estimated_yield = max(20, min(80, estimated_yield))  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        
        return np.array([estimated_yield])

# å°è¯•æŸ¥æ‰¾simple_predictoræ¨¡å—
found_predictor = False
predictor_files = glob.glob("**/simple_predictor.py", recursive=True)

if predictor_files:
    # æ‰¾åˆ°äº†predictoræ–‡ä»¶
    predictor_path = predictor_files[0]
    predictor_dir = os.path.dirname(os.path.abspath(predictor_path))
    
    # æ·»åŠ ç›®å½•åˆ°sys.path
    if predictor_dir not in sys.path:
        sys.path.append(predictor_dir)
    
    st.sidebar.success(f"æ‰¾åˆ°predictoræ–‡ä»¶: {predictor_path}")
    st.sidebar.write(f"æ·»åŠ ç›®å½•åˆ°sys.path: {predictor_dir}")
    
    # å°è¯•å¯¼å…¥
    try:
        import simple_predictor
        from simple_predictor import Char_YieldPredictor
        predictor = Char_YieldPredictor()
        found_predictor = True
        st.sidebar.success("æˆåŠŸå¯¼å…¥å¹¶å®ä¾‹åŒ–Char_YieldPredictor")
    except Exception as e:
        st.sidebar.error(f"å¯¼å…¥simple_predictorå¤±è´¥: {str(e)}")
        # å¤±è´¥åå°è¯•ä½¿ç”¨å†…åµŒé¢„æµ‹å™¨
        predictor = EmbeddedPredictor()
else:
    st.sidebar.warning("æœªæ‰¾åˆ°simple_predictor.pyæ–‡ä»¶")
    # ä½¿ç”¨å†…åµŒé¢„æµ‹å™¨
    predictor = EmbeddedPredictor()

# è‡ªå®šä¹‰æ ·å¼
st.markdown(
    """
    <style>
    /* å…¨å±€å­—ä½“è®¾ç½® */
    html, body, [class*="css"] {
        font-size: 16px !important;
    }
    
    /* æ ‡é¢˜ */
    .main-title {
        text-align: center;
        font-size: 32px !important;
        font-weight: bold;
        margin-bottom: 20px;
        color: white !important;
    }
    
    /* åŒºåŸŸæ ·å¼ */
    .section-header {
        color: white;
        font-weight: bold;
        font-size: 22px;
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 5px;
        border-radius: 5px;
        margin-bottom: 5px;
        font-size: 18px;
        color: white;
    }
    
    /* ç»“æœæ˜¾ç¤ºæ ·å¼ */
    .yield-result {
        background-color: #1E1E1E;
        color: white;
        font-size: 36px;
        font-weight: bold;
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    
    /* å¼ºåˆ¶åº”ç”¨ç™½è‰²èƒŒæ™¯åˆ°è¾“å…¥æ¡† */
    [data-testid="stNumberInput"] input {
        background-color: white !important;
        color: black !important;
    }
    
    /* å¢å¤§æŒ‰é’®çš„å­—ä½“ */
    .stButton button {
        font-size: 18px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ä¸»æ ‡é¢˜
st.markdown("<h1 class='main-title'>Prediction of crop biomass pyrolysis yield based on CatBoost ensemble modeling</h1>", unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False

# å®šä¹‰é»˜è®¤å€¼å’ŒèŒƒå›´
default_values = {
    "PT(Â°C)": 500.0,
    "RT(min)": 20.0,
    "C(%)": 45.0,
    "H(%)": 6.0,
    "O(%)": 40.0,
    "N(%)": 0.5,
    "Ash(%)": 5.0,
    "VM(%)": 75.0,
    "FC(%)": 15.0,
    "HR(â„ƒ/min)": 20.0
}

# ç‰¹å¾åˆ†ç±»
feature_categories = {
    "Pyrolysis Conditions": ["PT(Â°C)", "RT(min)", "HR(â„ƒ/min)"],
    "Ultimate Analysis": ["C(%)", "H(%)", "O(%)", "N(%)"],
    "Proximate Analysis": ["Ash(%)", "VM(%)", "FC(%)"]
}

# ç‰¹å¾èŒƒå›´
feature_ranges = {
    "PT(Â°C)": (300.0, 900.0),
    "RT(min)": (5.0, 120.0),
    "C(%)": (30.0, 80.0),
    "H(%)": (3.0, 10.0),
    "O(%)": (10.0, 60.0),
    "N(%)": (0.0, 5.0),
    "Ash(%)": (0.0, 25.0),
    "VM(%)": (40.0, 95.0),
    "FC(%)": (5.0, 40.0),
    "HR(â„ƒ/min)": (5.0, 100.0)
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸æ¥å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# Pyrolysis Conditions (æ©™è‰²åŒºåŸŸ)
with col1:
    st.markdown("<div class='section-header' style='background-color: #FF7F50;'>Pyrolysis Conditions</div>", unsafe_allow_html=True)
    
    for feature in feature_categories["Pyrolysis Conditions"]:
        # é‡ç½®å€¼æˆ–ä½¿ç”¨ç°æœ‰å€¼
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"pyrolysis_{feature}", default_values[feature])
        
        # è·å–è¯¥ç‰¹å¾çš„èŒƒå›´
        min_val, max_val = feature_ranges[feature]
        
        # ç®€å•çš„ä¸¤åˆ—å¸ƒå±€
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: #FF7F50;'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"pyrolysis_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# Ultimate Analysis (é»„è‰²åŒºåŸŸ)
with col2:
    st.markdown("<div class='section-header' style='background-color: #DAA520;'>Ultimate Analysis</div>", unsafe_allow_html=True)
    
    for feature in feature_categories["Ultimate Analysis"]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"ultimate_{feature}", default_values[feature])
        
        min_val, max_val = feature_ranges[feature]
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: #DAA520;'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"ultimate_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# Proximate Analysis (ç»¿è‰²åŒºåŸŸ)
with col3:
    st.markdown("<div class='section-header' style='background-color: #32CD32;'>Proximate Analysis</div>", unsafe_allow_html=True)
    
    for feature in feature_categories["Proximate Analysis"]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"proximate_{feature}", default_values[feature])
        
        min_val, max_val = feature_ranges[feature]
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: #32CD32;'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"proximate_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# é‡ç½®session_stateä¸­çš„clear_pressedçŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.clear_pressed = False

# è½¬æ¢ä¸ºDataFrame
input_data = pd.DataFrame([features])

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸå’ŒæŒ‰é’®
result_col, button_col = st.columns([3, 1])

with result_col:
    prediction_placeholder = st.empty()
    
with button_col:
    predict_button = st.button("PUSH", key="predict")
    
    # å®šä¹‰ClearæŒ‰é’®çš„å›è°ƒå‡½æ•°
    def clear_values():
        st.session_state.clear_pressed = True
        # æ¸…é™¤æ˜¾ç¤º
        if 'prediction_result' in st.session_state:
            st.session_state.prediction_result = None
    
    clear_button = st.button("CLEAR", key="clear", on_click=clear_values)

# å¤„ç†é¢„æµ‹é€»è¾‘
if predict_button:
    try:
        # ä½¿ç”¨predictorè¿›è¡Œé¢„æµ‹
        y_pred = predictor.predict(input_data)[0]
        
        # ä¿å­˜é¢„æµ‹ç»“æœåˆ°session_state
        st.session_state.prediction_result = y_pred

        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        prediction_placeholder.markdown(
            f"<div class='yield-result'>Char Yield (wt%) <br> {y_pred:.2f}</div>",
            unsafe_allow_html=True
        )
    except Exception as e:
        st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        st.error(traceback.format_exc())

# å¦‚æœæœ‰ä¿å­˜çš„é¢„æµ‹ç»“æœï¼Œæ˜¾ç¤ºå®ƒ
if 'prediction_result' in st.session_state and st.session_state.prediction_result is not None:
    prediction_placeholder.markdown(
        f"<div class='yield-result'>Char Yield (wt%) <br> {st.session_state.prediction_result:.2f}</div>",
        unsafe_allow_html=True
    )

# æ·»åŠ è°ƒè¯•ä¿¡æ¯
with st.expander("Debug Information", expanded=False):
    st.write("Input Features:")
    st.write(input_data)
    
    if hasattr(predictor, 'feature_names'):
        st.write("Model Features:")
        st.write(predictor.feature_names)

# æ·»åŠ å…³äºæ¨¡å‹çš„ä¿¡æ¯
st.markdown("""
### About the Model
This application uses a CatBoost ensemble model to predict char yield in biomass pyrolysis.

#### Key Factors Affecting Char Yield:
- **Pyrolysis Temperature**: Higher temperature generally decreases char yield
- **Residence Time**: Longer residence time generally increases char yield
- **Biomass Composition**: Carbon content and ash content significantly affect the final yield

The model was trained using 10-fold cross-validation with optimized hyperparameters, achieving high prediction accuracy.
""")