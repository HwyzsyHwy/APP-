# -*- coding: utf-8 -*-
"""
Biomass Pyrolysis Yield Forecast using CatBoost Ensemble Models
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import glob
import joblib
import json
import traceback
import logging

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Pyrolysis_App")

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title='Biomass Pyrolysis Yield Forecast',
    page_icon='ğŸ”¥',
    layout='wide'
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown(
    """
    <style>
    /* å…¨å±€å­—ä½“è®¾ç½® */
    html, body, [class*="css"] {
        font-size: 16px !important;
    }
    
    /* æ ‡é¢˜ */
    .main-title {
        text-align: center;
        font-size: 32px !important;
        font-weight: bold;
        margin-bottom: 20px;
        color: white !important;
    }
    
    /* åŒºåŸŸæ ·å¼ */
    .section-header {
        color: white;
        font-weight: bold;
        font-size: 22px;
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 5px;
        border-radius: 5px;
        margin-bottom: 5px;
        font-size: 18px;
        color: white;
    }
    
    /* ç»“æœæ˜¾ç¤ºæ ·å¼ */
    .yield-result {
        background-color: #1E1E1E;
        color: white;
        font-size: 36px;
        font-weight: bold;
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    
    /* å¼ºåˆ¶åº”ç”¨ç™½è‰²èƒŒæ™¯åˆ°è¾“å…¥æ¡† */
    [data-testid="stNumberInput"] input {
        background-color: white !important;
        color: black !important;
    }
    
    /* å¢å¤§æŒ‰é’®çš„å­—ä½“ */
    .stButton button {
        font-size: 18px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ä¸»æ ‡é¢˜
st.markdown("<h1 class='main-title'>Prediction of crop biomass pyrolysis yield based on CatBoost ensemble modeling</h1>", unsafe_allow_html=True)

# åˆ›å»ºä¾§è¾¹æ æ—¥å¿—åŒºåŸŸ
log_container = st.sidebar.container()
log_container.write("### è°ƒè¯•æ—¥å¿—")

def log(message):
    """è®°å½•è°ƒè¯•ä¿¡æ¯åˆ°ä¾§è¾¹æ å’Œæ—¥å¿—ç³»ç»Ÿ"""
    log_container.write(message)
    logger.info(message)

class EnsembleModelPredictor:
    """
    é›†æˆæ¨¡å‹é¢„æµ‹å™¨ - è´Ÿè´£åŠ è½½å’Œä½¿ç”¨CatBoosté›†æˆæ¨¡å‹è¿›è¡Œé¢„æµ‹
    """
    def __init__(self):
        # åˆå§‹åŒ–æ—¶ä¸è®¾ç½®ç‰¹å¾åˆ—è¡¨ï¼Œè€Œæ˜¯ä»å…ƒæ•°æ®ä¸­è·å–
        self.models = []
        self.model_weights = None
        self.final_scaler = None
        self.feature_names = None
        self.metadata = None
        self.model_dir = None
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶
        self.load_model_components()
    
    def find_model_directory(self):
        """
        æŸ¥æ‰¾æ¨¡å‹ç›®å½•çš„å¤šç§æ–¹æ³•
        """
        # å¯èƒ½çš„æ¨¡å‹ç›®å½•è·¯å¾„
        possible_dirs = [
            "Char_Yield_Model",
            "models/Char_Yield_Model",
            "../Char_Yield_Model",
            "../../Char_Yield_Model",
            "./Char_Yield_Model",
            os.path.join(os.getcwd(), "Char_Yield_Model"),
            "C:/Users/HWY/Desktop/æ–¹-3/Char_Yield_Model"
        ]
        
        # é¦–å…ˆå°è¯•ç›´æ¥å®šä½æ¨¡å‹ç›®å½•
        for dir_path in possible_dirs:
            if os.path.exists(dir_path) and os.path.isdir(dir_path):
                log(f"æ‰¾åˆ°æ¨¡å‹ç›®å½•: {dir_path}")
                return os.path.abspath(dir_path)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•åŸºäºæ¨¡å‹æ–‡ä»¶æ¨æ–­
        model_files = glob.glob("**/model_*.joblib", recursive=True)
        if model_files:
            # å–ç¬¬ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶æ‰€åœ¨çš„ä¸Šä¸¤çº§ç›®å½•
            model_dir = os.path.dirname(os.path.dirname(model_files[0]))
            log(f"åŸºäºæ¨¡å‹æ–‡ä»¶æ¨æ–­æ¨¡å‹ç›®å½•: {model_dir}")
            return model_dir
        
        # å¦‚æœæ‰¾ä¸åˆ°æ¨¡å‹ç›®å½•ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›å½“å‰ç›®å½•
        log("è­¦å‘Š: æ— æ³•æ‰¾åˆ°æ¨¡å‹ç›®å½•ï¼Œå°†ä½¿ç”¨å½“å‰ç›®å½•")
        return os.getcwd()
    
    def load_model_components(self):
        """åŠ è½½æ¨¡å‹çš„æ‰€æœ‰ç»„ä»¶"""
        try:
            # 1. æŸ¥æ‰¾æ¨¡å‹ç›®å½•
            self.model_dir = self.find_model_directory()
            log(f"ä½¿ç”¨æ¨¡å‹ç›®å½•: {self.model_dir}")
            
            # 2. åŠ è½½å…ƒæ•°æ® - è¿™ä¸€æ­¥éå¸¸é‡è¦ï¼ŒåŒ…å«äº†ç‰¹å¾åç§°
            metadata_path = os.path.join(self.model_dir, 'metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    self.metadata = json.load(f)
                
                # ä»å…ƒæ•°æ®ä¸­è·å–ç‰¹å¾åç§° - è¿™æ˜¯ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®çš„å…³é”®
                self.feature_names = self.metadata.get('feature_names', None)
                log(f"ä»å…ƒæ•°æ®åŠ è½½ç‰¹å¾åˆ—è¡¨: {self.feature_names}")
                
                if not self.feature_names:
                    log("è­¦å‘Š: å…ƒæ•°æ®ä¸­æ²¡æœ‰ç‰¹å¾åˆ—è¡¨")
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶: {metadata_path}")
                # ä½¿ç”¨é»˜è®¤ç‰¹å¾åˆ—è¡¨ - è¿™å¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
                self.feature_names = [
                    'PT(Â°C)', 'RT(min)', 'HT(Â°C/min)', 
                    'C(%)', 'H(%)', 'O(%)', 'N(%)',
                    'Ash(%)', 'VM(%)', 'FC(%)'
                ]
                log(f"ä½¿ç”¨é»˜è®¤ç‰¹å¾åˆ—è¡¨: {self.feature_names}")
            
            # 3. åŠ è½½æ¨¡å‹æ–‡ä»¶
            models_dir = os.path.join(self.model_dir, 'models')
            if os.path.exists(models_dir):
                model_files = sorted(glob.glob(os.path.join(models_dir, 'model_*.joblib')))
                if not model_files:
                    log(f"æœªåœ¨ {models_dir} ä¸­æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
                    return False
                
                # æŒ‰é¡ºåºåŠ è½½æ‰€æœ‰æ¨¡å‹
                for model_file in model_files:
                    try:
                        model = joblib.load(model_file)
                        self.models.append(model)
                        log(f"åŠ è½½æ¨¡å‹: {os.path.basename(model_file)}")
                    except Exception as e:
                        log(f"åŠ è½½æ¨¡å‹ {model_file} æ—¶å‡ºé”™: {str(e)}")
            else:
                log(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
                return False
            
            # 4. åŠ è½½æƒé‡æ–‡ä»¶
            weights_path = os.path.join(self.model_dir, 'model_weights.npy')
            if os.path.exists(weights_path):
                self.model_weights = np.load(weights_path)
                log(f"åŠ è½½æƒé‡æ–‡ä»¶: {weights_path}")
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶: {weights_path}")
                # å¦‚æœæ‰¾ä¸åˆ°æƒé‡ï¼Œä½¿ç”¨å‡ç­‰æƒé‡
                self.model_weights = np.ones(len(self.models)) / len(self.models)
                log("ä½¿ç”¨å‡ç­‰æƒé‡")
            
            # 5. åŠ è½½æ ‡å‡†åŒ–å™¨ï¼ˆè¿™ä¸€æ­¥éå¸¸é‡è¦ï¼‰
            scaler_path = os.path.join(self.model_dir, 'final_scaler.joblib')
            if os.path.exists(scaler_path):
                self.final_scaler = joblib.load(scaler_path)
                log(f"åŠ è½½æ ‡å‡†åŒ–å™¨: {scaler_path}")
                
                # æ‰“å°æ ‡å‡†åŒ–å™¨çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç”¨äºéªŒè¯
                if hasattr(self.final_scaler, 'mean_'):
                    log(f"ç‰¹å¾å‡å€¼: {self.final_scaler.mean_}")
                if hasattr(self.final_scaler, 'scale_'):
                    log(f"ç‰¹å¾æ ‡å‡†å·®: {self.final_scaler.scale_}")
            else:
                log(f"é”™è¯¯: æœªæ‰¾åˆ°æ ‡å‡†åŒ–å™¨æ–‡ä»¶: {scaler_path}")
                return False
            
            log(f"æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹")
            return True
            
        except Exception as e:
            log(f"åŠ è½½æ¨¡å‹ç»„ä»¶æ—¶å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            return False
    
    def check_feature_order(self, input_df):
        """
        ç¡®ä¿è¾“å…¥ç‰¹å¾çš„é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
        """
        # æ£€æŸ¥ç‰¹å¾åç§°æ˜¯å¦å­˜åœ¨
        if self.feature_names is None:
            log("é”™è¯¯: ç‰¹å¾åç§°åˆ—è¡¨ä¸ºç©º")
            return input_df
        
        # è®°å½•åŸå§‹è¾“å…¥
        log(f"åŸå§‹è¾“å…¥ç‰¹å¾: {input_df.columns.tolist()}")
        log(f"æ¨¡å‹éœ€è¦çš„ç‰¹å¾é¡ºåº: {self.feature_names}")
        
        # åˆ›å»ºæ–°çš„DataFrameï¼Œä¸¥æ ¼æŒ‰ç…§æ¨¡å‹ç‰¹å¾é¡ºåº
        ordered_df = pd.DataFrame(index=input_df.index)
        
        for feature in self.feature_names:
            # ç²¾ç¡®åŒ¹é…
            if feature in input_df.columns:
                ordered_df[feature] = input_df[feature]
            # åŸºäºå‰ç¼€åŒ¹é…
            else:
                feature_base = feature.split('(')[0].strip()
                for col in input_df.columns:
                    col_base = col.split('(')[0].strip()
                    if col_base == feature_base:
                        log(f"æ˜ å°„ç‰¹å¾: {col} -> {feature}")
                        ordered_df[feature] = input_df[col]
                        break
                else:
                    # æœªæ‰¾åˆ°åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    log(f"è­¦å‘Š: æœªæ‰¾åˆ°ç‰¹å¾ {feature} çš„å¯¹åº”è¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼0")
                    ordered_df[feature] = 0.0
        
        log(f"é‡æ’åçš„ç‰¹å¾é¡ºåº: {ordered_df.columns.tolist()}")
        return ordered_df
    
    def predict(self, input_features):
        """
        ä½¿ç”¨åŠ è½½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        å‚æ•°:
            input_features: åŒ…å«ç‰¹å¾æ•°æ®çš„DataFrame
        """
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
            if not self.models or not self.final_scaler:
                log("é”™è¯¯: æ¨¡å‹æˆ–æ ‡å‡†åŒ–å™¨æœªåŠ è½½")
                return np.array([0.0])
            
            # ç¡®ä¿ç‰¹å¾é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
            input_ordered = self.check_feature_order(input_features)
            
            # è®°å½•è¯¦ç»†çš„è¾“å…¥æ•°æ®
            log(f"é¢„æµ‹è¾“å…¥æ•°æ®: {input_ordered.to_dict('records')}")
            
            # åº”ç”¨æ ‡å‡†åŒ–
            X_scaled = self.final_scaler.transform(input_ordered)
            log(f"æ ‡å‡†åŒ–åçš„æ•°æ®å½¢çŠ¶: {X_scaled.shape}")
            
            # ä½¿ç”¨æ¯ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹
            all_predictions = np.zeros((input_ordered.shape[0], len(self.models)))
            for i, model in enumerate(self.models):
                pred = model.predict(X_scaled)
                all_predictions[:, i] = pred
                log(f"æ¨¡å‹ {i} é¢„æµ‹ç»“æœ: {pred[0]:.2f}")
            
            # åº”ç”¨æ¨¡å‹æƒé‡è®¡ç®—æœ€ç»ˆé¢„æµ‹
            weighted_pred = np.sum(all_predictions * self.model_weights.reshape(1, -1), axis=1)
            log(f"æœ€ç»ˆåŠ æƒé¢„æµ‹ç»“æœ: {weighted_pred[0]:.2f}")
            
            return weighted_pred
            
        except Exception as e:
            log(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            # è¿”å›é»˜è®¤å€¼
            return np.array([0.0])

# åˆå§‹åŒ–é¢„æµ‹å™¨
predictor = EnsembleModelPredictor()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False

# å®šä¹‰é»˜è®¤å€¼
default_values = {
    "C(%)": 38.3,  # ä½¿ç”¨æˆªå›¾ä¸­æ˜¾ç¤ºçš„å€¼
    "H(%)": 5.5,
    "O(%)": 55.2,
    "N(%)": 0.6,
    "Ash(%)": 6.6,
    "VM(%)": 81.1,
    "FC(%)": 10.3,
    "PT(Â°C)": 500.0,
    "HR(â„ƒ/min)": 10.0,
    "RT(min)": 60.0
}

# ç‰¹å¾åˆ†ç±»
feature_categories = {
    "Ultimate Analysis": ["C(%)", "H(%)", "O(%)", "N(%)"],
    "Proximate Analysis": ["Ash(%)", "VM(%)", "FC(%)"],
    "Pyrolysis Conditions": ["PT(Â°C)", "HR(â„ƒ/min)", "RT(min)"]
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸æ¥å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# Ultimate Analysis (é»„è‰²åŒºåŸŸ) - ç¬¬ä¸€åˆ—
with col1:
    st.markdown("<div class='section-header' style='background-color: #DAA520;'>Ultimate Analysis</div>", unsafe_allow_html=True)
    
    for feature in feature_categories["Ultimate Analysis"]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"ultimate_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: #DAA520;'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=0.0, 
                max_value=100.0, 
                value=value, 
                key=f"ultimate_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# Proximate Analysis (ç»¿è‰²åŒºåŸŸ) - ç¬¬äºŒåˆ—
with col2:
    st.markdown("<div class='section-header' style='background-color: #32CD32;'>Proximate Analysis</div>", unsafe_allow_html=True)
    
    for feature in feature_categories["Proximate Analysis"]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"proximate_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: #32CD32;'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=0.0, 
                max_value=100.0, 
                value=value, 
                key=f"proximate_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# Pyrolysis Conditions (æ©™è‰²åŒºåŸŸ) - ç¬¬ä¸‰åˆ—
with col3:
    st.markdown("<div class='section-header' style='background-color: #FF7F50;'>Pyrolysis Conditions</div>", unsafe_allow_html=True)
    
    for feature in feature_categories["Pyrolysis Conditions"]:
        # é‡ç½®å€¼æˆ–ä½¿ç”¨ç°æœ‰å€¼
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"pyrolysis_{feature}", default_values[feature])
        
        # å¯¹äºæ¸©åº¦å’Œå…¶ä»–å‚æ•°ä½¿ç”¨ä¸åŒçš„èŒƒå›´
        if feature == "PT(Â°C)":
            min_val, max_val = 200.0, 1000.0
        elif feature == "HR(â„ƒ/min)":
            min_val, max_val = 1.0, 100.0
        elif feature == "RT(min)":
            min_val, max_val = 0.0, 500.0
        else:
            min_val, max_val = 0.0, 100.0
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: #FF7F50;'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"pyrolysis_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# é‡ç½®session_stateä¸­çš„clear_pressedçŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.clear_pressed = False

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸå’ŒæŒ‰é’®
result_col, button_col = st.columns([5, 1])

with result_col:
    st.subheader("Char Yield (wt%)")
    prediction_placeholder = st.empty()

with button_col:
    # é¢„æµ‹æŒ‰é’®
    predict_button = st.button("PUSH", type="primary")
    
    # å®šä¹‰ClearæŒ‰é’®çš„å›è°ƒå‡½æ•°
    def clear_values():
        st.session_state.clear_pressed = True
        # æ¸…é™¤é¢„æµ‹ç»“æœ
        if 'prediction_result' in st.session_state:
            del st.session_state.prediction_result
    
    clear_button = st.button("CLEAR", on_click=clear_values)

# è½¬æ¢ä¸ºDataFrame
input_data = pd.DataFrame([features])

# å½“ç‚¹å‡»é¢„æµ‹æŒ‰é’®æ—¶
if predict_button:
    try:
        # è®°å½•é¢„æµ‹å¼€å§‹
        log("å¼€å§‹è¿›è¡Œé¢„æµ‹...")
        
        # ä½¿ç”¨é¢„æµ‹å™¨é¢„æµ‹
        result = predictor.predict(input_data)[0]
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        st.session_state.prediction_result = result
        
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        prediction_placeholder.markdown(
            f"<div class='yield-result'>{result:.2f}</div>",
            unsafe_allow_html=True
        )
        
        # è®°å½•é¢„æµ‹å®Œæˆ
        log(f"é¢„æµ‹å®Œæˆ: Char Yield(%) = {result:.2f}")
        
    except Exception as e:
        log(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")

# å¦‚æœæœ‰ä¿å­˜çš„é¢„æµ‹ç»“æœï¼Œæ˜¾ç¤ºå®ƒ
if 'prediction_result' in st.session_state:
    prediction_placeholder.markdown(
        f"<div class='yield-result'>{st.session_state.prediction_result:.2f}</div>",
        unsafe_allow_html=True
    )

# æ·»åŠ è°ƒè¯•ä¿¡æ¯æŠ˜å åŒºåŸŸ
with st.expander("Debug Information", expanded=False):
    st.write("### è¾“å…¥ç‰¹å¾")
    st.write(input_data)
    
    st.write("### æ¨¡å‹ä¿¡æ¯")
    if predictor.feature_names:
        st.write(f"ç‰¹å¾åˆ—è¡¨: {predictor.feature_names}")
    if predictor.metadata and 'performance' in predictor.metadata:
        st.write(f"æ¨¡å‹æ€§èƒ½: {predictor.metadata['performance']}")
    
    st.write(f"ä½¿ç”¨ç›®å½•: {predictor.model_dir}")
    st.write(f"åŠ è½½çš„æ¨¡å‹æ•°é‡: {len(predictor.models)}")

# æ·»åŠ æ¨¡å‹æè¿°
st.markdown("""
### About the Model

This application uses a CatBoost ensemble model to predict char yield in biomass pyrolysis.

#### Key Factors Affecting Char Yield:
* **Pyrolysis Temperature**: Higher temperature generally decreases char yield
* **Residence Time**: Longer residence time generally increases char yield
* **Biomass Composition**: Carbon content and ash content significantly affect the final yield

The model was trained using 10-fold cross-validation with optimized hyperparameters, achieving high prediction accuracy (RÂ² = 0.93, RMSE = 3.39 on test set).
""")

# é¡µè„š
st.markdown("---")
st.caption("Â© 2023 Biomass Pyrolysis Research Team. All rights reserved.")