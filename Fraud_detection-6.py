# -*- coding: utf-8 -*-
"""
Biomass Pyrolysis Yield Forecast using CatBoost Ensemble Models
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import glob
import joblib
import json
import traceback
import importlib.util

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title='Biomass Pyrolysis Yield Forecast',
    page_icon='ğŸ“Š',
    layout='wide'
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown(
    """
    <style>
    /* å…¨å±€å­—ä½“è®¾ç½® */
    html, body, [class*="css"] {
        font-size: 16px !important;
    }
    
    /* æ ‡é¢˜ */
    .main-title {
        text-align: center;
        font-size: 32px !important;
        font-weight: bold;
        margin-bottom: 20px;
        color: white !important;
    }
    
    /* åŒºåŸŸæ ·å¼ */
    .section-header {
        color: white;
        font-weight: bold;
        font-size: 22px;
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 5px;
        border-radius: 5px;
        margin-bottom: 5px;
        font-size: 18px;
        color: white;
    }
    
    /* ç»“æœæ˜¾ç¤ºæ ·å¼ */
    .yield-result {
        background-color: #1E1E1E;
        color: white;
        font-size: 36px;
        font-weight: bold;
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    
    /* å¼ºåˆ¶åº”ç”¨ç™½è‰²èƒŒæ™¯åˆ°è¾“å…¥æ¡† */
    [data-testid="stNumberInput"] input {
        background-color: white !important;
        color: black !important;
    }
    
    /* å¢å¤§æŒ‰é’®çš„å­—ä½“ */
    .stButton button {
        font-size: 18px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ä¸»æ ‡é¢˜
st.markdown("<h1 class='main-title'>Prediction of crop biomass pyrolysis yield based on CatBoost ensemble modeling</h1>", unsafe_allow_html=True)

# åˆ›å»ºä¾§è¾¹æ æ—¥å¿—åŒºåŸŸ
log_container = st.sidebar.container()
log_container.write("### è°ƒè¯•æ—¥å¿—")

def log(message):
    """è®°å½•è°ƒè¯•ä¿¡æ¯åˆ°ä¾§è¾¹æ """
    log_container.write(message)

# ç›´æ¥é¢„æµ‹å™¨ç±» - ä¸¥æ ¼æŒ‰ç…§è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåºå’Œå¤„ç†æ–¹æ³•
class ModelPredictor:
    """ç›´æ¥åŠ è½½å¹¶ä½¿ç”¨æ¨¡å‹æ–‡ä»¶è¿›è¡Œé¢„æµ‹"""
    
    def __init__(self):
        # ä¸¥æ ¼å®šä¹‰æ¨¡å‹æœŸæœ›çš„ç‰¹å¾é¡ºåº
        self.feature_names = ['C(%)', 'H(%)', 'O(%)', 'N(%)', 'Ash(%)', 'VM(%)', 'FC(%)', 'PT(Â°C)', 'HR(â„ƒ/min)', 'RT(min)']
        self.models = []
        self.model_weights = None
        self.scaler = None
        self.metadata = None
        self.performance = None
        
        # åŠ è½½æ¨¡å‹ç»„ä»¶
        self.load_components()
    
    def load_components(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹ç»„ä»¶"""
        try:
            # æŸ¥æ‰¾æ¨¡å‹ç›®å½•
            model_dirs = glob.glob("**/models", recursive=True)
            if not model_dirs:
                log("æœªæ‰¾åˆ°æ¨¡å‹ç›®å½•")
                return False
            
            # æ¨æ–­æ¨¡å‹æ ¹ç›®å½•
            model_dir = os.path.dirname(model_dirs[0])
            log(f"æ¨¡å‹æ ¹ç›®å½•: {model_dir}")
            
            # åŠ è½½å…ƒæ•°æ®
            metadata_path = os.path.join(model_dir, 'metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    self.metadata = json.load(f)
                # éªŒè¯ç‰¹å¾é¡ºåº, ä½†ä»ä½¿ç”¨é¢„å®šä¹‰çš„é¡ºåº
                metadata_features = self.metadata.get('feature_names', None)
                if metadata_features:
                    log(f"å…ƒæ•°æ®ç‰¹å¾é¡ºåº: {metadata_features}")
                # åŠ è½½æ€§èƒ½æŒ‡æ ‡
                if 'performance' in self.metadata:
                    self.performance = self.metadata['performance']
                    log(f"æ¨¡å‹æ€§èƒ½: RÂ²={self.performance.get('test_r2', 'unknown')}, RMSE={self.performance.get('test_rmse', 'unknown')}")
            
            # åŠ è½½æ¨¡å‹
            models_dir = os.path.join(model_dir, 'models')
            if os.path.exists(models_dir):
                model_files = sorted(glob.glob(os.path.join(models_dir, 'model_*.joblib')))
                if model_files:
                    for model_path in model_files:
                        try:
                            model = joblib.load(model_path)
                            self.models.append(model)
                            log(f"åŠ è½½æ¨¡å‹: {model_path}")
                        except Exception as e:
                            log(f"åŠ è½½æ¨¡å‹å¤±è´¥: {model_path}, é”™è¯¯: {e}")
            
            # åŠ è½½æƒé‡
            weights_path = os.path.join(model_dir, 'model_weights.npy')
            if os.path.exists(weights_path):
                self.model_weights = np.load(weights_path)
                log(f"åŠ è½½æƒé‡: {weights_path}")
            else:
                if self.models:
                    self.model_weights = np.ones(len(self.models)) / len(self.models)
                    log("ä½¿ç”¨å‡ç­‰æƒé‡")
            
            # åŠ è½½æ ‡å‡†åŒ–å™¨
            scaler_path = os.path.join(model_dir, 'final_scaler.joblib')
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
                log(f"åŠ è½½æ ‡å‡†åŒ–å™¨: {scaler_path}")
            
            # éªŒè¯åŠ è½½çŠ¶æ€
            if self.models and self.scaler:
                log(f"æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹")
                return True
            else:
                log("æ¨¡å‹åŠ è½½ä¸å®Œæ•´")
                return False
                
        except Exception as e:
            log(f"åŠ è½½æ¨¡å‹ç»„ä»¶æ—¶å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            return False
    
    def check_input_range(self, input_data):
        """æ£€æŸ¥è¾“å…¥å€¼æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®èŒƒå›´å†…"""
        if not hasattr(self.scaler, 'mean_') or not hasattr(self.scaler, 'scale_'):
            return []
            
        warnings = []
        feature_mean = self.scaler.mean_
        feature_std = self.scaler.scale_
            
        # è½¬æ¢åæ£€æŸ¥è¾“å…¥èŒƒå›´
        ordered_data = self.reorder_features(input_data)
        
        for i, feature in enumerate(self.feature_names):
            input_val = ordered_data[feature].iloc[0]
            mean = feature_mean[i]
            std = feature_std[i]
            
            # è®¡ç®—åˆç†èŒƒå›´ (2ä¸ªæ ‡å‡†å·®)
            lower_bound = mean - 2 * std
            upper_bound = mean + 2 * std
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºèŒƒå›´
            if input_val < lower_bound or input_val > upper_bound:
                log(f"è­¦å‘Š: {feature} = {input_val} è¶…å‡ºæ­£å¸¸èŒƒå›´ [{lower_bound:.2f}, {upper_bound:.2f}]")
                warnings.append(f"{feature}: {input_val} (èŒƒå›´: {lower_bound:.2f}-{upper_bound:.2f})")
        
        return warnings
    
    def reorder_features(self, X):
        """ç¡®ä¿ç‰¹å¾é¡ºåºä¸æ¨¡å‹æœŸæœ›ä¸€è‡´"""
        if not isinstance(X, pd.DataFrame):
            log("è¾“å…¥ä¸æ˜¯DataFrameæ ¼å¼")
            # è½¬æ¢ä¸ºDataFrame
            if isinstance(X, dict):
                X = pd.DataFrame([X])
            else:
                return X
        
        log(f"è¾“å…¥ç‰¹å¾: {X.columns.tolist()}")
        log(f"æ¨¡å‹æœŸæœ›ç‰¹å¾: {self.feature_names}")
        
        # åˆ›å»ºæ–°DataFrameï¼Œç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®
        ordered_X = pd.DataFrame(index=X.index)
        
        # åŒ¹é…ç‰¹å¾
        for feature in self.feature_names:
            if feature in X.columns:
                # ç›´æ¥åŒ¹é…
                ordered_X[feature] = X[feature]
            else:
                # åŸºäºå‰ç¼€åŒ¹é…
                feature_base = feature.split('(')[0]
                matched = False
                for col in X.columns:
                    col_base = col.split('(')[0]
                    if col_base == feature_base:
                        ordered_X[feature] = X[col]
                        log(f"åŒ¹é…ç‰¹å¾: {col} -> {feature}")
                        matched = True
                        break
                
                if not matched:
                    log(f"è­¦å‘Š: æ‰¾ä¸åˆ°åŒ¹é…ç‰¹å¾ {feature}")
                    # ä½¿ç”¨é»˜è®¤å€¼
                    ordered_X[feature] = 0.0
        
        return ordered_X
    
    def predict(self, input_data):
        """ä½¿ç”¨æ¨¡å‹é¢„æµ‹ç»“æœ"""
        try:
            if not self.models:
                log("æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•é¢„æµ‹")
                return np.array([33.0])  # è¿”å›é»˜è®¤å€¼
            
            # ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®
            ordered_data = self.reorder_features(input_data)
            log(f"é‡æ’åçš„ç‰¹å¾æ•°æ®: {ordered_data.iloc[0].to_dict()}")
            
            # æ ‡å‡†åŒ–æ•°æ®
            if self.scaler:
                X_scaled = self.scaler.transform(ordered_data)
                log("åº”ç”¨æ ‡å‡†åŒ–å™¨")
                # è°ƒè¯•ï¼šæ˜¾ç¤ºæ ‡å‡†åŒ–å‰åçš„å€¼
                log(f"æ ‡å‡†åŒ–å‰: {ordered_data.iloc[0].values}")
                log(f"æ ‡å‡†åŒ–å: {X_scaled[0]}")
            else:
                log("æœªæ‰¾åˆ°æ ‡å‡†åŒ–å™¨ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                X_scaled = ordered_data.values
            
            # ä½¿ç”¨æ¯ä¸ªæ¨¡å‹é¢„æµ‹å¹¶åº”ç”¨æƒé‡
            all_predictions = np.zeros((len(ordered_data), len(self.models)))
            
            for i, model in enumerate(self.models):
                try:
                    pred = model.predict(X_scaled)
                    all_predictions[:, i] = pred
                    log(f"æ¨¡å‹ {i} é¢„æµ‹: {pred[0]:.2f}")
                except Exception as e:
                    log(f"æ¨¡å‹ {i} é¢„æµ‹å¤±è´¥: {e}")
                    if i > 0:
                        # ä½¿ç”¨å·²å®Œæˆæ¨¡å‹çš„å¹³å‡å€¼
                        all_predictions[:, i] = np.mean(all_predictions[:, :i], axis=1)
            
            # åº”ç”¨æƒé‡
            if self.model_weights is not None:
                weighted_contributions = all_predictions[0] * self.model_weights
                log(f"å„æ¨¡å‹è´¡çŒ®: {weighted_contributions}")
                weighted_pred = np.sum(all_predictions * self.model_weights.reshape(1, -1), axis=1)
            else:
                # ç®€å•å¹³å‡
                weighted_pred = np.mean(all_predictions, axis=1)
            
            log(f"æœ€ç»ˆé¢„æµ‹: {weighted_pred[0]:.2f}")
            return weighted_pred
            
        except Exception as e:
            log(f"é¢„æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            return np.array([33.0])  # è¿”å›é»˜è®¤å€¼

# åŠ è½½æ¨¡å‹
predictor = ModelPredictor()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False

# å®šä¹‰é»˜è®¤å€¼å’ŒèŒƒå›´ - ä½¿ç”¨æ¨¡å‹æœŸæœ›çš„ç‰¹å¾é¡ºåº
default_values = {
    'C(%)': 45.0,
    'H(%)': 6.0,
    'O(%)': 40.0,
    'N(%)': 0.5,
    'Ash(%)': 5.0,
    'VM(%)': 75.0,
    'FC(%)': 15.0,
    'PT(Â°C)': 500.0,
    'HR(â„ƒ/min)': 20.0,
    'RT(min)': 20.0
}

# ç‰¹å¾åˆ†ç±»åŠé¡ºåº
feature_categories = {
    "Ultimate Analysis": ['C(%)', 'H(%)', 'O(%)', 'N(%)'],
    "Proximate Analysis": ['Ash(%)', 'VM(%)', 'FC(%)'],
    "Pyrolysis Conditions": ['PT(Â°C)', 'HR(â„ƒ/min)', 'RT(min)']
}

# ç‰¹å¾èŒƒå›´
feature_ranges = {
    'C(%)': (30.0, 80.0),
    'H(%)': (3.0, 10.0),
    'O(%)': (10.0, 60.0),
    'N(%)': (0.0, 5.0),
    'Ash(%)': (0.0, 25.0),
    'VM(%)': (40.0, 95.0),
    'FC(%)': (5.0, 40.0),
    'PT(Â°C)': (300.0, 900.0),
    'HR(â„ƒ/min)': (5.0, 100.0),
    'RT(min)': (5.0, 120.0)
}

# ä¸ºæ¯ç§åˆ†ç±»è®¾ç½®ä¸åŒçš„é¢œè‰²
category_colors = {
    "Ultimate Analysis": "#DAA520",  # é»„è‰²
    "Proximate Analysis": "#32CD32",  # ç»¿è‰²
    "Pyrolysis Conditions": "#FF7F50"  # æ©™è‰²
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸æ¥å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# ç¬¬ä¸€åˆ—: Ultimate Analysis (é»„è‰²åŒºåŸŸ)
with col1:
    category = "Ultimate Analysis"
    st.markdown(f"<div class='section-header' style='background-color: {category_colors[category]};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        min_val, max_val = feature_ranges[feature]
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {category_colors[category]};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"{category}_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# ç¬¬äºŒåˆ—: Proximate Analysis (ç»¿è‰²åŒºåŸŸ)
with col2:
    category = "Proximate Analysis"
    st.markdown(f"<div class='section-header' style='background-color: {category_colors[category]};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        min_val, max_val = feature_ranges[feature]
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {category_colors[category]};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"{category}_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# ç¬¬ä¸‰åˆ—: Pyrolysis Conditions (æ©™è‰²åŒºåŸŸ)
with col3:
    category = "Pyrolysis Conditions"
    st.markdown(f"<div class='section-header' style='background-color: {category_colors[category]};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        min_val, max_val = feature_ranges[feature]
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {category_colors[category]};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"{category}_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# é‡ç½®session_stateä¸­çš„clear_pressedçŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.clear_pressed = False

# è½¬æ¢ä¸ºDataFrame
input_data = pd.DataFrame([features])

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸå’ŒæŒ‰é’®
result_col, button_col = st.columns([3, 1])

with result_col:
    prediction_placeholder = st.empty()
    warning_placeholder = st.empty()
    
with button_col:
    predict_button = st.button("PUSH", key="predict")
    
    # å®šä¹‰ClearæŒ‰é’®çš„å›è°ƒå‡½æ•°
    def clear_values():
        st.session_state.clear_pressed = True
        # æ¸…é™¤æ˜¾ç¤º
        if 'prediction_result' in st.session_state:
            st.session_state.prediction_result = None
        if 'warnings' in st.session_state:
            st.session_state.warnings = None
    
    clear_button = st.button("CLEAR", key="clear", on_click=clear_values)

# å¤„ç†é¢„æµ‹é€»è¾‘
if predict_button:
    try:
        # è®°å½•è¾“å…¥æ•°æ®
        log("è¿›è¡Œé¢„æµ‹:")
        log(f"è¾“å…¥æ•°æ®: {input_data.to_dict('records')}")
        
        # æ£€æŸ¥è¾“å…¥èŒƒå›´
        warnings_list = predictor.check_input_range(input_data)
        st.session_state.warnings = warnings_list
        
        # ä½¿ç”¨predictorè¿›è¡Œé¢„æµ‹
        log("è°ƒç”¨é¢„æµ‹å™¨çš„predictæ–¹æ³•")
        y_pred = predictor.predict(input_data)[0]
        log(f"é¢„æµ‹å®Œæˆ: {y_pred:.2f}")
        
        # ä¿å­˜é¢„æµ‹ç»“æœåˆ°session_state
        st.session_state.prediction_result = y_pred

        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        prediction_placeholder.markdown(
            f"<div class='yield-result'>Char Yield (wt%) <br> {y_pred:.2f}</div>",
            unsafe_allow_html=True
        )
        
        # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        if warnings_list:
            warning_text = "<div style='color:orange;padding:10px;margin-top:10px;'><b>âš ï¸ è­¦å‘Š:</b> ä»¥ä¸‹è¾“å…¥å€¼è¶…å‡ºè®­ç»ƒèŒƒå›´ï¼Œå¯èƒ½å½±å“é¢„æµ‹å‡†ç¡®æ€§:<br>"
            for warning in warnings_list:
                warning_text += f"- {warning}<br>"
            warning_text += "</div>"
            warning_placeholder.markdown(warning_text, unsafe_allow_html=True)
    except Exception as e:
        log(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        log(traceback.format_exc())
        st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")

# å¦‚æœæœ‰ä¿å­˜çš„é¢„æµ‹ç»“æœï¼Œæ˜¾ç¤ºå®ƒ
if 'prediction_result' in st.session_state and st.session_state.prediction_result is not None:
    prediction_placeholder.markdown(
        f"<div class='yield-result'>Char Yield (wt%) <br> {st.session_state.prediction_result:.2f}</div>",
        unsafe_allow_html=True
    )
    
    # æ˜¾ç¤ºä¿å­˜çš„è­¦å‘Š
    if 'warnings' in st.session_state and st.session_state.warnings:
        warning_text = "<div style='color:orange;padding:10px;margin-top:10px;'><b>âš ï¸ è­¦å‘Š:</b> ä»¥ä¸‹è¾“å…¥å€¼è¶…å‡ºè®­ç»ƒèŒƒå›´ï¼Œå¯èƒ½å½±å“é¢„æµ‹å‡†ç¡®æ€§:<br>"
        for warning in st.session_state.warnings:
            warning_text += f"- {warning}<br>"
        warning_text += "</div>"
        warning_placeholder.markdown(warning_text, unsafe_allow_html=True)

# æ·»åŠ è°ƒè¯•ä¿¡æ¯
with st.expander("Debug Information", expanded=False):
    st.write("Input Features:")
    st.write(input_data)
    
    if predictor is not None:
        st.write("Predictor Information:")
        predictor_info = {
            "Type": type(predictor).__name__,
            "Feature Names": predictor.feature_names
        }
        
        if predictor.performance:
            predictor_info["Performance"] = predictor.performance
        
        st.write(predictor_info)
        
        if predictor.metadata:
            st.write("Model Metadata:")
            st.write(predictor.metadata)

# æ·»åŠ å…³äºæ¨¡å‹çš„ä¿¡æ¯
st.markdown("""
### About the Model
This application uses a CatBoost ensemble model to predict char yield in biomass pyrolysis.

#### Key Factors Affecting Char Yield:
- **Pyrolysis Temperature**: Higher temperature generally decreases char yield
- **Residence Time**: Longer residence time generally increases char yield
- **Biomass Composition**: Carbon content and ash content significantly affect the final yield

The model was trained using 10-fold cross-validation with optimized hyperparameters, achieving high prediction accuracy (RÂ² = 0.93, RMSE = 3.39 on test set).
""")