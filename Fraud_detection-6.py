# -*- coding: utf-8 -*-
"""
Biomass Pyrolysis Yield Forecast using CatBoost Ensemble Models
å®Œå…¨ä¼˜åŒ–ç‰ˆæœ¬ - è§£å†³é¢„æµ‹ç²¾åº¦é—®é¢˜
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import glob
import joblib
import json
import traceback
import matplotlib.pyplot as plt
import base64
import io
from PIL import Image
from datetime import datetime

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title='Biomass Pyrolysis Yield Forecast',
    page_icon='ğŸ”¥',
    layout='wide',
    initial_sidebar_state='expanded'
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown(
    """
    <style>
    /* å…¨å±€å­—ä½“è®¾ç½® */
    html, body, [class*="css"] {
        font-size: 16px !important;
    }
    
    /* æ ‡é¢˜ */
    .main-title {
        text-align: center;
        font-size: 32px !important;
        font-weight: bold;
        margin-bottom: 20px;
        color: white !important;
    }
    
    /* åŒºåŸŸæ ·å¼ */
    .section-header {
        color: white;
        font-weight: bold;
        font-size: 22px;
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 5px;
        border-radius: 5px;
        margin-bottom: 5px;
        font-size: 18px;
        color: white;
    }
    
    /* ç»“æœæ˜¾ç¤ºæ ·å¼ */
    .yield-result {
        background-color: #1E1E1E;
        color: white;
        font-size: 36px;
        font-weight: bold;
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    
    /* å¼ºåˆ¶åº”ç”¨ç™½è‰²èƒŒæ™¯åˆ°è¾“å…¥æ¡† */
    [data-testid="stNumberInput"] input {
        background-color: white !important;
        color: black !important;
    }
    
    /* å¢å¤§æŒ‰é’®çš„å­—ä½“ */
    .stButton button {
        font-size: 18px !important;
    }
    
    /* è­¦å‘Šæ ·å¼ */
    .warning-box {
        background-color: rgba(255, 165, 0, 0.2);
        border-left: 5px solid orange;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* é”™è¯¯æ ·å¼ */
    .error-box {
        background-color: rgba(255, 0, 0, 0.2);
        border-left: 5px solid red;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* æ—¥å¿—æ ·å¼ */
    .log-container {
        height: 300px;
        overflow-y: auto;
        background-color: #1E1E1E;
        color: #00FF00;
        font-family: 'Courier New', monospace;
        padding: 10px;
        border-radius: 5px;
        font-size: 14px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# åˆ›å»ºä¾§è¾¹æ æ—¥å¿—åŒºåŸŸ
log_container = st.sidebar.container()
log_container.markdown("<h3>æ‰§è¡Œæ—¥å¿—</h3>", unsafe_allow_html=True)
log_text = st.sidebar.empty()

# åˆå§‹åŒ–æ—¥å¿—å­—ç¬¦ä¸²
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []

def log(message):
    """è®°å½•æ—¥å¿—åˆ°ä¾§è¾¹æ å’Œä¼šè¯çŠ¶æ€"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    st.session_state.log_messages.append(log_entry)
    # åªä¿ç•™æœ€è¿‘çš„100æ¡æ—¥å¿—
    if len(st.session_state.log_messages) > 100:
        st.session_state.log_messages = st.session_state.log_messages[-100:]
    
    # æ›´æ–°æ—¥å¿—æ˜¾ç¤º
    log_text.markdown(
        f"<div class='log-container'>{'<br>'.join(st.session_state.log_messages)}</div>", 
        unsafe_allow_html=True
    )

# ä¸»æ ‡é¢˜
st.markdown("<h1 class='main-title'>Prediction of crop biomass pyrolysis yield based on CatBoost ensemble modeling</h1>", unsafe_allow_html=True)

class CatBoostEnsemblePredictor:
    """å¢å¼ºç‰ˆé›†æˆæ¨¡å‹é¢„æµ‹å™¨ - è§£å†³é¢„æµ‹ç²¾åº¦é—®é¢˜"""
    
    def __init__(self):
        self.models = []
        self.model_weights = None
        self.final_scaler = None
        self.feature_names = None
        self.target_name = "Char Yield(%)"
        self.metadata = None
        self.model_dir = None
        self.feature_importance = None
        self.training_ranges = {}
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    def find_model_directory(self):
        """æŸ¥æ‰¾æ¨¡å‹ç›®å½•çš„å¤šç§æ–¹æ³•"""
        # æ¨¡å‹ç›®å½•å¯èƒ½çš„è·¯å¾„
        possible_dirs = [
            # ç›´æ¥è·¯å¾„
            "Char_Yield_Model",
            "Char_Yield%_Model",
            # ç›¸å¯¹è·¯å¾„
            "./Char_Yield_Model",
            "./Char_Yield%_Model",
            "../Char_Yield_Model",
            "../Char_Yield%_Model",
            # ç»å¯¹è·¯å¾„ç¤ºä¾‹
            "C:/Users/HWY/Desktop/æ–¹-3/Char_Yield_Model",
            "C:/Users/HWY/Desktop/æ–¹-3/Char_Yield%_Model"
        ]
        
        # å°è¯•æ‰€æœ‰å¯èƒ½è·¯å¾„
        for dir_path in possible_dirs:
            if os.path.exists(dir_path) and os.path.isdir(dir_path):
                log(f"æ‰¾åˆ°æ¨¡å‹ç›®å½•: {dir_path}")
                return os.path.abspath(dir_path)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡æ¨¡å‹æ–‡ä»¶æ¨æ–­
        try:
            model_files = glob.glob("**/model_*.joblib", recursive=True)
            if model_files:
                model_dir = os.path.dirname(os.path.dirname(model_files[0]))
                log(f"åŸºäºæ¨¡å‹æ–‡ä»¶æ¨æ–­æ¨¡å‹ç›®å½•: {model_dir}")
                return model_dir
        except Exception as e:
            log(f"é€šè¿‡æ¨¡å‹æ–‡ä»¶æ¨æ–­ç›®å½•æ—¶å‡ºé”™: {str(e)}")
        
        # å½“å‰ç›®å½•ä½œä¸ºæœ€åçš„é€€è·¯
        log("è­¦å‘Š: æ— æ³•æ‰¾åˆ°æ¨¡å‹ç›®å½•ï¼Œå°†ä½¿ç”¨å½“å‰ç›®å½•")
        return os.getcwd()
    
    def load_feature_importance(self):
        """åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®"""
        try:
            # å°è¯•ä»CSVæ–‡ä»¶åŠ è½½ç‰¹å¾é‡è¦æ€§
            importance_csv = os.path.join(self.model_dir, "feature_importance.csv")
            if os.path.exists(importance_csv):
                importance_df = pd.read_csv(importance_csv)
                self.feature_importance = importance_df
                log(f"å·²åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œå…± {len(importance_df)} ä¸ªç‰¹å¾")
                return True
            
            # å¦‚æœCSVä¸å­˜åœ¨ï¼Œå°è¯•ä»å…ƒæ•°æ®ä¸­åŠ è½½
            if self.metadata and 'feature_importance' in self.metadata:
                importance_data = self.metadata['feature_importance']
                self.feature_importance = pd.DataFrame(importance_data)
                log(f"ä»å…ƒæ•°æ®åŠ è½½ç‰¹å¾é‡è¦æ€§æ•°æ®")
                return True
            
            # å°è¯•é€šè¿‡åŠ è½½çš„æ¨¡å‹è®¡ç®—ç‰¹å¾é‡è¦æ€§
            if self.models and self.model_weights is not None and self.feature_names:
                log("é€šè¿‡æ¨¡å‹è®¡ç®—ç‰¹å¾é‡è¦æ€§")
                importance = np.zeros(len(self.feature_names))
                for i, model in enumerate(self.models):
                    model_importance = model.get_feature_importance()
                    importance += model_importance * self.model_weights[i]
                
                self.feature_importance = pd.DataFrame({
                    'Feature': self.feature_names,
                    'Importance': importance
                }).sort_values('Importance', ascending=False)
                
                log(f"è®¡ç®—å¾—åˆ°ç‰¹å¾é‡è¦æ€§æ•°æ®ï¼Œæœ€é‡è¦ç‰¹å¾: {self.feature_importance['Feature'].iloc[0]}")
                return True
                
            log("è­¦å‘Š: æ— æ³•åŠ è½½æˆ–è®¡ç®—ç‰¹å¾é‡è¦æ€§")
            return False
        except Exception as e:
            log(f"åŠ è½½ç‰¹å¾é‡è¦æ€§æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def extract_training_ranges(self):
        """ä»æ ‡å‡†åŒ–å™¨ä¸­æå–è®­ç»ƒæ•°æ®èŒƒå›´"""
        if not hasattr(self.final_scaler, 'mean_') or not hasattr(self.final_scaler, 'scale_'):
            log("è­¦å‘Š: æ ‡å‡†åŒ–å™¨æ²¡æœ‰å‡å€¼æˆ–æ ‡å‡†å·®ä¿¡æ¯")
            return
        
        if not self.feature_names:
            log("è­¦å‘Š: æ— æ³•è·å–ç‰¹å¾åç§°")
            return
        
        # æå–ç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
        means = self.final_scaler.mean_
        stds = self.final_scaler.scale_
        
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„95%ç½®ä¿¡åŒºé—´ (å‡å€¼Â±2æ ‡å‡†å·®)
        for i, feature in enumerate(self.feature_names):
            if i < len(means) and i < len(stds):
                mean_val = means[i]
                std_val = stds[i]
                self.training_ranges[feature] = {
                    'mean': mean_val,
                    'std': std_val,
                    'min': mean_val - 2 * std_val,  # è¿‘ä¼¼95%ç½®ä¿¡åŒºé—´ä¸‹é™
                    'max': mean_val + 2 * std_val,  # è¿‘ä¼¼95%ç½®ä¿¡åŒºé—´ä¸Šé™
                }
        
        if self.training_ranges:
            log(f"å·²æå– {len(self.training_ranges)} ä¸ªç‰¹å¾çš„è®­ç»ƒèŒƒå›´")
    
    def load_model(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹ç»„ä»¶"""
        try:
            # 1. æŸ¥æ‰¾æ¨¡å‹ç›®å½•
            self.model_dir = self.find_model_directory()
            log(f"ä½¿ç”¨æ¨¡å‹ç›®å½•: {self.model_dir}")
            
            # 2. åŠ è½½å…ƒæ•°æ®
            metadata_path = os.path.join(self.model_dir, 'metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r') as f:
                    self.metadata = json.load(f)
                
                # è·å–ç‰¹å¾åç§°å’Œç›®æ ‡å˜é‡
                self.feature_names = self.metadata.get('feature_names', None)
                if self.metadata.get('target_name'):
                    self.target_name = self.metadata['target_name']
                
                log(f"ä»å…ƒæ•°æ®åŠ è½½ç‰¹å¾åˆ—è¡¨: {self.feature_names}")
                log(f"ç›®æ ‡å˜é‡: {self.target_name}")
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ {metadata_path}")
                # ä½¿ç”¨é»˜è®¤ç‰¹å¾åˆ—è¡¨ - å¿…é¡»ä¸æ¨¡å‹è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
                self.feature_names = [
                    'C(%)', 'H(%)', 'O(%)', 'N(%)', 'Ash(%)', 'VM(%)', 'FC(%)', 
                    'PT(Â°C)', 'HR(â„ƒ/min)', 'RT(min)'
                ]
                log(f"ä½¿ç”¨é»˜è®¤ç‰¹å¾åˆ—è¡¨: {self.feature_names}")
            
            # 3. åŠ è½½æ¨¡å‹
            models_dir = os.path.join(self.model_dir, 'models')
            if os.path.exists(models_dir):
                model_files = sorted(glob.glob(os.path.join(models_dir, 'model_*.joblib')))
                if model_files:
                    for model_file in model_files:
                        model = joblib.load(model_file)
                        self.models.append(model)
                        log(f"åŠ è½½æ¨¡å‹: {os.path.basename(model_file)}")
                else:
                    log(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶åœ¨ {models_dir}")
                    return False
            else:
                log(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
                return False
            
            # 4. åŠ è½½æƒé‡
            weights_path = os.path.join(self.model_dir, 'model_weights.npy')
            if os.path.exists(weights_path):
                self.model_weights = np.load(weights_path)
                log(f"åŠ è½½æƒé‡æ–‡ä»¶: {weights_path}")
            else:
                log(f"è­¦å‘Š: æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ {weights_path}")
                # ä½¿ç”¨å‡ç­‰æƒé‡
                self.model_weights = np.ones(len(self.models)) / len(self.models)
                log("ä½¿ç”¨å‡ç­‰æƒé‡")
            
            # 5. åŠ è½½æ ‡å‡†åŒ–å™¨
            scaler_path = os.path.join(self.model_dir, 'final_scaler.joblib')
            if os.path.exists(scaler_path):
                self.final_scaler = joblib.load(scaler_path)
                log(f"åŠ è½½æ ‡å‡†åŒ–å™¨: {scaler_path}")
                
                # æ‰“å°æ ‡å‡†åŒ–å™¨ä¿¡æ¯
                if hasattr(self.final_scaler, 'mean_'):
                    log(f"ç‰¹å¾å‡å€¼: {self.final_scaler.mean_}")
                if hasattr(self.final_scaler, 'scale_'):
                    log(f"ç‰¹å¾æ ‡å‡†å·®: {self.final_scaler.scale_}")
                
                # æå–è®­ç»ƒæ•°æ®èŒƒå›´
                self.extract_training_ranges()
            else:
                log(f"é”™è¯¯: æœªæ‰¾åˆ°æ ‡å‡†åŒ–å™¨æ–‡ä»¶ {scaler_path}")
                return False
            
            # 6. åŠ è½½ç‰¹å¾é‡è¦æ€§
            self.load_feature_importance()
            
            log(f"æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹")
            return True
            
        except Exception as e:
            log(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            return False
    
    def check_input_range(self, input_df):
        """æ£€æŸ¥è¾“å…¥å€¼æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®èŒƒå›´å†…"""
        warnings = []
        
        if not self.training_ranges:
            log("è­¦å‘Š: æ²¡æœ‰è®­ç»ƒæ•°æ®èŒƒå›´ä¿¡æ¯ï¼Œè·³è¿‡èŒƒå›´æ£€æŸ¥")
            return warnings
        
        for feature, range_info in self.training_ranges.items():
            if feature in input_df.columns:
                value = input_df[feature].iloc[0]
                # æ£€æŸ¥æ˜¯å¦è¶…å‡ºè®­ç»ƒæ•°æ®çš„95%ç½®ä¿¡åŒºé—´
                if value < range_info['min'] or value > range_info['max']:
                    warning = f"{feature}: {value:.1f} (è¶…å‡ºè®­ç»ƒèŒƒå›´ {range_info['min']:.1f} - {range_info['max']:.1f})"
                    warnings.append(warning)
                    log(f"è­¦å‘Š: {warning}")
        
        return warnings
    
    def predict(self, input_features, return_individual=False):
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        try:
            # éªŒè¯æ¨¡å‹
            if not self.models or len(self.models) == 0:
                log("é”™è¯¯: æ²¡æœ‰åŠ è½½æ¨¡å‹")
                return np.array([0.0])
            
            if not self.final_scaler:
                log("é”™è¯¯: æ²¡æœ‰åŠ è½½æ ‡å‡†åŒ–å™¨")
                return np.array([0.0])
            
            # ç¡®ä¿è¾“å…¥ç‰¹å¾åŒ…å«æ‰€æœ‰å¿…è¦ç‰¹å¾
            missing_features = []
            if self.feature_names:
                for feature in self.feature_names:
                    if feature not in input_features.columns:
                        missing_features.append(feature)
            
            if missing_features:
                missing_str = ", ".join(missing_features)
                log(f"é”™è¯¯: è¾“å…¥ç¼ºå°‘ä»¥ä¸‹ç‰¹å¾: {missing_str}")
                return np.array([0.0])
            
            # æŒ‰ç…§æ¨¡å‹å®šä¹‰çš„ç‰¹å¾é¡ºåºé‡æ–°æ’åˆ—
            if self.feature_names:
                input_ordered = input_features[self.feature_names].copy()
                log("è¾“å…¥ç‰¹å¾å·²æŒ‰ç…§è®­ç»ƒæ—¶çš„é¡ºåºæ’åˆ—")
            else:
                input_ordered = input_features
                log("è­¦å‘Š: æ²¡æœ‰ç‰¹å¾åç§°åˆ—è¡¨ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥é¡ºåº")
            
            # è®°å½•è¾“å…¥æ•°æ®
            log(f"é¢„æµ‹è¾“å…¥æ•°æ®: {input_ordered.iloc[0].to_dict()}")
            
            # åº”ç”¨æ ‡å‡†åŒ–
            X_scaled = self.final_scaler.transform(input_ordered)
            log(f"æ•°æ®å·²æ ‡å‡†åŒ–ï¼Œå½¢çŠ¶: {X_scaled.shape}")
            
            # ä½¿ç”¨æ¯ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹
            individual_predictions = []
            all_predictions = np.zeros((input_ordered.shape[0], len(self.models)))
            
            for i, model in enumerate(self.models):
                pred = model.predict(X_scaled)
                all_predictions[:, i] = pred
                individual_predictions.append(float(pred[0]))
                log(f"æ¨¡å‹ {i} é¢„æµ‹ç»“æœ: {pred[0]:.2f}")
            
            # è®¡ç®—åŠ æƒå¹³å‡
            weighted_pred = np.sum(all_predictions * self.model_weights.reshape(1, -1), axis=1)
            log(f"æœ€ç»ˆåŠ æƒé¢„æµ‹ç»“æœ: {weighted_pred[0]:.2f}")
            
            if return_individual:
                return weighted_pred, individual_predictions
            else:
                return weighted_pred
            
        except Exception as e:
            log(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            return np.array([0.0])
    
    def get_feature_importance_plot(self):
        """ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾"""
        if self.feature_importance is None or len(self.feature_importance) == 0:
            return None
        
        try:
            # åˆ›å»ºå›¾è¡¨
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # æå–æ•°æ®
            features = self.feature_importance['Feature'].tolist()
            importance = self.feature_importance['Importance'].tolist()
            
            # åè½¬é¡ºåºï¼Œä½¿æœ€é‡è¦çš„ç‰¹å¾æ˜¾ç¤ºåœ¨é¡¶éƒ¨
            features.reverse()
            importance.reverse()
            
            # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
            ax.barh(features, importance, color='skyblue')
            
            # æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title('ç‰¹å¾é‡è¦æ€§åˆ†æ', fontsize=14)
            ax.set_xlabel('é‡è¦æ€§å¾—åˆ†', fontsize=12)
            ax.set_ylabel('ç‰¹å¾', fontsize=12)
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout()
            
            # å°†å›¾è¡¨è½¬æ¢ä¸ºå›¾åƒ
            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=100)
            buf.seek(0)
            
            # ä½¿ç”¨PILæ‰“å¼€å›¾åƒå¹¶è¿”å›
            img = Image.open(buf)
            return img
            
        except Exception as e:
            log(f"åˆ›å»ºç‰¹å¾é‡è¦æ€§å›¾æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯æ‘˜è¦"""
        info = {
            "æ¨¡å‹ç±»å‹": "CatBoosté›†æˆæ¨¡å‹",
            "æ¨¡å‹æ•°é‡": len(self.models),
            "ç‰¹å¾æ•°é‡": len(self.feature_names) if self.feature_names else 0,
            "ç›®æ ‡å˜é‡": self.target_name
        }
        
        # æ·»åŠ æ€§èƒ½ä¿¡æ¯
        if self.metadata and 'performance' in self.metadata:
            performance = self.metadata['performance']
            info["æµ‹è¯•é›†RÂ²"] = f"{performance.get('test_r2', 'N/A'):.4f}"
            info["æµ‹è¯•é›†RMSE"] = f"{performance.get('test_rmse', 'N/A'):.2f}"
        
        # æ·»åŠ ç‰¹å¾é‡è¦æ€§ä¿¡æ¯
        if self.feature_importance is not None and len(self.feature_importance) > 0:
            top_features = self.feature_importance.head(3)
            info["é‡è¦ç‰¹å¾"] = ", ".join(top_features['Feature'].tolist())
        
        return info

# åˆå§‹åŒ–é¢„æµ‹å™¨
predictor = CatBoostEnsemblePredictor()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False
if 'prediction_result' not in st.session_state:
    st.session_state.prediction_result = None
if 'warnings' not in st.session_state:
    st.session_state.warnings = []
if 'individual_predictions' not in st.session_state:
    st.session_state.individual_predictions = []

# å®šä¹‰é»˜è®¤å€¼ - ä»ç”¨æˆ·æ—¥å¿—ä¸­æå–
default_values = {
    "C(%)": 38.3,
    "H(%)": 5.5,
    "O(%)": 55.2,
    "N(%)": 0.6,
    "Ash(%)": 6.6,
    "VM(%)": 81.1,
    "FC(%)": 10.3,
    "PT(Â°C)": 500.0,  # æ”¹ä¸ºæ›´åˆç†çš„æ¸©åº¦
    "HR(â„ƒ/min)": 10.0,
    "RT(min)": 60.0
}

# ç‰¹å¾åˆ†ç±»
feature_categories = {
    "Ultimate Analysis": ["C(%)", "H(%)", "O(%)", "N(%)"],
    "Proximate Analysis": ["Ash(%)", "VM(%)", "FC(%)"],
    "Pyrolysis Conditions": ["PT(Â°C)", "HR(â„ƒ/min)", "RT(min)"]
}

# é¢œè‰²é…ç½®
category_colors = {
    "Ultimate Analysis": "#DAA520",  # é»„è‰²
    "Proximate Analysis": "#32CD32",  # ç»¿è‰²
    "Pyrolysis Conditions": "#FF7F50"  # æ©™è‰²
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# Ultimate Analysis - ç¬¬ä¸€åˆ—
with col1:
    category = "Ultimate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=0.0, 
                max_value=100.0, 
                value=value, 
                key=f"{category}_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# Proximate Analysis - ç¬¬äºŒåˆ—
with col2:
    category = "Proximate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=0.0, 
                max_value=100.0, 
                value=value, 
                key=f"{category}_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# Pyrolysis Conditions - ç¬¬ä¸‰åˆ—
with col3:
    category = "Pyrolysis Conditions"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        # æ ¹æ®ç‰¹å¾è®¾ç½®èŒƒå›´
        if feature == "PT(Â°C)":
            min_val, max_val = 200.0, 900.0
        elif feature == "HR(â„ƒ/min)":
            min_val, max_val = 1.0, 100.0
        elif feature == "RT(min)":
            min_val, max_val = 0.0, 120.0
        else:
            min_val, max_val = 0.0, 100.0
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            features[feature] = st.number_input(
                "", 
                min_value=min_val, 
                max_value=max_val, 
                value=value, 
                key=f"{category}_{feature}", 
                format="%.1f",
                label_visibility="collapsed"
            )

# é‡ç½®çŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.clear_pressed = False

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
result_container = st.container()

# é¢„æµ‹æŒ‰é’®åŒºåŸŸ
col1, col2 = st.columns([5, 1])

with col2:
    # é¢„æµ‹æŒ‰é’®
    predict_button = st.button("PUSH", type="primary")
    
    # ClearæŒ‰é’®
    def clear_values():
        st.session_state.clear_pressed = True
        st.session_state.prediction_result = None
        st.session_state.warnings = []
        st.session_state.individual_predictions = []
    
    clear_button = st.button("CLEAR", on_click=clear_values)

# åˆ›å»ºè¾“å…¥æ•°æ®DataFrame
input_data = pd.DataFrame([features])

# é¢„æµ‹æµç¨‹
if predict_button:
    log("="*40)
    log("å¼€å§‹æ–°é¢„æµ‹")
    
    try:
        # æ£€æŸ¥è¾“å…¥èŒƒå›´
        warnings = predictor.check_input_range(input_data)
        st.session_state.warnings = warnings
        
        # æ‰§è¡Œé¢„æµ‹
        result, individual_preds = predictor.predict(input_data, return_individual=True)
        
        # ä¿å­˜ç»“æœ
        st.session_state.prediction_result = float(result[0])
        st.session_state.individual_predictions = individual_preds
        
        log(f"é¢„æµ‹æˆåŠŸå®Œæˆ: {st.session_state.prediction_result:.2f}")
        
    except Exception as e:
        log(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")

# æ˜¾ç¤ºç»“æœ
with result_container:
    # ä¸»é¢„æµ‹ç»“æœ
    st.subheader("Char Yield (wt%)")
    
    if st.session_state.prediction_result is not None:
        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        st.markdown(
            f"<div class='yield-result'>{st.session_state.prediction_result:.2f}</div>",
            unsafe_allow_html=True
        )
        
        # æ˜¾ç¤ºè­¦å‘Š
        if st.session_state.warnings:
            warning_html = "<div class='warning-box'><b>âš ï¸ è­¦å‘Š:</b> ä»¥ä¸‹è¾“å…¥å€¼è¶…å‡ºè®­ç»ƒèŒƒå›´ï¼Œå¯èƒ½å½±å“é¢„æµ‹å‡†ç¡®æ€§:<ul>"
            for warning in st.session_state.warnings:
                warning_html += f"<li>{warning}</li>"
            warning_html += "</ul></div>"
            st.markdown(warning_html, unsafe_allow_html=True)
        
        # æ¨¡å‹è¯¦ç»†ä¿¡æ¯åŒºåŸŸ
        with st.expander("é¢„æµ‹è¯¦æƒ…", expanded=False):
            # æ˜¾ç¤ºå„ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
            if st.session_state.individual_predictions:
                st.write("å„æ¨¡å‹é¢„æµ‹å€¼:")
                pred_df = pd.DataFrame({
                    'æ¨¡å‹': [f"æ¨¡å‹ {i+1}" for i in range(len(st.session_state.individual_predictions))],
                    'é¢„æµ‹å€¼': st.session_state.individual_predictions
                })
                st.dataframe(pred_df)
                
                # è®¡ç®—æ ‡å‡†å·®
                std_dev = np.std(st.session_state.individual_predictions)
                st.write(f"æ¨¡å‹é—´é¢„æµ‹æ ‡å‡†å·®: {std_dev:.2f} (è¾ƒå¤§çš„æ ‡å‡†å·®è¡¨ç¤ºæ¨¡å‹æ„è§ä¸ä¸€è‡´)")
                
                # ç®€å•æŸ±çŠ¶å›¾
                st.bar_chart(pred_df.set_index('æ¨¡å‹'))
            
            # æ˜¾ç¤ºè¾“å…¥ç‰¹å¾åŠå…¶é‡è¦æ€§
            if predictor.feature_importance is not None:
                st.write("è¾“å…¥ç‰¹å¾å€¼åŠå…¶é‡è¦æ€§æ’å:")
                
                # åˆå¹¶ç‰¹å¾é‡è¦æ€§å’Œè¾“å…¥å€¼
                input_values = input_data.iloc[0].to_dict()
                importance_data = predictor.feature_importance.copy()
                
                # è®¡ç®—æ’å
                importance_data['æ’å'] = importance_data.index + 1
                
                # æ·»åŠ è¾“å…¥å€¼åˆ—
                importance_data['è¾“å…¥å€¼'] = importance_data['Feature'].map(input_values)
                
                # è°ƒæ•´æ˜¾ç¤ºåˆ—
                display_df = importance_data[['æ’å', 'Feature', 'è¾“å…¥å€¼', 'Importance']]
                display_df.columns = ['æ’å', 'ç‰¹å¾', 'è¾“å…¥å€¼', 'é‡è¦æ€§å¾—åˆ†']
                
                st.dataframe(display_df)
                
                # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§å›¾
                importance_img = predictor.get_feature_importance_plot()
                if importance_img:
                    st.image(importance_img, caption="ç‰¹å¾é‡è¦æ€§åˆ†æ", use_column_width=True)

# æ·»åŠ æ¨¡å‹ä¿¡æ¯åŒºåŸŸ
with st.expander("About the Model", expanded=False):
    # å·¦å³ä¸¤åˆ—å¸ƒå±€
    info_col, chart_col = st.columns([1, 1])
    
    with info_col:
        st.write("### æ¨¡å‹ä¿¡æ¯")
        model_info = predictor.get_model_info()
        for key, value in model_info.items():
            st.write(f"**{key}:** {value}")
        
        st.write("### å…³é”®å½±å“å› ç´ ")
        st.markdown("""
        * **çƒ­è§£æ¸©åº¦(PT)**: æ›´é«˜çš„æ¸©åº¦é€šå¸¸ä¼šé™ä½ç„¦ç‚­äº§ç‡
        * **åœç•™æ—¶é—´(RT)**: æ›´é•¿çš„åœç•™æ—¶é—´é€šå¸¸ä¼šå¢åŠ ç„¦ç‚­äº§ç‡
        * **ç”Ÿç‰©è´¨æˆåˆ†**: ç¢³å«é‡å’Œç°åˆ†å«é‡æ˜¾è‘—å½±å“æœ€ç»ˆäº§ç‡
        """)
        
    with chart_col:
        if predictor.feature_importance is not None:
            importance_img = predictor.get_feature_importance_plot()
            if importance_img:
                st.image(importance_img, caption="ç‰¹å¾é‡è¦æ€§åˆ†æ", use_column_width=True)

# æ·»åŠ é¡µè„š
st.markdown("---")
st.caption("Â© 2023 Biomass Pyrolysis Research Team. All rights reserved.")