import numpy as np
import pandas as pd
import streamlit as st
import os
import joblib
import logging
import json
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    handlers=[logging.StreamHandler()])
logger = logging.getLogger("Pyrolysis_Predictor")

class DirectPredictor:
    """
    ç›´æ¥é¢„æµ‹å™¨ - æ— éœ€ä¾èµ–externalæ¨¡å—ï¼Œç›´æ¥åŠ è½½ä¿å­˜çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
    """
    def __init__(self, models_dir=None):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨
        
        å‚æ•°:
            models_dir: æ¨¡å‹ä¿å­˜ç›®å½•ï¼Œé»˜è®¤æŸ¥æ‰¾å¸¸è§ä½ç½®
        """
        self.models_dir = self._find_model_directory() if models_dir is None else models_dir
        logger.info(f"ä½¿ç”¨æ¨¡å‹ç›®å½•: {self.models_dir}")
        
        self.models = []
        self.model_weights = None
        self.final_scaler = None
        self.feature_names = None
        self.metadata = None
        self.target_name = "Char Yield(%)"
        
        # åŠ è½½æ‰€æœ‰éœ€è¦çš„æ¨¡å‹ç»„ä»¶
        try:
            self._load_all_components()
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡å‹ç»„ä»¶æ—¶å‡ºé”™: {str(e)}")
            raise
    
    def _find_model_directory(self):
        """æŸ¥æ‰¾æ¨¡å‹ç›®å½•"""
        # å¸¸è§çš„æ¨¡å‹ç›®å½•ä½ç½®
        common_locations = [
            "Char_Yield_Model",  # å½“å‰ç›®å½•
            "../Char_Yield_Model",  # ä¸Šä¸€çº§ç›®å½•
            "models/Char_Yield_Model",  # modelså­ç›®å½•
            "C:/Users/HWY/Desktop/æ–¹-3/Char_Yield_Model"  # ç»å¯¹è·¯å¾„
        ]
        
        for location in common_locations:
            if os.path.exists(location) and os.path.isdir(location):
                return location
        
        # å¦‚æœæ‰¾ä¸åˆ°é¢„è®¾ä½ç½®ï¼Œå°è¯•åœ¨å½“å‰ç›®å½•ä¸‹æŸ¥æ‰¾
        current_dir = os.getcwd()
        for item in os.listdir(current_dir):
            item_path = os.path.join(current_dir, item)
            if os.path.isdir(item_path) and "model" in item.lower():
                return item_path
        
        # å¦‚æœä¾ç„¶æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºé”™è¯¯
        raise FileNotFoundError("æ— æ³•æ‰¾åˆ°æ¨¡å‹ç›®å½•ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šmodels_dirå‚æ•°")
    
    def _load_all_components(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹ç»„ä»¶"""
        # åŠ è½½å…ƒæ•°æ®
        metadata_path = os.path.join(self.models_dir, 'metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r') as f:
                self.metadata = json.load(f)
            self.feature_names = self.metadata.get('feature_names', None)
            logger.info(f"å·²åŠ è½½å…ƒæ•°æ®ï¼Œç‰¹å¾åˆ—è¡¨: {self.feature_names}")
        else:
            # å¦‚æœæ‰¾ä¸åˆ°å…ƒæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾é¡ºåº
            self.feature_names = [
                'PT(Â°C)', 'RT(min)', 'HT(Â°C/min)', 
                'C(%)', 'H(%)', 'O(%)', 'N(%)',
                'Ash(%)', 'VM(%)', 'FC(%)'
            ]
            logger.warning(f"æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾é¡ºåº: {self.feature_names}")
        
        # åŠ è½½æ¨¡å‹
        models_dir = os.path.join(self.models_dir, 'models')
        if os.path.exists(models_dir):
            model_files = [f for f in os.listdir(models_dir) if f.startswith('model_') and f.endswith('.joblib')]
            model_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))  # ç¡®ä¿æŒ‰é¡ºåºåŠ è½½
            
            for model_file in model_files:
                model_path = os.path.join(models_dir, model_file)
                self.models.append(joblib.load(model_path))
            logger.info(f"å·²åŠ è½½ {len(self.models)} ä¸ªæ¨¡å‹")
        else:
            raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir}")
        
        # åŠ è½½æƒé‡
        weights_path = os.path.join(self.models_dir, 'model_weights.npy')
        if os.path.exists(weights_path):
            self.model_weights = np.load(weights_path)
            logger.info(f"å·²åŠ è½½æ¨¡å‹æƒé‡ï¼Œå½¢çŠ¶: {self.model_weights.shape}")
        else:
            # å¦‚æœæ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨å¹³å‡æƒé‡
            self.model_weights = np.ones(len(self.models)) / len(self.models)
            logger.warning("æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨å¹³å‡æƒé‡")
        
        # åŠ è½½ç¼©æ”¾å™¨
        scaler_path = os.path.join(self.models_dir, 'final_scaler.joblib')
        if os.path.exists(scaler_path):
            self.final_scaler = joblib.load(scaler_path)
            logger.info("å·²åŠ è½½æ ‡å‡†åŒ–å™¨")
        else:
            raise FileNotFoundError(f"æ ‡å‡†åŒ–å™¨æ–‡ä»¶ä¸å­˜åœ¨: {scaler_path}")
    
    def predict(self, data):
        """
        é¢„æµ‹Char Yield(%)
        
        å‚æ•°:
            data: DataFrameæˆ–å­—å…¸ï¼ŒåŒ…å«ç‰¹å¾æ•°æ®
            
        è¿”å›:
            é¢„æµ‹çš„Char Yield(%)å€¼
        """
        try:
            # å¤„ç†è¾“å…¥æ•°æ®
            if isinstance(data, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºDataFrame
                data = pd.DataFrame([data])
            
            # ç¡®ä¿ç‰¹å¾é¡ºåºæ­£ç¡®
            if self.feature_names:
                # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ç‰¹å¾
                missing_features = set(self.feature_names) - set(data.columns)
                if missing_features:
                    error_msg = f"è¾“å…¥æ•°æ®ç¼ºå°‘ä»¥ä¸‹ç‰¹å¾: {missing_features}"
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                
                # é‡æ’ç‰¹å¾é¡ºåº - è¿™æ˜¯è§£å†³é¢„æµ‹ä¸å‡†ç¡®çš„å…³é”®
                data = data[self.feature_names]
                logger.info(f"ç‰¹å¾å·²æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—: {self.feature_names}")
            
            # æ ‡å‡†åŒ–æ•°æ®
            X_scaled = self.final_scaler.transform(data)
            logger.info(f"æ•°æ®å·²æ ‡å‡†åŒ–ï¼Œå½¢çŠ¶: {X_scaled.shape}")
            
            # ä½¿ç”¨æ‰€æœ‰æ¨¡å‹è¿›è¡Œé¢„æµ‹
            all_predictions = np.zeros((data.shape[0], len(self.models)))
            for i, model in enumerate(self.models):
                all_predictions[:, i] = model.predict(X_scaled)
            
            # è®¡ç®—åŠ æƒå¹³å‡
            weighted_pred = np.sum(all_predictions * self.model_weights.reshape(1, -1), axis=1)
            logger.info(f"é¢„æµ‹ç»“æœ: {weighted_pred}")
            
            return weighted_pred
            
        except Exception as e:
            logger.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            raise

# ä½¿ç”¨Streamlitåˆ›å»ºWebåº”ç”¨
st.set_page_config(
    page_title="ç”Ÿç‰©è´¨çƒ­è§£äº§ç‡é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ”¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åº”ç”¨æ ‡é¢˜
st.title("Prediction of crop biomass pyrolysis yield based on CatBoost ensemble modeling")

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ç¬¬ä¸€åˆ—: å…ƒç´ åˆ†æ
with col1:
    st.subheader("Ultimate Analysis")
    c_pct = st.number_input("C(%)", min_value=0.0, max_value=100.0, value=38.3, step=0.1)
    h_pct = st.number_input("H(%)", min_value=0.0, max_value=100.0, value=5.5, step=0.1)
    o_pct = st.number_input("O(%)", min_value=0.0, max_value=100.0, value=55.2, step=0.1)
    n_pct = st.number_input("N(%)", min_value=0.0, max_value=100.0, value=0.6, step=0.1)

# ç¬¬äºŒåˆ—: è¿‘ä¼¼åˆ†æ
with col2:
    st.subheader("Proximate Analysis")
    ash_pct = st.number_input("Ash(%)", min_value=0.0, max_value=100.0, value=6.6, step=0.1)
    vm_pct = st.number_input("VM(%)", min_value=0.0, max_value=100.0, value=81.1, step=0.1)
    fc_pct = st.number_input("FC(%)", min_value=0.0, max_value=100.0, value=10.3, step=0.1)

# ç¬¬ä¸‰åˆ—: çƒ­è§£æ¡ä»¶
with col3:
    st.subheader("Pyrolysis Conditions")
    pt_c = st.number_input("PT(Â°C)", min_value=200.0, max_value=1000.0, value=500.0, step=1.0)
    ht_c_min = st.number_input("HT(Â°C/min)", min_value=1.0, max_value=100.0, value=10.0, step=1.0)
    rt_min = st.number_input("RT(min)", min_value=0.0, max_value=500.0, value=60.0, step=1.0)

# é¢„æµ‹æŒ‰é’®
col1, col2 = st.columns([5, 1])
with col2:
    predict_button = st.button("PUSH", type="primary")
    clear_button = st.button("CLEAR")

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
result_container = st.container()

with result_container:
    # é¢„æµ‹ç»“æœ
    st.subheader("Char Yield (wt%)")
    
    # å¦‚æœç‚¹å‡»é¢„æµ‹æŒ‰é’®
    if predict_button:
        try:
            # å‡†å¤‡è¾“å…¥æ•°æ® - ç¡®ä¿ä¸è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåºå®Œå…¨ä¸€è‡´
            input_data = {
                'PT(Â°C)': pt_c,
                'RT(min)': rt_min,
                'HT(Â°C/min)': ht_c_min,
                'C(%)': c_pct,
                'H(%)': h_pct,
                'O(%)': o_pct,
                'N(%)': n_pct,
                'Ash(%)': ash_pct,
                'VM(%)': vm_pct,
                'FC(%)': fc_pct
            }
            
            # è®°å½•è¾“å…¥æ•°æ®
            logger.info(f"è¾“å…¥æ•°æ®: {input_data}")
            
            # åˆ›å»ºé¢„æµ‹å™¨å¹¶é¢„æµ‹
            predictor = DirectPredictor()
            result = predictor.predict(pd.DataFrame([input_data]))[0]
            
            # æ˜¾ç¤ºç»“æœ
            st.header(f"{result:.2f}")
            
            # è®°å½•è°ƒè¯•ä¿¡æ¯
            logger.info(f"é¢„æµ‹ç»“æœ: {result:.2f}")
            
            # æ·»åŠ åˆ°è°ƒè¯•ä¿¡æ¯åŒºåŸŸ
            with st.expander("Debug Information"):
                st.write(f"è¾“å…¥å‚æ•°: PT(Â°C): {pt_c}, H(%):{h_pct}, N(%):{n_pct}, Ash(%):{ash_pct}")
                st.write(f"O(%):{o_pct}, FC(%):{fc_pct}, RT(min):{rt_min}")
                st.write(f"VM(%):{vm_pct}, HT(Â°C/min):{ht_c_min}, C(%):{c_pct}")
                
                st.write("é¢„æµ‹è¿‡ç¨‹:")
                st.write(f"æ¨¡å‹ç›®å½•: {predictor.models_dir}")
                st.write(f"åŠ è½½äº† {len(predictor.models)} ä¸ªæ¨¡å‹")
                st.write(f"ç‰¹å¾é¡ºåº: {predictor.feature_names}")
                st.write(f"é¢„æµ‹ç»“æœ: {result:.2f}")
                
        except Exception as e:
            st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")
            logger.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

# æ¨¡å‹ä¿¡æ¯åŒºåŸŸ
with st.expander("About the Model"):
    st.write("This application uses a CatBoost ensemble model to predict char yield in biomass pyrolysis.")
    
    st.subheader("Key Factors Affecting Char Yield:")
    st.markdown("""
    * **Pyrolysis Temperature**: Higher temperature generally decreases char yield
    * **Residence Time**: Longer residence time generally increases char yield
    * **Biomass Composition**: Carbon content and ash content significantly affect the final yield
    """)
    
    st.write("The model was trained using 10-fold cross-validation with optimized hyperparameters, achieving high prediction accuracy (RÂ² = 0.93, RMSE = 3.39 on test set).")

# æ·»åŠ é¡µè„š
st.markdown("---")
st.caption("Â© 2023 Biomass Pyrolysis Research Team. All rights reserved.")