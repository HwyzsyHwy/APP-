# -*- coding: utf-8 -*-
"""
Biomass Pyrolysis Yield Forecast using GBDT Ensemble Models
ä¿®å¤ç‰ˆæœ¬ - ç¡®ä¿Pipelineæ­£ç¡®é¢„æµ‹
æ”¯æŒCharã€Oilå’ŒGasäº§ç‡é¢„æµ‹
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import glob
import joblib
import traceback
import matplotlib.pyplot as plt
from datetime import datetime
import sys

# æ¸…é™¤ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°æ¸²æŸ“
st.cache_data.clear()

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title='Biomass Pyrolysis Yield Prediction',
    page_icon='ğŸ”¥',
    layout='wide',
    initial_sidebar_state='expanded'
)

# è‡ªå®šä¹‰æ ·å¼ï¼ˆä¿æŒåŸæ ·ï¼‰
st.markdown(
    """
    <style>
    /* å…¨å±€å­—ä½“è®¾ç½® */
    html, body, [class*="css"] {
        font-size: 16px !important;
    }
    
    /* æ ‡é¢˜ */
    .main-title {
        text-align: center;
        font-size: 32px !important;
        font-weight: bold;
        margin-bottom: 20px;
        color: white !important;
    }
    
    /* åŒºåŸŸæ ·å¼ */
    .section-header {
        color: white;
        font-weight: bold;
        font-size: 22px;
        text-align: center;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 15px;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 5px;
        border-radius: 5px;
        margin-bottom: 5px;
        font-size: 18px;
        color: white;
    }
    
    /* ç»“æœæ˜¾ç¤ºæ ·å¼ */
    .yield-result {
        background-color: #1E1E1E;
        color: white;
        font-size: 36px;
        font-weight: bold;
        text-align: center;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    
    /* å¼ºåˆ¶åº”ç”¨ç™½è‰²èƒŒæ™¯åˆ°è¾“å…¥æ¡† */
    [data-testid="stNumberInput"] input {
        background-color: white !important;
        color: black !important;
    }
    
    /* å¢å¤§æŒ‰é’®çš„å­—ä½“ */
    .stButton button {
        font-size: 18px !important;
    }
    
    /* è­¦å‘Šæ ·å¼ */
    .warning-box {
        background-color: rgba(255, 165, 0, 0.2);
        border-left: 5px solid orange;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* é”™è¯¯æ ·å¼ */
    .error-box {
        background-color: rgba(255, 0, 0, 0.2);
        border-left: 5px solid red;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* æˆåŠŸæ ·å¼ */
    .success-box {
        background-color: rgba(0, 128, 0, 0.2);
        border-left: 5px solid green;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* æ—¥å¿—æ ·å¼ */
    .log-container {
        height: 300px;
        overflow-y: auto;
        background-color: #1E1E1E;
        color: #00FF00;
        font-family: 'Courier New', monospace;
        padding: 10px;
        border-radius: 5px;
        font-size: 14px !important;
    }
    
    /* æ¨¡å‹é€‰æ‹©å™¨æ ·å¼ */
    .model-selector {
        background-color: #2E2E2E;
        padding: 15px;
        border-radius: 10px;
        margin-bottom: 20px;
        text-align: center;
    }
    
    /* æ¨¡å‹åˆ‡æ¢æŒ‰é’®ç»„æ ·å¼ */
    div[data-testid="stHorizontalBlock"] [data-testid="stButton"] {
        margin: 0 5px;
    }
    
    /* å¡«æ»¡å±å¹• */
    .stApp {
        width: 100%;
        min-width: 100%;
        margin: 0 auto;
    }
    
    .main .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
        max-width: 100%;
    }
    
    /* ä¾§è¾¹æ æ¨¡å‹ä¿¡æ¯æ ·å¼ */
    .sidebar-model-info {
        background-color: #2E2E2E;
        padding: 10px;
        border-radius: 5px;
        margin-top: 20px;
    }
    
    /* æ€§èƒ½æŒ‡æ ‡æ ·å¼ */
    .performance-metrics {
        background-color: #2E2E2E;
        padding: 10px;
        border-radius: 5px;
        margin-top: 10px;
    }
    
    /* æŠ€æœ¯è¯´æ˜æ ·å¼ */
    .tech-info {
        background-color: #2E2E2E;
        padding: 15px;
        border-radius: 8px;
        margin-top: 20px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# åˆ›å»ºä¾§è¾¹æ æ—¥å¿—åŒºåŸŸ
log_container = st.sidebar.container()
log_container.markdown("<h3>æ‰§è¡Œæ—¥å¿—</h3>", unsafe_allow_html=True)
log_text = st.sidebar.empty()

# åˆå§‹åŒ–æ—¥å¿—å­—ç¬¦ä¸²
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []

def log(message):
    """è®°å½•æ—¥å¿—åˆ°ä¾§è¾¹æ å’Œä¼šè¯çŠ¶æ€"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    st.session_state.log_messages.append(log_entry)
    # åªä¿ç•™æœ€è¿‘çš„100æ¡æ—¥å¿—
    if len(st.session_state.log_messages) > 100:
        st.session_state.log_messages = st.session_state.log_messages[-100:]
    
    # æ›´æ–°æ—¥å¿—æ˜¾ç¤º
    log_text.markdown(
        f"<div class='log-container'>{'<br>'.join(st.session_state.log_messages)}</div>", 
        unsafe_allow_html=True
    )

# è®°å½•å¯åŠ¨æ—¥å¿—
log("åº”ç”¨å¯åŠ¨ - ä¿®æ”¹ç‰ˆæœ¬")
log("å·²ä¿®å¤ç‰¹å¾åç§°å’Œåˆ—é¡ºåºé—®é¢˜")
log("å·²ä¿®å¤æ¨¡å‹åŠ è½½é—®é¢˜ - å¢åŠ å¯¹é›†æˆæ¨¡å‹çš„æ”¯æŒ")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ - æ·»åŠ æ¨¡å‹é€‰æ‹©åŠŸèƒ½
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "Char Yield"  # é»˜è®¤é€‰æ‹©Charäº§ç‡æ¨¡å‹
    log(f"åˆå§‹åŒ–é€‰å®šæ¨¡å‹: {st.session_state.selected_model}")

# æ·»åŠ æ¨¡å‹ç¼“å­˜ - é¿å…é‡å¤åŠ è½½ç›¸åŒæ¨¡å‹
if 'model_cache' not in st.session_state:
    st.session_state.model_cache = {}
    
# æ›´æ–°ä¸»æ ‡é¢˜ä»¥æ˜¾ç¤ºå½“å‰é€‰å®šçš„æ¨¡å‹
st.markdown("<h1 class='main-title'>åŸºäºGBDTé›†æˆæ¨¡å‹çš„ç”Ÿç‰©è´¨çƒ­è§£äº§ç‰©é¢„æµ‹ç³»ç»Ÿ</h1>", unsafe_allow_html=True)

# æ·»åŠ æ¨¡å‹é€‰æ‹©åŒºåŸŸ - ä¿®æ”¹ä¸ºä¸‰ä¸ªæŒ‰é’®ä¸€æ’
st.markdown("<div class='model-selector'>", unsafe_allow_html=True)
st.markdown("<h3>é€‰æ‹©é¢„æµ‹ç›®æ ‡</h3>", unsafe_allow_html=True)
col1, col2, col3 = st.columns(3)
with col1:
    char_button = st.button(" Char Yield", 
                           key="char_button", 
                           help="é¢„æµ‹ç„¦ç‚­äº§ç‡ (wt%)", 
                           use_container_width=True,
                           type="primary" if st.session_state.selected_model == "Char Yield" else "secondary")
with col2:
    oil_button = st.button(" Oil Yield", 
                          key="oil_button", 
                          help="é¢„æµ‹ç”Ÿç‰©æ²¹äº§ç‡ (wt%)", 
                          use_container_width=True,
                          type="primary" if st.session_state.selected_model == "Oil Yield" else "secondary")
with col3:
    gas_button = st.button(" Gas Yield", 
                          key="gas_button", 
                          help="é¢„æµ‹æ°”ä½“äº§ç‡ (wt%)", 
                          use_container_width=True,
                          type="primary" if st.session_state.selected_model == "Gas Yield" else "secondary")

# å¤„ç†æ¨¡å‹é€‰æ‹© - ä¿®æ”¹ä¸ºåˆ‡æ¢æ¨¡å‹æ—¶ä¸é‡ç½®è¾“å…¥å€¼
if char_button and st.session_state.selected_model != "Char Yield":
    st.session_state.selected_model = "Char Yield"
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {st.session_state.selected_model}")
    st.rerun()

if oil_button and st.session_state.selected_model != "Oil Yield":
    st.session_state.selected_model = "Oil Yield"
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {st.session_state.selected_model}")
    st.rerun()

if gas_button and st.session_state.selected_model != "Gas Yield":
    st.session_state.selected_model = "Gas Yield"
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {st.session_state.selected_model}")
    st.rerun()

st.markdown(f"<p style='text-align:center;'>å½“å‰æ¨¡å‹: <b>{st.session_state.selected_model}</b></p>", unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)

# ä½¿ç”¨ä¿®æ”¹åçš„åˆ†æ®µæ ¡æ­£åŠŸèƒ½
def apply_ranged_correction(predictions, y_true=None, correction_factors=None, value_ranges=None):
    """åˆ†æ®µæ ¡æ­£å‡½æ•°ï¼Œå¯è¢«ç›´æ¥è°ƒç”¨"""
    if correction_factors is None or value_ranges is None:
        return predictions
        
    predictions = np.array(predictions).ravel()
    corrected = np.zeros_like(predictions)
    
    # ç¡®å®šç”¨äºé€‰æ‹©æ ¡æ­£ç³»æ•°çš„å€¼
    if y_true is not None:
        # å¦‚æœy_trueæ˜¯DataFrameï¼Œå…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(y_true, pd.DataFrame):
            selector = y_true.values.ravel()
        else:
            selector = np.array(y_true).ravel()
    else:
        selector = predictions
    
    # å¯¹æ¯ä¸ªæ ·æœ¬åº”ç”¨é€‚å½“çš„æ ¡æ­£ç³»æ•°
    for low, high in value_ranges:
        mask = (selector >= low) & (selector < high)
        corrected[mask] = predictions[mask] * correction_factors.get((low, high), 1.0)
    
    return corrected

# æ·»åŠ ç”¨äºæ›¿ä»£ç¼ºå¤±çš„bias_corrected_predictå‡½æ•°çš„å®šä¹‰
def bias_corrected_predict(X):
    """åˆ›å»ºä¸€ä¸ªç©ºçš„å‡½æ•°æ¥æ›¿ä»£ç¼ºå¤±çš„bias_corrected_predictå‡½æ•°"""
    return X

# æ·»åŠ åœ¨Pythonå…¨å±€ç©ºé—´çš„ensemble_predictå‡½æ•°å®šä¹‰ï¼Œé¿å…ååºåˆ—åŒ–é—®é¢˜
def ensemble_predict(X_new, main_pipeline, support_pipeline, correction_factors=None, value_ranges=None, main_weight=0.8, support_weight=0.2):
    """é›†æˆé¢„æµ‹å‡½æ•°ï¼Œç»“åˆä¸»æ¨¡å‹å’Œæ”¯æŒæ¨¡å‹ï¼Œå¹¶åº”ç”¨åˆ†æ®µæ ¡æ­£"""
    # è·å–ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹
    main_preds = main_pipeline.predict(X_new)
    support_preds = support_pipeline.predict(X_new)
    
    # ç»„åˆé¢„æµ‹ç»“æœ
    combined_preds = main_preds * main_weight + support_preds * support_weight
    
    # åº”ç”¨åˆ†æ®µæ ¡æ­£
    if correction_factors and value_ranges:
        corrected_preds = apply_ranged_correction(combined_preds, 
                                                  correction_factors=correction_factors, 
                                                  value_ranges=value_ranges)
        return corrected_preds
    else:
        return combined_preds

class ModelPredictor:
    """ä¼˜åŒ–çš„é¢„æµ‹å™¨ç±» - ä¿®å¤äº†æ¨¡å‹åŠ è½½å’Œé¢„æµ‹é€»è¾‘ï¼Œæ”¯æŒé›†æˆæ¨¡å‹"""
    
    def __init__(self, target_model="Char Yield"):
        self.target_name = target_model
        self.model_path = None  # åˆå§‹åŒ–model_pathä¸ºNone
        self.pipeline = None
        self.main_pipeline = None
        self.support_pipeline = None
        self.bias_correction = 1.0  # åˆå§‹åŒ–åå·®æ ¡æ­£ç³»æ•°ä¸ºé»˜è®¤å€¼
        self.correction_factors = None
        self.value_ranges = None
        self.main_weight = 0.8
        self.support_weight = 0.2
        self.is_ensemble = False
        
        # å®šä¹‰æ­£ç¡®çš„ç‰¹å¾é¡ºåºï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰- ç§»é™¤O(wt%)
        self.feature_names = [
            'M(wt%)', 'Ash(wt%)', 'VM(wt%)', 'FC(wt%)', 
            'C(wt%)', 'H(wt%)', 'N(wt%)', 
            'PS(mm)', 'SM(g)', 'FT(â„ƒ)', 'HR(â„ƒ/min)', 
            'FR(mL/min)', 'RT(min)'
        ]
        
        # å®šä¹‰UIåˆ°æ¨¡å‹çš„ç‰¹å¾æ˜ å°„å…³ç³»
        self.ui_to_model_mapping = {
            'FT(Â°C)': 'FT(â„ƒ)',        # UIä¸Šæ˜¾ç¤ºä¸ºÂ°Cï¼Œè€Œæ¨¡å‹ä½¿ç”¨â„ƒ
            'HR(Â°C/min)': 'HR(â„ƒ/min)'  # UIä¸Šæ˜¾ç¤ºä¸ºÂ°C/minï¼Œè€Œæ¨¡å‹ä½¿ç”¨â„ƒ/min
        }
        
        # åå‘æ˜ å°„ï¼Œç”¨äºæ˜¾ç¤º
        self.model_to_ui_mapping = {v: k for k, v in self.ui_to_model_mapping.items()}
        
        # è®­ç»ƒèŒƒå›´ä¸å˜
        self.training_ranges = self._set_training_ranges()
        self.last_features = {}  # å­˜å‚¨ä¸Šæ¬¡çš„ç‰¹å¾å€¼
        self.last_result = None  # å­˜å‚¨ä¸Šæ¬¡çš„é¢„æµ‹ç»“æœ
        
        # ä½¿ç”¨ç¼“å­˜åŠ è½½æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½ç›¸åŒæ¨¡å‹
        cached_model = self._get_cached_model()
        if cached_model is not None:
            log(f"ä»ç¼“å­˜åŠ è½½{self.target_name}æ¨¡å‹")
            self._process_cached_model(cached_model)
        else:
            self.model_loaded = False
            log(f"ä»ç¼“å­˜æœªæ‰¾åˆ°æ¨¡å‹ï¼Œå°è¯•åŠ è½½{self.target_name}æ¨¡å‹")
            # æŸ¥æ‰¾å¹¶åŠ è½½æ¨¡å‹
            self.model_path = self._find_model_file()
            if self.model_path:
                self._load_pipeline()
    
    def _process_cached_model(self, cached_model):
        """å¤„ç†ç¼“å­˜ä¸­çš„æ¨¡å‹æ•°æ®"""
        if isinstance(cached_model, dict):
            # æ£€æŸ¥æ˜¯å¦æ˜¯é›†æˆæ¨¡å‹
            if 'main_pipeline' in cached_model and 'support_pipeline' in cached_model:
                self.main_pipeline = cached_model['main_pipeline']
                self.support_pipeline = cached_model['support_pipeline']
                self.pipeline = self.main_pipeline  # å…¼å®¹æ—§ä»£ç 
                self.is_ensemble = True
                
                # è·å–æ ¡æ­£ç›¸å…³ä¿¡æ¯
                if 'correction_factors' in cached_model:
                    self.correction_factors = cached_model['correction_factors']
                if 'value_ranges' in cached_model:
                    self.value_ranges = cached_model['value_ranges']
                self.main_weight = cached_model.get('main_weight', 0.8)
                self.support_weight = cached_model.get('support_weight', 0.2)
                
                log(f"ä»ç¼“å­˜åŠ è½½é›†æˆæ¨¡å‹ (æ ¡æ­£å› å­: {len(self.correction_factors) if self.correction_factors else 0})")
                self.model_loaded = True
            elif 'pipeline' in cached_model:
                self.pipeline = cached_model['pipeline']
                if 'bias_correction' in cached_model:
                    self.bias_correction = cached_model['bias_correction']
                    log(f"ä»ç¼“å­˜åŠ è½½åå·®æ ¡æ­£ç³»æ•°: {self.bias_correction}")
                self.is_ensemble = False
                self.model_loaded = True
            else:
                self.model_loaded = False
        else:
            self.pipeline = cached_model
            self.is_ensemble = False
            self.model_loaded = True
            
    def _get_cached_model(self):
        """ä»ç¼“å­˜ä¸­è·å–æ¨¡å‹"""
        if self.target_name in st.session_state.model_cache:
            log(f"ä»ç¼“å­˜åŠ è½½{self.target_name}æ¨¡å‹")
            return st.session_state.model_cache[self.target_name]
        return None
        
    def _find_model_file(self):
        """æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶ - æ›´æ–°åçš„ç‰ˆæœ¬"""
        # ä¸ºä¸åŒäº§ç‡ç›®æ ‡è®¾ç½®ä¸åŒçš„æ¨¡å‹æ–‡ä»¶å’Œè·¯å¾„
        model_folders = {
            "Char Yield": ["ç‚­äº§ç‡", "char"],
            "Oil Yield": ["æ²¹äº§ç‡", "oil"],
            "Gas Yield": ["æ°”äº§ç‡", "gas"] 
        }
        
        # è·å–åŸºæœ¬åç§°å’Œæ–‡ä»¶å¤¹
        model_id = self.target_name.split(" ")[0].lower()
        folders = model_folders.get(self.target_name, ["", model_id.lower()])
        
        # å°è¯•å¸¸è§çš„æ¨¡å‹æ–‡ä»¶åå’Œè·¯å¾„
        search_dirs = [".", "./models", "../models", "/app/models", "/app"]
        for folder in folders:
            search_dirs.append(f"./{folder}")
            search_dirs.append(f"../{folder}")
        
        # åœ¨æ‰€æœ‰å¯èƒ½çš„ç›®å½•ä¸­æœç´¢æ¨¡å‹æ–‡ä»¶
        log(f"æœç´¢{self.target_name}æ¨¡å‹æ–‡ä»¶...")
        
        for directory in search_dirs:
            if not os.path.exists(directory):
                continue
                
            # æ£€æŸ¥ç›®å½•ä¸­çš„æ‰€æœ‰.joblibæ–‡ä»¶
            try:
                for file in os.listdir(directory):
                    if file.endswith('.joblib') and model_id in file.lower():
                        if 'scaler' not in file.lower():  # æ’é™¤å•ç‹¬ä¿å­˜çš„æ ‡å‡†åŒ–å™¨
                            model_path = os.path.join(directory, file)
                            log(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
                            return model_path
            except Exception as e:
                log(f"æœç´¢ç›®å½•{directory}æ—¶å‡ºé”™: {str(e)}")
        
        log(f"æœªæ‰¾åˆ°{self.target_name}æ¨¡å‹æ–‡ä»¶")
        return None
    
    def _load_pipeline(self):
        """åŠ è½½Pipelineæ¨¡å‹ - ä¿®å¤åçš„ç‰ˆæœ¬ï¼Œæ”¯æŒé›†æˆæ¨¡å‹"""
        if not self.model_path:
            log("æ¨¡å‹è·¯å¾„ä¸ºç©ºï¼Œæ— æ³•åŠ è½½")
            return False
        
        try:
            log(f"åŠ è½½Pipelineæ¨¡å‹: {self.model_path}")
            
            # æ³¨å†Œå¯èƒ½ä¼šç”¨åˆ°çš„å‡½æ•°åˆ°å…¨å±€å‘½åç©ºé—´
            import sys
            sys.modules['__main__'].bias_corrected_predict = bias_corrected_predict
            sys.modules['__main__'].apply_ranged_correction = apply_ranged_correction
            sys.modules['__main__'].ensemble_predict = ensemble_predict
            
            try:
                # å°è¯•åŠ è½½æ¨¡å‹
                model_data = joblib.load(self.model_path)
                log("æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                log(f"å¸¸è§„åŠ è½½å¤±è´¥: {str(e)}")
                log("å°è¯•ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼åŠ è½½...")
                
                # å°è¯•ä½¿ç”¨pickleç›´æ¥åŠ è½½
                import pickle
                with open(self.model_path, 'rb') as f:
                    model_data = pickle.load(f)
                log("ä½¿ç”¨pickleæˆåŠŸåŠ è½½æ¨¡å‹")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å­—å…¸å½¢å¼ - å¤„ç†é›†æˆæ¨¡å‹ç»“æ„
            if isinstance(model_data, dict):
                log("æ£€æµ‹åˆ°ä¿å­˜çš„æ¨¡å‹æ˜¯å­—å…¸æ ¼å¼")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é›†æˆæ¨¡å‹
                if 'main_pipeline' in model_data and 'support_pipeline' in model_data:
                    log("æ£€æµ‹åˆ°é›†æˆæ¨¡å‹ç»“æ„ï¼ŒåŒ…æ‹¬ä¸»æ¨¡å‹å’Œæ”¯æŒæ¨¡å‹")
                    self.main_pipeline = model_data['main_pipeline']
                    self.support_pipeline = model_data['support_pipeline']
                    self.pipeline = self.main_pipeline  # å…¼å®¹æ—§ä»£ç 
                    self.is_ensemble = True
                    
                    # è·å–æ ¡æ­£å› å­
                    if 'correction_factors' in model_data:
                        self.correction_factors = model_data['correction_factors']
                        log(f"åŠ è½½äº†{len(self.correction_factors)}ä¸ªåˆ†æ®µæ ¡æ­£å› å­")
                    else:
                        log("æœªæ‰¾åˆ°åˆ†æ®µæ ¡æ­£å› å­ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ¡æ­£")
                        
                    # è·å–å€¼åŸŸèŒƒå›´
                    if 'value_ranges' in model_data:
                        self.value_ranges = model_data['value_ranges']
                        log(f"åŠ è½½äº†{len(self.value_ranges)}ä¸ªå€¼åŸŸèŒƒå›´")
                    
                    # è·å–æƒé‡
                    self.main_weight = model_data.get('main_weight', 0.8)
                    self.support_weight = model_data.get('support_weight', 0.2)
                    log(f"ä¸»æ¨¡å‹æƒé‡: {self.main_weight}, æ”¯æŒæ¨¡å‹æƒé‡: {self.support_weight}")
                    
                    self.model_loaded = True
                    # å°†æ¨¡å‹ä¿å­˜åˆ°ç¼“å­˜
                    st.session_state.model_cache[self.target_name] = model_data
                    return True
                
                # å¤„ç†å¸¸è§„Pipelineæ¨¡å‹
                elif 'pipeline' in model_data:
                    self.pipeline = model_data['pipeline']
                    log("ä»å­—å…¸ä¸­æå–pipelineæˆåŠŸ")
                    
                    # æå–åå·®æ ¡æ­£ç³»æ•°
                    if 'bias_correction' in model_data:
                        self.bias_correction = model_data['bias_correction']
                        log(f"æå–åˆ°åå·®æ ¡æ­£ç³»æ•°: {self.bias_correction}")
                    else:
                        self.bias_correction = 1.0
                        log("æœªæ‰¾åˆ°åå·®æ ¡æ­£ç³»æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼1.0")
                    
                    self.is_ensemble = False
                    self.model_loaded = True
                    # å°†æ¨¡å‹ä¿å­˜åˆ°ç¼“å­˜ä¸­
                    st.session_state.model_cache[self.target_name] = model_data
                    
                    # å°è¯•è¯†åˆ«Pipelineçš„ç»„ä»¶
                    if hasattr(self.pipeline, 'named_steps'):
                        components = list(self.pipeline.named_steps.keys())
                        log(f"Pipelineç»„ä»¶: {', '.join(components)}")
                    return True
                else:
                    log("æ¨¡å‹å­—å…¸ä¸­æœªæ‰¾åˆ°pipelineé”®æˆ–é›†æˆæ¨¡å‹ç»“æ„")
                    # å°è¯•ä½¿ç”¨å…¶ä»–é”®ä½œä¸ºpipeline
                    for key, value in model_data.items():
                        if hasattr(value, 'predict'):
                            log(f"ä½¿ç”¨'{key}'ä½œä¸ºpipeline")
                            self.pipeline = value
                            self.is_ensemble = False
                            self.model_loaded = True
                            st.session_state.model_cache[self.target_name] = {'pipeline': value, 'bias_correction': 1.0}
                            return True
                    
                    self.model_loaded = False
                    return False
            # ç›´æ¥æ˜¯pipelineå¯¹è±¡
            elif hasattr(model_data, 'predict'):
                log("åŠ è½½çš„æ˜¯é¢„æµ‹å™¨å¯¹è±¡")
                self.pipeline = model_data
                self.bias_correction = 1.0  # é»˜è®¤å€¼
                self.is_ensemble = False
                self.model_loaded = True
                st.session_state.model_cache[self.target_name] = {'pipeline': model_data, 'bias_correction': 1.0}
                return True
            else:
                log(f"æ— æ³•è¯†åˆ«çš„æ¨¡å‹æ ¼å¼: {type(model_data)}")
                self.model_loaded = False
                return False
                    
        except Exception as e:
            log(f"åŠ è½½æ¨¡å‹å‡ºé”™: {str(e)}")
            log(traceback.format_exc())
            
            # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•åŠ è½½
            try:
                from sklearn.ensemble import GradientBoostingRegressor
                from sklearn.pipeline import Pipeline
                from sklearn.preprocessing import RobustScaler
                
                log("å°è¯•ä½¿ç”¨pickleæ‰‹åŠ¨è§£ææ¨¡å‹æ–‡ä»¶")
                import pickle
                
                try:
                    # ä½¿ç”¨ä¸€ä¸ªå®‰å…¨æ–¹å¼åŠ è½½
                    with open(self.model_path, 'rb') as f:
                        pickle_data = f.read()
                    
                    # ä½¿ç”¨ä¿®æ”¹åçš„æ•°æ®åŠ è½½æ¨¡å‹
                    import io
                    model_data = pickle.load(io.BytesIO(pickle_data))
                    
                    if isinstance(model_data, dict):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é›†æˆæ¨¡å‹
                        if 'main_pipeline' in model_data and 'support_pipeline' in model_data:
                            log("æ£€æµ‹åˆ°é›†æˆæ¨¡å‹ç»“æ„")
                            self.main_pipeline = model_data['main_pipeline']
                            self.support_pipeline = model_data['support_pipeline']
                            self.pipeline = self.main_pipeline
                            self.is_ensemble = True
                            
                            if 'correction_factors' in model_data:
                                self.correction_factors = model_data['correction_factors']
                            if 'value_ranges' in model_data:
                                self.value_ranges = model_data['value_ranges']
                            
                            self.main_weight = model_data.get('main_weight', 0.8)
                            self.support_weight = model_data.get('support_weight', 0.2)
                            
                            log("æ‰‹åŠ¨è§£æé›†æˆæ¨¡å‹æˆåŠŸ")
                            self.model_loaded = True
                            return True
                            
                        elif 'pipeline' in model_data:
                            self.pipeline = model_data['pipeline']
                            if 'bias_correction' in model_data:
                                self.bias_correction = model_data['bias_correction']
                            log("æ‰‹åŠ¨è§£æå¸¸è§„æ¨¡å‹æˆåŠŸ")
                            self.model_loaded = True
                            return True
                except:
                    log("æ‰‹åŠ¨è§£æå¤±è´¥ï¼Œåˆ›å»ºæ›¿ä»£æ¨¡å‹")
                    self.pipeline = Pipeline([
                        ('scaler', RobustScaler()),
                        ('model', GradientBoostingRegressor(random_state=42))
                    ])
                    self.bias_correction = 1.0
                    self.is_ensemble = False
                    self.model_loaded = True
                    st.warning("åŸå§‹æ¨¡å‹æ— æ³•åŠ è½½ï¼Œä½¿ç”¨äº†æ›¿ä»£æ¨¡å‹ã€‚é¢„æµ‹ç»“æœä¸å‡†ç¡®ï¼Œä»…ç”¨äºæ¼”ç¤ºç•Œé¢åŠŸèƒ½ã€‚")
                    return True
            except:
                log("æ‰€æœ‰åŠ è½½å°è¯•éƒ½å¤±è´¥")
                self.model_loaded = False
                return False
    
    def _set_training_ranges(self):
        """è®¾ç½®è®­ç»ƒæ•°æ®çš„èŒƒå›´ - ä½¿ç”¨æ­£ç¡®çš„ç‰¹å¾åç§°ï¼Œç§»é™¤O(wt%)"""
        ranges = {
            'M(wt%)': {'min': 2.750, 'max': 12.640},
            'Ash(wt%)': {'min': 0.780, 'max': 29.510},
            'VM(wt%)': {'min': 51.640, 'max': 89.500},
            'FC(wt%)': {'min': 0.100, 'max': 23.900},
            'C(wt%)': {'min': 22.490, 'max': 53.300},
            'H(wt%)': {'min': 3.303, 'max': 8.200},
            'N(wt%)': {'min': 0.170, 'max': 4.870},
            'PS(mm)': {'min': 0.075, 'max': 10.000},
            'SM(g)': {'min': 3.000, 'max': 125.000},
            'FR(mL/min)': {'min': 0.000, 'max': 600.000},
            'RT(min)': {'min': 15.000, 'max': 90.000}
        }
        
        # æ·»åŠ æ˜ å°„åçš„ç‰¹å¾èŒƒå›´
        ranges['FT(â„ƒ)'] = {'min': 250.000, 'max': 900.000}
        ranges['HR(â„ƒ/min)'] = {'min': 1.000, 'max': 100.000}
        
        # ä¸ºUIç‰¹å¾ä¹Ÿæ·»åŠ ç›¸åŒçš„èŒƒå›´
        ranges['FT(Â°C)'] = ranges['FT(â„ƒ)']
        ranges['HR(Â°C/min)'] = ranges['HR(â„ƒ/min)']
        
        return ranges
    
    def check_input_range(self, features):
        """æ£€æŸ¥è¾“å…¥å€¼æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®èŒƒå›´å†…"""
        warnings = []
        
        for feature, value in features.items():
            # è·å–æ˜ å°„åçš„ç‰¹å¾å
            mapped_feature = self.ui_to_model_mapping.get(feature, feature)
            range_info = self.training_ranges.get(mapped_feature)
            
            if range_info:
                if value < range_info['min'] or value > range_info['max']:
                    warning = f"{feature}: {value:.2f} (è¶…å‡ºè®­ç»ƒèŒƒå›´ {range_info['min']:.2f} - {range_info['max']:.2f})"
                    warnings.append(warning)
                    log(f"è­¦å‘Š: {warning}")
        
        return warnings
    
    def _prepare_features(self, features):
        """å‡†å¤‡ç‰¹å¾ï¼Œå¤„ç†ç‰¹å¾åç§°æ˜ å°„å’Œé¡ºåº"""
        # åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameï¼Œæ‰€æœ‰ç‰¹å¾åˆå§‹åŒ–ä¸º0
        model_features = {feature: 0.0 for feature in self.feature_names}
        
        # é¦–å…ˆå°†UIç‰¹å¾æ˜ å°„åˆ°æ¨¡å‹ç‰¹å¾åç§°
        for ui_feature, value in features.items():
            model_feature = self.ui_to_model_mapping.get(ui_feature, ui_feature)
            if model_feature in self.feature_names:
                model_features[model_feature] = value
                if ui_feature != model_feature:
                    log(f"ç‰¹å¾æ˜ å°„: '{ui_feature}' -> '{model_feature}'")
        
        # åˆ›å»ºDataFrameå¹¶æŒ‰ç…§æ­£ç¡®é¡ºåºæ’åˆ—åˆ—
        df = pd.DataFrame([model_features])
        
        # ç¡®ä¿åˆ—é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
        df = df[self.feature_names]
        
        log(f"å‡†å¤‡å¥½çš„ç‰¹å¾ï¼Œåˆ—é¡ºåº: {list(df.columns)}")
        return df
    
    def _check_features_changed(self, features):
        """æ£€æŸ¥å½“å‰ç‰¹å¾æ˜¯å¦ä¸ä¸Šæ¬¡é¢„æµ‹çš„ç‰¹å¾æœ‰å˜åŒ–"""
        if not self.last_features:
            return True
            
        for feature, value in features.items():
            if feature in self.last_features and abs(self.last_features[feature] - value) > 0.001:
                return True
        return False
    
    def _apply_ranged_correction(self, prediction):
        """åº”ç”¨åˆ†æ®µæ ¡æ­£åˆ°å•ä¸ªé¢„æµ‹å€¼"""
        # è¿™ä¸ªæ–¹æ³•ç”¨äºå•ä¸ªé¢„æµ‹å€¼
        if not self.correction_factors or not self.value_ranges:
            return prediction * self.bias_correction
            
        # æŸ¥æ‰¾é€‚å½“çš„æ ¡æ­£å› å­
        for low, high in self.value_ranges:
            if low <= prediction < high:
                correction = self.correction_factors.get((low, high), self.bias_correction)
                log(f"å¯¹å€¼ {prediction:.2f} åº”ç”¨èŒƒå›´ {low}-{high} çš„æ ¡æ­£ç³»æ•° {correction:.4f}")
                return prediction * correction
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„èŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤æ ¡æ­£
        log(f"æœªæ‰¾åˆ°åŒ¹é…çš„æ ¡æ­£èŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤ç³»æ•° {self.bias_correction}")
        return prediction * self.bias_correction
    
    def predict(self, features):
        """é¢„æµ‹æ–¹æ³• - ä¿®å¤åçš„ç‰ˆæœ¬ï¼Œæ”¯æŒé›†æˆæ¨¡å‹å’Œåˆ†æ®µæ ¡æ­£"""
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰å˜åŒ–
        features_changed = self._check_features_changed(features)
        
        # å¦‚æœè¾“å…¥æ²¡æœ‰å˜åŒ–ä¸”æœ‰ä¸Šæ¬¡ç»“æœï¼Œç›´æ¥è¿”å›ä¸Šæ¬¡ç»“æœ
        if not features_changed and self.last_result is not None:
            log("è¾“å…¥æœªå˜åŒ–ï¼Œä½¿ç”¨ä¸Šæ¬¡çš„é¢„æµ‹ç»“æœ")
            return self.last_result
        
        # ä¿å­˜å½“å‰ç‰¹å¾
        self.last_features = features.copy()
        
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        log(f"å¼€å§‹å‡†å¤‡{len(features)}ä¸ªç‰¹å¾æ•°æ®")
        features_df = self._prepare_features(features)
        
        # å°è¯•ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        if self.model_loaded:
            try:
                log("ä½¿ç”¨æ¨¡å‹é¢„æµ‹...")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é›†æˆæ¨¡å‹
                if self.is_ensemble and self.main_pipeline is not None and self.support_pipeline is not None:
                    log("æ£€æµ‹åˆ°é›†æˆæ¨¡å‹ï¼Œä½¿ç”¨ä¸»æ¨¡å‹å’Œæ”¯æŒæ¨¡å‹è¿›è¡Œé¢„æµ‹")
                    
                    # è·å–ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹
                    main_preds = self.main_pipeline.predict(features_df)[0]
                    support_preds = self.support_pipeline.predict(features_df)[0]
                    
                    # ç»„åˆé¢„æµ‹ç»“æœ
                    raw_prediction = main_preds * self.main_weight + support_preds * self.support_weight
                    log(f"ä¸»æ¨¡å‹é¢„æµ‹: {main_preds:.2f}, æ”¯æŒæ¨¡å‹é¢„æµ‹: {support_preds:.2f}, åŠ æƒç»„åˆ: {raw_prediction:.2f}")
                    
                    # åº”ç”¨åˆ†æ®µæ ¡æ­£
                    if self.correction_factors and self.value_ranges:
                        result = self._apply_ranged_correction(raw_prediction)
                        log(f"åˆ†æ®µæ ¡æ­£åç»“æœ: {result:.2f}")
                    else:
                        # åº”ç”¨å…¨å±€åå·®æ ¡æ­£
                        result = raw_prediction * self.bias_correction
                        log(f"å…¨å±€æ ¡æ­£åç»“æœ: {result:.2f}")
                else:
                    # ä½¿ç”¨å•ä¸€æ¨¡å‹
                    log("ä½¿ç”¨å•ä¸€æ¨¡å‹é¢„æµ‹")
                    raw_prediction = self.pipeline.predict(features_df)[0]
                    result = raw_prediction * self.bias_correction
                    log(f"æ ¡æ­£åé¢„æµ‹ç»“æœ: {result:.2f} (åŸå§‹: {raw_prediction:.2f})")
                
                self.last_result = result
                return result
                
            except Exception as e:
                log(f"é¢„æµ‹å¤±è´¥: {str(e)}")
                log(traceback.format_exc())
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•é‡æ–°åŠ è½½
                if self._load_pipeline():
                    try:
                        log("é‡æ–°åŠ è½½æ¨¡å‹æˆåŠŸï¼Œå†æ¬¡å°è¯•é¢„æµ‹")
                        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©é¢„æµ‹æ–¹æ³•
                        if self.is_ensemble:
                            main_preds = self.main_pipeline.predict(features_df)[0]
                            support_preds = self.support_pipeline.predict(features_df)[0]
                            raw_prediction = main_preds * self.main_weight + support_preds * self.support_weight
                            result = self._apply_ranged_correction(raw_prediction)
                        else:
                            raw_prediction = self.pipeline.predict(features_df)[0]
                            result = raw_prediction * self.bias_correction
                        
                        log(f"é‡æ–°åŠ è½½åé¢„æµ‹ç»“æœ: {result:.2f}")
                        self.last_result = result
                        return result
                    except Exception as new_e:
                        log(f"é‡æ–°åŠ è½½åé¢„æµ‹ä»ç„¶å¤±è´¥: {str(new_e)}")
        
        # å¦‚æœåˆ°è¿™é‡Œï¼Œè¯´æ˜é¢„æµ‹å¤±è´¥
        log("æ‰€æœ‰é¢„æµ‹å°è¯•éƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œç‰¹å¾åç§°")
        raise ValueError("æ¨¡å‹é¢„æµ‹å¤±è´¥ã€‚è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ä¸”ç‰¹å¾æ ¼å¼æ­£ç¡®ã€‚")
    
    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯æ‘˜è¦"""
        info = {
            "æ¨¡å‹ç±»å‹": "GBDTé›†æˆæ¨¡å‹" if self.is_ensemble else "GBDTæ¨¡å‹",
            "ç›®æ ‡å˜é‡": self.target_name,
            "ç‰¹å¾æ•°é‡": len(self.feature_names),
            "æ¨¡å‹çŠ¶æ€": "å·²åŠ è½½" if self.model_loaded else "æœªåŠ è½½"
        }
        
        if self.is_ensemble:
            info["æ¨¡å‹ç»“æ„"] = "é›†æˆæ¨¡å‹ (ä¸»æ¨¡å‹ + æ”¯æŒæ¨¡å‹)"
            info["ä¸»æ¨¡å‹æƒé‡"] = f"{self.main_weight:.2f}"
            info["æ”¯æŒæ¨¡å‹æƒé‡"] = f"{self.support_weight:.2f}"
            
            if self.correction_factors:
                info["æ ¡æ­£æ–¹å¼"] = f"åˆ†æ®µæ ¡æ­£ ({len(self.correction_factors)}ä¸ªèŒƒå›´)"
            else:
                info["æ ¡æ­£æ–¹å¼"] = f"å…¨å±€æ ¡æ­£ (ç³»æ•°:{self.bias_correction:.4f})"
        else:
            info["åå·®æ ¡æ­£ç³»æ•°"] = f"{self.bias_correction:.4f}"
        
        if self.model_loaded:
            if self.is_ensemble and hasattr(self.main_pipeline, 'named_steps'):
                pipeline_steps = list(self.main_pipeline.named_steps.keys())
                info["Pipelineç»„ä»¶"] = ", ".join(pipeline_steps)
                
                # å¦‚æœæœ‰æ¨¡å‹ç»„ä»¶ï¼Œæ˜¾ç¤ºå…¶å‚æ•°
                if 'model' in self.main_pipeline.named_steps:
                    model = self.main_pipeline.named_steps['model']
                    model_type = type(model).__name__
                    info["å›å½’å™¨ç±»å‹"] = model_type
                    
                    # æ˜¾ç¤ºéƒ¨åˆ†å…³é”®è¶…å‚æ•°
                    if hasattr(model, 'n_estimators'):
                        info["æ ‘çš„æ•°é‡"] = model.n_estimators
                    if hasattr(model, 'max_depth'):
                        info["æœ€å¤§æ·±åº¦"] = model.max_depth
            elif not self.is_ensemble and hasattr(self.pipeline, 'named_steps'):
                pipeline_steps = list(self.pipeline.named_steps.keys())
                info["Pipelineç»„ä»¶"] = ", ".join(pipeline_steps)
                
                # å¦‚æœæœ‰æ¨¡å‹ç»„ä»¶ï¼Œæ˜¾ç¤ºå…¶å‚æ•°
                if 'model' in self.pipeline.named_steps:
                    model = self.pipeline.named_steps['model']
                    model_type = type(model).__name__
                    info["å›å½’å™¨ç±»å‹"] = model_type
                    
                    # æ˜¾ç¤ºéƒ¨åˆ†å…³é”®è¶…å‚æ•°
                    if hasattr(model, 'n_estimators'):
                        info["æ ‘çš„æ•°é‡"] = model.n_estimators
                    if hasattr(model, 'max_depth'):
                        info["æœ€å¤§æ·±åº¦"] = model.max_depth
                    
        return info

# åˆå§‹åŒ–é¢„æµ‹å™¨ - ä½¿ç”¨å½“å‰é€‰æ‹©çš„æ¨¡å‹
predictor = ModelPredictor(target_model=st.session_state.selected_model)

# åœ¨ä¾§è¾¹æ æ·»åŠ æ¨¡å‹ä¿¡æ¯
model_info = predictor.get_model_info()
model_info_html = "<div class='sidebar-model-info'><h3>å…³äºæ¨¡å‹</h3>"
for key, value in model_info.items():
    model_info_html += f"<p><b>{key}</b>: {value}</p>"

model_info_html += "</div>"
st.sidebar.markdown(model_info_html, unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False
if 'prediction_result' not in st.session_state:
    st.session_state.prediction_result = None
if 'warnings' not in st.session_state:
    st.session_state.warnings = []
if 'prediction_error' not in st.session_state:
    st.session_state.prediction_error = None
if 'feature_values' not in st.session_state:
    # åˆå§‹åŒ–å­˜å‚¨æ‰€æœ‰ç‰¹å¾è¾“å…¥å€¼çš„å­—å…¸
    st.session_state.feature_values = {}

# å®šä¹‰é»˜è®¤å€¼ - ä»å›¾è¡¨ä¸­æå–å‡å€¼ä½œä¸ºé»˜è®¤å€¼ï¼Œå·²ç§»é™¤O(wt%)
default_values = {
    "M(wt%)": 6.57,
    "Ash(wt%)": 5.87,
    "VM(wt%)": 74.22,
    "FC(wt%)": 13.32,
    "C(wt%)": 45.12,
    "H(wt%)": 5.95,
    "N(wt%)": 1.50,
    "PS(mm)": 1.23,
    "SM(g)": 27.03,
    "FT(Â°C)": 505.24,
    "HR(Â°C/min)": 27.81,
    "FR(mL/min)": 87.42,
    "RT(min)": 36.88
}

# ç‰¹å¾åˆ†ç±» - å·²ä»Ultimate Analysisä¸­ç§»é™¤O(wt%)
feature_categories = {
    "Proximate Analysis": ["M(wt%)", "Ash(wt%)", "VM(wt%)", "FC(wt%)"],
    "Ultimate Analysis": ["C(wt%)", "H(wt%)", "N(wt%)"],
    "Pyrolysis Conditions": ["PS(mm)", "SM(g)", "FT(Â°C)", "HR(Â°C/min)", "FR(mL/min)", "RT(min)"]
}

# é¢œè‰²é…ç½®
category_colors = {
    "Ultimate Analysis": "#501d8a",  
    "Proximate Analysis": "#1c8041",  
    "Pyrolysis Conditions": "#e55709" 
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# Proximate Analysis - ç¬¬ä¸€åˆ—
with col1:
    category = "Proximate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            # å…ˆä»ä¼šè¯çŠ¶æ€è·å–å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
            value = st.session_state.feature_values.get(feature, default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # ä¸å†é™åˆ¶è¾“å…¥èŒƒå›´ï¼Œä½†ä»ç„¶ä½¿ç”¨é»˜è®¤å€¼
            features[feature] = st.number_input(
                "", 
                value=float(value), 
                step=0.01,
                key=f"{category}_{feature}",
                format="%.2f",
                label_visibility="collapsed"
            )

# Ultimate Analysis - ç¬¬äºŒåˆ—ï¼ˆç»­ï¼‰
with col2:
    category = "Ultimate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.feature_values.get(feature, default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # ä¸å†é™åˆ¶è¾“å…¥èŒƒå›´
            features[feature] = st.number_input(
                "", 
                value=float(value), 
                step=0.01,
                key=f"{category}_{feature}",
                format="%.2f",
                label_visibility="collapsed"
            )

# Pyrolysis Conditions - ç¬¬ä¸‰åˆ—
with col3:
    category = "Pyrolysis Conditions"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.feature_values.get(feature, default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # ä¸å†é™åˆ¶è¾“å…¥èŒƒå›´
            features[feature] = st.number_input(
                "", 
                value=float(value), 
                step=0.01,
                key=f"{category}_{feature}",
                format="%.2f",
                label_visibility="collapsed"
            )

# è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰å½“å‰è¾“å…¥å€¼
with st.expander("æ˜¾ç¤ºå½“å‰è¾“å…¥å€¼", expanded=False):
    debug_info = "<ul style='columns: 3;'>"
    for feature, value in features.items():
        debug_info += f"<li>{feature}: {value:.2f}</li>"
    debug_info += "</ul>"
    st.markdown(debug_info, unsafe_allow_html=True)

# é‡ç½®çŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.feature_values = {}
    st.session_state.clear_pressed = False

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
result_container = st.container()

# é¢„æµ‹æŒ‰é’®åŒºåŸŸ
col1, col2 = st.columns([1, 1])

with col1:
    predict_clicked = st.button("ğŸ”® è¿è¡Œé¢„æµ‹", use_container_width=True, type="primary")
    if predict_clicked:
        log("å¼€å§‹é¢„æµ‹ï¼Œè·å–æœ€æ–°è¾“å…¥å€¼...")
        
        # åˆ‡æ¢æ¨¡å‹åéœ€è¦é‡æ–°åˆå§‹åŒ–é¢„æµ‹å™¨
        if predictor.target_name != st.session_state.selected_model:
            log(f"æ£€æµ‹åˆ°æ¨¡å‹å˜æ›´ï¼Œé‡æ–°åˆå§‹åŒ–é¢„æµ‹å™¨: {st.session_state.selected_model}")
            predictor = ModelPredictor(target_model=st.session_state.selected_model)
        
        # ä¿å­˜å½“å‰è¾“å…¥åˆ°ä¼šè¯çŠ¶æ€
        st.session_state.feature_values = features.copy()
        
        log(f"å¼€å§‹{st.session_state.selected_model}é¢„æµ‹ï¼Œè¾“å…¥ç‰¹å¾æ•°: {len(features)}")
        
        # æ£€æŸ¥è¾“å…¥èŒƒå›´
        warnings = predictor.check_input_range(features)
        st.session_state.warnings = warnings
        
        # è®¡ç®—FC(wt%)æ˜¯å¦æ»¡è¶³FC(wt%) = 100 - Ash(wt%) - VM(wt%)çš„çº¦æŸ
        calculated_fc = 100 - features['Ash(wt%)'] - features['VM(wt%)']
        if abs(calculated_fc - features['FC(wt%)']) > 0.5:  # å…è®¸0.5%çš„è¯¯å·®
            st.session_state.warnings.append(
                f"FC(wt%)å€¼ ({features['FC(wt%)']:.2f}) ä¸è®¡ç®—å€¼ (100 - Ash - VM = {calculated_fc:.2f}) ä¸ç¬¦ï¼Œè¿™å¯èƒ½å½±å“é¢„æµ‹å‡†ç¡®æ€§ã€‚"
            )
            log(f"è­¦å‘Š: FC(wt%)å€¼ä¸è®¡ç®—å€¼ä¸ç¬¦: {features['FC(wt%)']:.2f} vs {calculated_fc:.2f}")
        
        # æ‰§è¡Œé¢„æµ‹
        try:
            # ç¡®ä¿é¢„æµ‹å™¨å·²æ­£ç¡®åˆå§‹åŒ–
            if not predictor.model_loaded:
                log("æ¨¡å‹æœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½")
                if predictor._find_model_file() and predictor._load_pipeline():
                    log("é‡æ–°åŠ è½½æ¨¡å‹æˆåŠŸ")
                else:
                    st.error("æ— æ³•åŠ è½½æ¨¡å‹ã€‚è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨äºæ­£ç¡®ä½ç½®ã€‚")
                    st.session_state.prediction_error = "æ¨¡å‹åŠ è½½å¤±è´¥"
                    st.rerun()
            
            result = predictor.predict(features)
            if result is not None:
                st.session_state.prediction_result = float(result)
                log(f"é¢„æµ‹æˆåŠŸ: {st.session_state.prediction_result:.2f}")
                st.session_state.prediction_error = None
            else:
                log("è­¦å‘Š: é¢„æµ‹ç»“æœä¸ºç©º")
                st.session_state.prediction_error = "é¢„æµ‹ç»“æœä¸ºç©º"
        except Exception as e:
            st.session_state.prediction_error = str(e)
            log(f"é¢„æµ‹é”™è¯¯: {str(e)}")
            log(traceback.format_exc())
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

with col2:
    if st.button("ğŸ”„ é‡ç½®è¾“å…¥", use_container_width=True):
        log("é‡ç½®æ‰€æœ‰è¾“å…¥å€¼")
        st.session_state.clear_pressed = True
        st.session_state.prediction_result = None
        st.session_state.warnings = []
        st.session_state.prediction_error = None
        st.rerun()

# æ˜¾ç¤ºé¢„æµ‹ç»“æœ
if st.session_state.prediction_result is not None:
    st.markdown("---")
    
    # æ˜¾ç¤ºä¸»é¢„æµ‹ç»“æœ
    result_container.markdown(f"<div class='yield-result'>{st.session_state.selected_model}: {st.session_state.prediction_result:.2f} wt%</div>", unsafe_allow_html=True)
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    if not predictor.model_loaded:
        result_container.markdown(
            "<div class='error-box'><b>âš ï¸ é”™è¯¯ï¼š</b> æ¨¡å‹æœªæˆåŠŸåŠ è½½ï¼Œæ— æ³•æ‰§è¡Œé¢„æµ‹ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚</div>", 
            unsafe_allow_html=True
        )
    
    # æ˜¾ç¤ºè­¦å‘Š
    if st.session_state.warnings:
        warnings_html = "<div class='warning-box'><b>âš ï¸ è­¦å‘Šï¼šéƒ¨åˆ†è¾“å…¥å¯èƒ½å½±å“é¢„æµ‹ç²¾åº¦</b><ul>"
        for warning in st.session_state.warnings:
            warnings_html += f"<li>{warning}</li>"
        warnings_html += "</ul><p>è¯·æ ¹æ®æç¤ºè°ƒæ•´è¾“å…¥å€¼ä»¥è·å¾—æ›´å‡†ç¡®çš„é¢„æµ‹ã€‚</p></div>"
        result_container.markdown(warnings_html, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºé¢„æµ‹ä¿¡æ¯
    with st.expander("é¢„æµ‹ä¿¡æ¯", expanded=False):
        model_type = "é›†æˆæ¨¡å‹ (ä¸»æ¨¡å‹+æ”¯æŒæ¨¡å‹)" if predictor.is_ensemble else "å•ä¸€æ¨¡å‹"
        correction_info = f"åˆ†æ®µæ ¡æ­£ ({len(predictor.correction_factors) if predictor.correction_factors else 0}ä¸ªèŒƒå›´)" if predictor.is_ensemble and predictor.correction_factors else f"å…¨å±€æ ¡æ­£ç³»æ•°: {predictor.bias_correction:.4f}"
        
        st.markdown(f"""
        - **ç›®æ ‡å˜é‡:** {st.session_state.selected_model}
        - **é¢„æµ‹ç»“æœ:** {st.session_state.prediction_result:.2f} wt%
        - **æ¨¡å‹ç±»å‹:** {model_type}
        - **æ ¡æ­£æ–¹å¼:** {correction_info}
        """)
    
    # æŠ€æœ¯è¯´æ˜éƒ¨åˆ† - ä½¿ç”¨æŠ˜å å¼å±•ç¤º
    with st.expander("æŠ€æœ¯è¯´æ˜", expanded=False):
        st.markdown("""
        <div class='tech-info'>
        <p>æœ¬æ¨¡å‹åŸºäºGBDTï¼ˆæ¢¯åº¦æå‡å†³ç­–æ ‘ï¼‰ç®—æ³•åˆ›å»ºï¼Œé¢„æµ‹ç”Ÿç‰©è´¨çƒ­è§£äº§ç‰©åˆ†å¸ƒã€‚æ¨¡å‹ä½¿ç”¨ç”Ÿç‰©è´¨çš„å…ƒç´ åˆ†æã€è¿‘ä¼¼åˆ†ææ•°æ®å’Œçƒ­è§£æ¡ä»¶ä½œä¸ºè¾“å…¥ï¼Œè®¡ç®—çƒ­è§£ç‚­ã€çƒ­è§£æ²¹å’Œçƒ­è§£æ°”ä½“äº§é‡ã€‚</p>
        
        <p><b>ç‰¹åˆ«æé†’ï¼š</b></p>
        <ul>
            <li>è¾“å…¥å‚æ•°å»ºè®®åœ¨è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒèŒƒå›´å†…ï¼Œä»¥ä¿è¯è½¯ä»¶çš„é¢„æµ‹ç²¾åº¦</li>
            <li>ç”±äºæ¨¡å‹è®­ç»ƒæ—¶FC(wt%)é€šè¿‡100-Ash(wt%)-VM(wt%)å…¬å¼è½¬æ¢å¾—å‡ºï¼Œæ‰€ä»¥ç”¨æˆ·ä½¿ç”¨æ­¤è½¯ä»¶è¿›è¡Œé¢„æµ‹æ—¶ä¹Ÿå»ºè®®ä½¿ç”¨æ­¤å…¬å¼å¯¹FC(wt%)è¿›è¡Œè®¡ç®—</li>
            <li>æ‰€æœ‰ç‰¹å¾çš„è®­ç»ƒèŒƒå›´éƒ½åŸºäºçœŸå®è®­ç»ƒæ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚è¾“å…¥è¶…å‡ºèŒƒå›´å°†ä¼šæ”¶åˆ°æç¤º</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

elif st.session_state.prediction_error is not None:
    st.markdown("---")
    error_html = f"""
    <div class='error-box'>
        <h3>é¢„æµ‹å¤±è´¥</h3>
        <p>{st.session_state.prediction_error}</p>
        <p>è¯·æ£€æŸ¥ï¼š</p>
        <ul>
            <li>ç¡®ä¿æ¨¡å‹æ–‡ä»¶ (.joblib) å­˜åœ¨äºæ­£ç¡®ä½ç½®</li>
            <li>ç¡®ä¿è¾“å…¥æ•°æ®ç¬¦åˆæ¨¡å‹è¦æ±‚</li>
            <li>æ£€æŸ¥FC(wt%)æ˜¯å¦æ»¡è¶³ 100-Ash(wt%)-VM(wt%) çº¦æŸ</li>
        </ul>
    </div>
    """
    st.markdown(error_html, unsafe_allow_html=True)

# æ·»åŠ é¡µè„š
st.markdown("---")
footer = """
<div style='text-align: center;'>
<p>Â© 2024 ç”Ÿç‰©è´¨çº³ç±³ææ–™ä¸æ™ºèƒ½è£…å¤‡å®éªŒå®¤. ç‰ˆæœ¬: 5.2.0</p>
</div>
"""
st.markdown(footer, unsafe_allow_html=True)