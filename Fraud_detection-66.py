import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import os
import sys
import glob
from datetime import datetime
import traceback
import json
from catboost import CatBoostRegressor

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="ç”Ÿç‰©è´¨çƒ­è§£äº§ç‡é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸŒ±",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    /* å…¨å±€è®¾ç½® */
    .main {
        background-color: #f8f9fa;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 2.2em;
        color: #2c3e50;
        text-align: center;
        padding: 10px;
        margin-bottom: 20px;
        font-weight: bold;
        background: linear-gradient(90deg, #a8e063 0%, #56ab2f 100%);
        color: white;
        border-radius: 10px;
    }
    
    /* é¢„æµ‹ç»“æœæ˜¾ç¤º */
    .yield-result {
        font-size: 2em;
        text-align: center;
        padding: 25px;
        margin: 20px 0;
        background-color: #2c3e50;
        color: white;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    /* è¾“å…¥æ¡†æ ‡é¢˜ */
    .section-header {
        font-size: 1em;
        text-align: center;
        padding: 8px;
        margin-bottom: 15px;
        background-color: #3498db;
        color: white;
        border-radius: 5px;
        font-weight: bold;
    }
    
    /* è¾“å…¥æ ‡ç­¾æ ·å¼ */
    .input-label {
        padding: 8px;
        margin: 5px 0;
        background-color: #3498db;
        color: white;
        border-radius: 5px;
        text-align: center;
    }
    
    /* è­¦å‘Šæ¡†æ ·å¼ */
    .warning-box {
        background-color: #ffeaa7;
        border-left: 5px solid #fdcb6e;
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
    }
    
    /* æŠ€æœ¯ä¿¡æ¯æ ·å¼ */
    .tech-info {
        font-size: 0.9em;
        background-color: #e9ecef;
        padding: 15px;
        border-radius: 5px;
    }
    
    /* æ¨¡å‹é€‰æ‹©å™¨æ ·å¼ */
    .model-selector {
        background-color: #e9ecef;
        padding: 10px;
        border-radius: 5px;
        margin-bottom: 15px;
    }
    
    /* å°†Streamlitå“ç‰Œæ°´å°éšè— */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* ä¼˜åŒ–å°å±å¹•æ˜¾ç¤º */
    @media screen and (max-width: 768px) {
        .yield-result {
            font-size: 1.5em;
            padding: 15px;
        }
        .main-title {
            font-size: 1.8em;
        }
    }
</style>
""", unsafe_allow_html=True)

# æ—¥å¿—è®°å½•
def log(message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.logs.append(f"[{timestamp}] {message}")
    print(f"[{timestamp}] {message}")

# ç¡®ä¿æ‰€æœ‰çŠ¶æ€å˜é‡éƒ½è¢«åˆå§‹åŒ–
if 'logs' not in st.session_state:
    st.session_state.logs = []
    
if 'predictions_running' not in st.session_state:
    st.session_state.predictions_running = False
    
if 'clear_pressed' not in st.session_state:
    st.session_state.clear_pressed = False

# æ•°æ®èŒƒå›´æ£€æŸ¥å™¨ç±»
class FeatureRangeChecker:
    def __init__(self, training_ranges=None):
        # é»˜è®¤è®­ç»ƒèŒƒå›´
        self.default_ranges = {
            "C(%)": [35.0, 55.0],
            "H(%)": [4.0, 7.0],
            "O(%)": [35.0, 60.0],
            "N(%)": [0.0, 5.0],
            "Ash(%)": [0.0, 25.0],
            "VM(%)": [65.0, 95.0],
            "FC(%)": [5.0, 30.0],
            "PT(Â°C)": [350.0, 700.0],
            "HR(â„ƒ/min)": [5.0, 50.0],
            "RT(min)": [0.0, 120.0]
        }
        
        # å¦‚æœæä¾›äº†è®­ç»ƒèŒƒå›´ï¼Œä½¿ç”¨æä¾›çš„èŒƒå›´
        self.training_ranges = training_ranges if training_ranges else self.default_ranges
        log(f"ç‰¹å¾èŒƒå›´æ£€æŸ¥å™¨åˆå§‹åŒ–: {len(self.training_ranges)}ä¸ªç‰¹å¾")
    
    def check_input_range(self, input_df):
        warnings = []
        for feature, (min_val, max_val) in self.training_ranges.items():
            if feature in input_df.columns:
                value = input_df[feature].values[0]
                if value < min_val or value > max_val:
                    warnings.append(f"{feature}={value:.2f} è¶…å‡ºè®­ç»ƒèŒƒå›´ [{min_val:.2f}, {max_val:.2f}]")
        
        return warnings
    
    def save_ranges(self, file_path):
        try:
            with open(file_path, 'w') as file:
                json.dump(self.training_ranges, file)
            return True
        except Exception as e:
            log(f"ä¿å­˜ç‰¹å¾èŒƒå›´å¤±è´¥: {str(e)}")
            return False
    
    @classmethod
    def load_ranges(cls, file_path):
        try:
            with open(file_path, 'r') as file:
                ranges = json.load(file)
            return cls(ranges)
        except Exception as e:
            log(f"åŠ è½½ç‰¹å¾èŒƒå›´å¤±è´¥: {str(e)}")
            return cls()

# é¢„æµ‹å™¨ç±»
class CorrectedEnsemblePredictor:
    def __init__(self, models_dir=None, model_type="Char"):
        self.models = []
        self.scalers = []
        self.models_dir = models_dir
        self.model_type = model_type
        self.range_checker = FeatureRangeChecker()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ç›®å½•ï¼Œåˆ™å°è¯•æŸ¥æ‰¾
        if not models_dir:
            self._find_models_directory()
        
        log(f"åˆå§‹åŒ–{model_type}äº§ç‡é¢„æµ‹å™¨: æ¨¡å‹ç›®å½•={self.models_dir}")
        self._load_models()
    
    def _find_models_directory(self):
        # æŸ¥æ‰¾ä¸åŒå¯èƒ½çš„ç›®å½•ç»“æ„
        possible_dirs = [
            os.path.join(os.getcwd(), f"{self.model_type.lower()}_models"),  # å½“å‰ç›®å½•ä¸‹çš„æ¨¡å‹ç›®å½•
            os.path.join(os.getcwd(), "models", self.model_type.lower()),  # å½“å‰ç›®å½•ä¸‹çš„models/ç±»å‹ç›®å½•
            os.path.join(os.path.dirname(os.path.abspath(__file__)), f"{self.model_type.lower()}_models"),  # è„šæœ¬ç›®å½•ä¸‹
            os.path.join(os.path.dirname(os.path.abspath(__file__)), "models", self.model_type.lower()),  # è„šæœ¬ç›®å½•ä¸‹çš„models/ç±»å‹
            os.path.join(".", f"{self.model_type.lower()}_models"),  # ç›¸å¯¹è·¯å¾„
            os.path.join(".", "models", self.model_type.lower()),  # ç›¸å¯¹è·¯å¾„models/ç±»å‹
        ]
        
        # æŸ¥æ‰¾å­˜åœ¨çš„ç›®å½•
        for directory in possible_dirs:
            if os.path.exists(directory) and os.path.isdir(directory):
                self.models_dir = directory
                log(f"æ‰¾åˆ°æ¨¡å‹ç›®å½•: {directory}")
                return
        
        # åœ¨æ²¡æœ‰æ‰¾åˆ°ç›®å½•çš„æƒ…å†µä¸‹è®¾ç½®é»˜è®¤å€¼å¹¶è®°å½•
        self.models_dir = os.path.join(".", f"{self.model_type.lower()}_models")
        log(f"è­¦å‘Š: æœªæ‰¾åˆ°æ¨¡å‹ç›®å½•, å°†ä½¿ç”¨é»˜è®¤è·¯å¾„: {self.models_dir}")
    
    def _load_models(self):
        """åŠ è½½æ‰€æœ‰CatBoostæ¨¡å‹å’Œå¯¹åº”çš„æ ‡å‡†åŒ–å™¨"""
        if not os.path.exists(self.models_dir):
            log(f"é”™è¯¯: æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.models_dir}")
            return
        
        # æŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
        model_files = glob.glob(os.path.join(self.models_dir, "model_*.cbm"))
        model_files.sort()  # ç¡®ä¿é¡ºåºä¸€è‡´
        
        if not model_files:
            log(f"é”™è¯¯: åœ¨{self.models_dir}ä¸­æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
            return
        
        # åŠ è½½æ¯ä¸ªæ¨¡å‹
        for model_file in model_files:
            try:
                model_id = os.path.basename(model_file).replace("model_", "").replace(".cbm", "")
                model = CatBoostRegressor()
                model.load_model(model_file)
                self.models.append(model)
                
                # å°è¯•åŠ è½½å¯¹åº”çš„æ ‡å‡†åŒ–å™¨
                scaler_file = os.path.join(self.models_dir, f"scaler_{model_id}.json")
                if os.path.exists(scaler_file):
                    try:
                        with open(scaler_file, 'r') as f:
                            scaler_data = json.load(f)
                        self.scalers.append(scaler_data)
                    except Exception as e:
                        log(f"åŠ è½½æ ‡å‡†åŒ–å™¨{scaler_file}å¤±è´¥: {str(e)}")
                        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„æ ‡å‡†åŒ–å™¨ï¼Œå°è¯•ä½¿ç”¨é€šç”¨çš„
                        self._try_load_general_scaler()
                else:
                    # å¦‚æœæ²¡æœ‰å¯¹åº”çš„æ ‡å‡†åŒ–å™¨ï¼Œå°è¯•ä½¿ç”¨é€šç”¨çš„
                    self._try_load_general_scaler()
                    
                log(f"åŠ è½½æ¨¡å‹: {model_file}")
            except Exception as e:
                log(f"åŠ è½½æ¨¡å‹{model_file}å¤±è´¥: {str(e)}")
        
        # åŠ è½½ç‰¹å¾èŒƒå›´
        range_file = os.path.join(self.models_dir, "feature_ranges.json")
        if os.path.exists(range_file):
            self.range_checker = FeatureRangeChecker.load_ranges(range_file)
            log(f"åŠ è½½ç‰¹å¾èŒƒå›´: {range_file}")
        
        log(f"æˆåŠŸåŠ è½½{len(self.models)}ä¸ª{self.model_type}äº§ç‡æ¨¡å‹å’Œ{len(self.scalers)}ä¸ªæ ‡å‡†åŒ–å™¨")
    
    def _try_load_general_scaler(self):
        """å°è¯•åŠ è½½é€šç”¨æ ‡å‡†åŒ–å™¨"""
        general_scaler_file = os.path.join(self.models_dir, "scaler.json")
        if os.path.exists(general_scaler_file):
            try:
                with open(general_scaler_file, 'r') as f:
                    scaler_data = json.load(f)
                self.scalers.append(scaler_data)
                log(f"ä½¿ç”¨é€šç”¨æ ‡å‡†åŒ–å™¨: {general_scaler_file}")
            except Exception as e:
                log(f"åŠ è½½é€šç”¨æ ‡å‡†åŒ–å™¨å¤±è´¥: {str(e)}")
                # å¦‚æœé€šç”¨æ ‡å‡†åŒ–å™¨åŠ è½½å¤±è´¥ï¼Œæ·»åŠ Noneå ä½
                self.scalers.append(None)
        else:
            # å¦‚æœæ²¡æœ‰æ ‡å‡†åŒ–å™¨ï¼Œæ·»åŠ Noneå ä½
            self.scalers.append(None)
            log("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ ‡å‡†åŒ–å™¨ï¼Œé¢„æµ‹å¯èƒ½ä¸å‡†ç¡®")
    
    def _normalize_features(self, features_df, scaler_data):
        """ä½¿ç”¨ç»™å®šçš„æ ‡å‡†åŒ–å™¨æ•°æ®æ ‡å‡†åŒ–ç‰¹å¾"""
        if not scaler_data:
            return features_df
        
        # åˆ›å»ºæ ‡å‡†åŒ–åçš„æ•°æ®æ¡†
        normalized_df = features_df.copy()
        
        # å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–
        for feature, params in scaler_data.items():
            if feature in features_df.columns:
                if 'mean' in params and 'std' in params:
                    # åº”ç”¨Z-scoreæ ‡å‡†åŒ–
                    normalized_df[feature] = (features_df[feature] - params['mean']) / params['std']
                elif 'min' in params and 'max' in params:
                    # åº”ç”¨Min-Maxæ ‡å‡†åŒ–
                    normalized_df[feature] = (features_df[feature] - params['min']) / (params['max'] - params['min'])
        
        return normalized_df
    
    def check_input_range(self, input_df):
        """æ£€æŸ¥è¾“å…¥æ˜¯å¦åœ¨è®­ç»ƒèŒƒå›´å†…"""
        return self.range_checker.check_input_range(input_df)
    
    def predict(self, features_df, return_individual=False):
        """
        ä½¿ç”¨é›†æˆæ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        å‚æ•°:
            features_df: åŒ…å«è¾“å…¥ç‰¹å¾çš„DataFrame
            return_individual: æ˜¯å¦è¿”å›æ¯ä¸ªå­æ¨¡å‹çš„é¢„æµ‹ç»“æœ
            
        è¿”å›:
            é¢„æµ‹ç»“æœæˆ–è€…(é¢„æµ‹ç»“æœ, å•ä¸ªæ¨¡å‹é¢„æµ‹)å…ƒç»„
        """
        # å¦‚æœæ²¡æœ‰åŠ è½½æ¨¡å‹ï¼Œè¿”å›é›¶
        if not self.models:
            log(f"é”™è¯¯: æ²¡æœ‰åŠ è½½{self.model_type}äº§ç‡é¢„æµ‹æ¨¡å‹")
            return 0.0, [] if return_individual else 0.0
        
        try:
            # å­˜å‚¨æ¯ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
            individual_predictions = []
            
            # ä½¿ç”¨æ¯ä¸ªæ¨¡å‹è¿›è¡Œé¢„æµ‹
            for i, model in enumerate(self.models):
                # ç¡®å®šä½¿ç”¨å“ªä¸ªæ ‡å‡†åŒ–å™¨
                scaler_data = self.scalers[i] if i < len(self.scalers) else None
                
                # å¦‚æœæœ‰æ ‡å‡†åŒ–å™¨ï¼Œæ ‡å‡†åŒ–ç‰¹å¾
                if scaler_data:
                    normalized_features = self._normalize_features(features_df, scaler_data)
                else:
                    normalized_features = features_df
                
                # è·å–é¢„æµ‹ç»“æœ
                try:
                    prediction = model.predict(normalized_features)
                    # ç¡®ä¿é¢„æµ‹ç»“æœæ˜¯æ•°å€¼
                    if isinstance(prediction, (list, np.ndarray)):
                        pred_value = float(prediction[0])
                    else:
                        pred_value = float(prediction)
                    
                    # å­˜å‚¨å•ä¸ªæ¨¡å‹çš„é¢„æµ‹
                    individual_predictions.append(pred_value)
                except Exception as e:
                    log(f"æ¨¡å‹{i}é¢„æµ‹å¤±è´¥: {str(e)}")
                    # å‘ç”Ÿé”™è¯¯æ—¶æ·»åŠ é›¶å€¼
                    individual_predictions.append(0.0)
            
            # è®¡ç®—å¹³å‡é¢„æµ‹ç»“æœ
            if individual_predictions:
                # ç¡®ä¿é¢„æµ‹ç»“æœéè´Ÿ
                individual_predictions = [max(0, pred) for pred in individual_predictions]
                ensemble_prediction = np.mean(individual_predictions)
                log(f"{self.model_type}äº§ç‡é¢„æµ‹ç»“æœ: {ensemble_prediction:.4f}%, å­æ¨¡å‹æ•°: {len(individual_predictions)}")
                
                # è¿”å›ç»“æœ
                if return_individual:
                    return np.array([ensemble_prediction]), individual_predictions
                else:
                    return np.array([ensemble_prediction])
            else:
                log(f"è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„{self.model_type}äº§ç‡é¢„æµ‹ç»“æœ")
                return np.array([0.0]), [] if return_individual else np.array([0.0])
                
        except Exception as e:
            log(f"{self.model_type}äº§ç‡é¢„æµ‹å¤±è´¥: {str(e)}")
            log(traceback.format_exc())
            return np.array([0.0]), [] if return_individual else np.array([0.0])

# ä¾§è¾¹æ è®¾ç½®
st.sidebar.markdown("## ğŸ”§ ç³»ç»Ÿè®¾ç½®")

# æ¨¡å‹é€‰æ‹©
if 'selected_model' not in st.session_state:
    st.session_state.selected_model = "Char Yield(%)"

model_options = {
    "Char Yield(%)": "Char",
    "Oil Yield(%)": "Oil"
}

selected_model_name = st.sidebar.radio(
    "é€‰æ‹©é¢„æµ‹æ¨¡å‹",
    list(model_options.keys()),
    key="model_selector"
)

if selected_model_name != st.session_state.selected_model:
    st.session_state.selected_model = selected_model_name
    st.session_state.prediction_result = None
    st.session_state.warnings = []
    st.session_state.individual_predictions = []
    log(f"åˆ‡æ¢åˆ°æ¨¡å‹: {selected_model_name}")

# åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
model_type = model_options[selected_model_name]
predictor = CorrectedEnsemblePredictor(model_type=model_type)

# ä¸»é¡µé¢
st.markdown("<h1 class='main-title'>ç”Ÿç‰©è´¨çƒ­è§£äº§ç‡é¢„æµ‹ç³»ç»Ÿ ğŸŒ±</h1>", unsafe_allow_html=True)

# åŠ è½½çŠ¶æ€æ£€æŸ¥
if not predictor.models:
    st.error(f"âš ï¸ é”™è¯¯: æœªèƒ½åŠ è½½{model_type}äº§ç‡é¢„æµ‹æ¨¡å‹ã€‚è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶ä¸”æ ¼å¼æ­£ç¡®ã€‚")
    st.stop()

if 'prediction_result' not in st.session_state:
    st.session_state.prediction_result = None
if 'warnings' not in st.session_state:
    st.session_state.warnings = []
if 'individual_predictions' not in st.session_state:
    st.session_state.individual_predictions = []
if 'current_rmse' not in st.session_state:
    st.session_state.current_rmse = None
if 'current_r2' not in st.session_state:
    st.session_state.current_r2 = None
if 'prediction_error' not in st.session_state:
    st.session_state.prediction_error = None

# å®šä¹‰é»˜è®¤å€¼ - ä»ç”¨æˆ·æˆªå›¾ä¸­æå–
default_values = {
    "C(%)": 46.00,  # ä½¿ç”¨ä¸¤ä½å°æ•°ç²¾åº¦
    "H(%)": 5.50,
    "O(%)": 55.20,
    "N(%)": 0.60,
    "Ash(%)": 6.60,
    "VM(%)": 81.10,
    "FC(%)": 10.30,
    "PT(Â°C)": 500.00,  # ä½¿ç”¨å®é™…æµ‹è¯•å€¼
    "HR(â„ƒ/min)": 10.00,
    "RT(min)": 60.00
}

# ç‰¹å¾åˆ†ç±»
feature_categories = {
    "Ultimate Analysis": ["C(%)", "H(%)", "O(%)", "N(%)"],
    "Proximate Analysis": ["Ash(%)", "VM(%)", "FC(%)"],
    "Pyrolysis Conditions": ["PT(Â°C)", "HR(â„ƒ/min)", "RT(min)"]
}

# é¢œè‰²é…ç½®
category_colors = {
    "Ultimate Analysis": "#DAA520",  # é»„è‰²
    "Proximate Analysis": "#32CD32",  # ç»¿è‰²
    "Pyrolysis Conditions": "#FF7F50"  # æ©™è‰²
}

# åˆ›å»ºä¸‰åˆ—å¸ƒå±€
col1, col2, col3 = st.columns(3)

# ä½¿ç”¨å­—å…¸å­˜å‚¨æ‰€æœ‰è¾“å…¥å€¼
features = {}

# Ultimate Analysis - ç¬¬ä¸€åˆ—
with col1:
    category = "Ultimate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # å…³é”®ä¿®æ”¹: è®¾ç½®æ­¥é•¿ä¸º0.01ä»¥æ”¯æŒä¸¤ä½å°æ•°
            features[feature] = st.number_input(
                "", 
                min_value=0.00, 
                max_value=100.00, 
                value=float(value), 
                step=0.01,  # è®¾ç½®ä¸º0.01å…è®¸ä¸¤ä½å°æ•°è¾“å…¥
                key=f"{category}_{feature}", 
                format="%.2f",  # å¼ºåˆ¶æ˜¾ç¤ºä¸¤ä½å°æ•°
                label_visibility="collapsed"
            )
            
            # è°ƒè¯•æ˜¾ç¤º
            st.markdown(f"<span style='font-size:10px;color:gray;'>è¾“å…¥å€¼: {features[feature]:.2f}</span>", unsafe_allow_html=True)

# Proximate Analysis - ç¬¬äºŒåˆ—
with col2:
    category = "Proximate Analysis"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # å…³é”®ä¿®æ”¹: è®¾ç½®æ­¥é•¿ä¸º0.01ä»¥æ”¯æŒä¸¤ä½å°æ•°
            features[feature] = st.number_input(
                "", 
                min_value=0.00, 
                max_value=100.00, 
                value=float(value), 
                step=0.01,  # è®¾ç½®ä¸º0.01å…è®¸ä¸¤ä½å°æ•°è¾“å…¥
                key=f"{category}_{feature}", 
                format="%.2f",  # å¼ºåˆ¶æ˜¾ç¤ºä¸¤ä½å°æ•°
                label_visibility="collapsed"
            )
            
            # è°ƒè¯•æ˜¾ç¤º
            st.markdown(f"<span style='font-size:10px;color:gray;'>è¾“å…¥å€¼: {features[feature]:.2f}</span>", unsafe_allow_html=True)

# Pyrolysis Conditions - ç¬¬ä¸‰åˆ—
with col3:
    category = "Pyrolysis Conditions"
    color = category_colors[category]
    st.markdown(f"<div class='section-header' style='background-color: {color};'>{category}</div>", unsafe_allow_html=True)
    
    for feature in feature_categories[category]:
        if st.session_state.clear_pressed:
            value = default_values[feature]
        else:
            value = st.session_state.get(f"{category}_{feature}", default_values[feature])
        
        # æ ¹æ®ç‰¹å¾è®¾ç½®èŒƒå›´
        if feature == "PT(Â°C)":
            min_val, max_val = 200.00, 900.00
        elif feature == "HR(â„ƒ/min)":
            min_val, max_val = 1.00, 100.00
        elif feature == "RT(min)":
            min_val, max_val = 0.00, 120.00
        else:
            min_val, max_val = 0.00, 100.00
        
        col_a, col_b = st.columns([1, 0.5])
        with col_a:
            st.markdown(f"<div class='input-label' style='background-color: {color};'>{feature}</div>", unsafe_allow_html=True)
        with col_b:
            # å…³é”®ä¿®æ”¹: è®¾ç½®æ­¥é•¿ä¸º0.01ä»¥æ”¯æŒä¸¤ä½å°æ•°
            features[feature] = st.number_input(
                "", 
                min_value=float(min_val), 
                max_value=float(max_val), 
                value=float(value), 
                step=0.01,  # è®¾ç½®ä¸º0.01å…è®¸ä¸¤ä½å°æ•°è¾“å…¥
                key=f"{category}_{feature}", 
                format="%.2f",  # å¼ºåˆ¶æ˜¾ç¤ºä¸¤ä½å°æ•°
                label_visibility="collapsed"
            )
            
            # è°ƒè¯•æ˜¾ç¤º
            st.markdown(f"<span style='font-size:10px;color:gray;'>è¾“å…¥å€¼: {features[feature]:.2f}</span>", unsafe_allow_html=True)

# é‡ç½®çŠ¶æ€
if st.session_state.clear_pressed:
    st.session_state.clear_pressed = False

# é¢„æµ‹ç»“æœæ˜¾ç¤ºåŒºåŸŸ
result_container = st.container()

# é¢„æµ‹æŒ‰é’®åŒºåŸŸ
col1, col2 = st.columns([1, 1])

with col1:
    if st.button("ğŸ”® è¿è¡Œé¢„æµ‹", use_container_width=True, type="primary"):
        log(f"å¼€å§‹{st.session_state.selected_model}é¢„æµ‹")
        st.session_state.predictions_running = True
        st.session_state.prediction_error = None  # æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
        
        # è®°å½•è¾“å…¥
        log(f"è¾“å…¥ç‰¹å¾: {features}")
        
        # åˆ›å»ºè¾“å…¥æ•°æ®æ¡†
        input_df = pd.DataFrame([features])
        
        # æ£€æŸ¥è¾“å…¥èŒƒå›´
        warnings = predictor.check_input_range(input_df)
        st.session_state.warnings = warnings
        
        # æ‰§è¡Œé¢„æµ‹
        try:
            result, individual_preds = predictor.predict(input_df, return_individual=True)
            # ç¡®ä¿ç»“æœä¸ä¸ºç©ºï¼Œä¿®å¤é¢„æµ‹å€¼ä¸æ˜¾ç¤ºçš„é—®é¢˜
            if result is not None and len(result) > 0:
                st.session_state.prediction_result = float(result[0])
                st.session_state.individual_predictions = individual_preds
                log(f"é¢„æµ‹æˆåŠŸ: {st.session_state.prediction_result:.2f}")
                
                # è®¡ç®—æ ‡å‡†å·®ä½œä¸ºä¸ç¡®å®šæ€§æŒ‡æ ‡
                std_dev = np.std(individual_preds) if individual_preds else 0
                log(f"é¢„æµ‹æ ‡å‡†å·®: {std_dev:.4f}")
            else:
                log("è­¦å‘Š: é¢„æµ‹ç»“æœä¸ºç©º")
                st.session_state.prediction_result = 0.0
                st.session_state.individual_predictions = []
        except Exception as e:
            st.session_state.prediction_error = str(e)
            log(f"é¢„æµ‹é”™è¯¯: {str(e)}")
            log(traceback.format_exc())
            st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        st.session_state.predictions_running = False
        st.rerun()

with col2:
    if st.button("ğŸ”„ é‡ç½®è¾“å…¥", use_container_width=True):
        log("é‡ç½®æ‰€æœ‰è¾“å…¥å€¼")
        st.session_state.clear_pressed = True
        st.session_state.prediction_result = None
        st.session_state.warnings = []
        st.session_state.individual_predictions = []
        st.session_state.prediction_error = None
        st.rerun()

# æ˜¾ç¤ºé¢„æµ‹ç»“æœ
if st.session_state.prediction_result is not None:
    st.markdown("---")
    
    # æ˜¾ç¤ºä¸»é¢„æµ‹ç»“æœ
    result_container.markdown(f"<div class='yield-result'>{st.session_state.selected_model}: {st.session_state.prediction_result:.2f}%</div>", unsafe_allow_html=True)
    
    # æ˜¾ç¤ºè­¦å‘Š
    if st.session_state.warnings:
        warnings_html = "<div class='warning-box'><b>âš ï¸ è­¦å‘Šï¼šéƒ¨åˆ†è¾“å…¥è¶…å‡ºè®­ç»ƒèŒƒå›´</b><ul>"
        for warning in st.session_state.warnings:
            warnings_html += f"<li>{warning}</li>"
        warnings_html += "</ul><p>é¢„æµ‹ç»“æœå¯èƒ½ä¸å¤ªå¯é ã€‚</p></div>"
        result_container.markdown(warnings_html, unsafe_allow_html=True)
    
    # æ ‡å‡†åŒ–å™¨çŠ¶æ€
    if len(predictor.scalers) < len(predictor.models):
        result_container.markdown(
            "<div class='warning-box'><b>âš ï¸ æ³¨æ„ï¼š</b> éƒ¨åˆ†æ¨¡å‹ä½¿ç”¨äº†æœ€ç»ˆæ ‡å‡†åŒ–å™¨è€Œéå…¶å¯¹åº”çš„å­æ¨¡å‹æ ‡å‡†åŒ–å™¨ï¼Œè¿™å¯èƒ½å½±å“é¢„æµ‹ç²¾åº¦ã€‚</div>", 
            unsafe_allow_html=True
        )
    
    # æ˜¾ç¤ºè¾“å…¥ç‰¹å¾è¡¨æ ¼
    st.markdown("### è¾“å…¥ç‰¹å¾")
    formatted_features = {}
    for feature, value in features.items():
        formatted_features[feature] = f"{value:.2f}"
    
    # è½¬æ¢ä¸ºDataFrameå¹¶æ˜¾ç¤º
    input_df = pd.DataFrame([formatted_features])
    st.dataframe(input_df, use_container_width=True)
    
    # æŠ€æœ¯è¯´æ˜éƒ¨åˆ† - ä½¿ç”¨æŠ˜å å¼å±•ç¤º
    with st.expander("æŠ€æœ¯è¯´æ˜"):
        st.markdown("""
        <div class='tech-info'>
        <p>æœ¬æ¨¡å‹åŸºäºå¤šä¸ªCatBoostæ¨¡å‹é›†æˆåˆ›å»ºï¼Œé¢„æµ‹ç”Ÿç‰©è´¨çƒ­è§£äº§ç‰©åˆ†å¸ƒã€‚æ¨¡å‹ä½¿ç”¨ç”Ÿç‰©è´¨çš„å…ƒç´ åˆ†æã€è¿‘ä¼¼åˆ†ææ•°æ®å’Œçƒ­è§£æ¡ä»¶ä½œä¸ºè¾“å…¥ï¼Œè®¡ç®—ç„¦ç‚­å’Œç”Ÿç‰©æ²¹äº§é‡ã€‚</p>
        
        <p><b>å…³é”®å½±å“å› ç´ ï¼š</b></p>
        <ul>
            <li>æ¸©åº¦(PT)æ˜¯æœ€é‡è¦çš„å½±å“å› ç´ ï¼Œå¯¹ç„¦ç‚­äº§é‡æœ‰æ˜¾è‘—è´Ÿç›¸å…³æ€§</li>
            <li>åœç•™æ—¶é—´(RT)æ˜¯ç¬¬äºŒé‡è¦çš„å› ç´ ï¼Œå»¶é•¿åœç•™æ—¶é—´ä¼šé™ä½ç„¦ç‚­äº§é‡</li>
            <li>å›ºå®šç¢³å«é‡(FC)å¯ç”±100-Ash(%)-VM(%)è®¡ç®—å¾—å‡ºï¼Œå¯¹é¢„æµ‹ä¹Ÿæœ‰é‡è¦å½±å“</li>
        </ul>
        
        <p><b>é¢„æµ‹å‡†ç¡®åº¦ï¼š</b></p>
        <p>æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡æ–¹æ ¹è¯¯å·®(RMSE)çº¦ä¸º3.39%ï¼Œå†³å®šç³»æ•°(RÂ²)ä¸º0.93ã€‚å¯¹å¤§å¤šæ•°ç”Ÿç‰©è´¨æ ·æœ¬ï¼Œé¢„æµ‹è¯¯å·®åœ¨Â±5%ä»¥å†…ã€‚</p>
        
        <p><b>æœ€è¿‘æ›´æ–°ï¼š</b></p>
        <ul>
            <li>âœ… ä¿®å¤äº†æ‰€æœ‰è¾“å…¥å€¼åªèƒ½ç²¾ç¡®åˆ°ä¸€ä½å°æ•°çš„é—®é¢˜</li>
            <li>âœ… è§£å†³äº†éƒ¨åˆ†å­æ¨¡å‹æ ‡å‡†åŒ–å™¨ä¸åŒ¹é…çš„é—®é¢˜</li>
            <li>âœ… å¢åŠ äº†æ¨¡å‹åˆ‡æ¢åŠŸèƒ½ï¼Œæ”¯æŒä¸åŒäº§ç‡é¢„æµ‹</li>
            <li>âœ… ä¿®å¤äº†é¢„æµ‹ç»“æœä¸æ˜¾ç¤ºçš„é—®é¢˜</li>
            <li>âœ… ä¿®å¤äº†"invalid index to scalar variable"é”™è¯¯</li>
            <li>âœ… ç§»é™¤äº†å­æ¨¡å‹é¢„æµ‹ç»“æœæŸ±çŠ¶å›¾æ˜¾ç¤º</li>
            <li>âœ… ç§»é™¤äº†æ€§èƒ½æŒ‡æ ‡æ˜¾ç¤ºéƒ¨åˆ†</li>
            <li>âœ… æ”¹è¿›äº†æ¨¡å‹åŠ è½½å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†å’Œæç¤º</li>
            <li>âœ… å¢å¼ºäº†å¯¹ä¸åŒç›®å½•ç»“æ„çš„å…¼å®¹æ€§</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

# æ·»åŠ é¡µè„š
st.markdown("---")
footer = """
<div style='text-align: center;'>
<p>Â© 2023 Biomass Pyrolysis Modeling Team. ç‰ˆæœ¬: 2.3.0</p>
<p>æœ¬åº”ç”¨æ”¯æŒä¸¤ä½å°æ•°è¾“å…¥ç²¾åº¦ | å·²é›†æˆCharå’ŒOiläº§ç‡é¢„æµ‹æ¨¡å‹</p>
</div>
"""
st.markdown(footer, unsafe_allow_html=True)